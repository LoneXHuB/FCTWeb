{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04D_jHiClylt"
      },
      "source": [
        "\n",
        "# Data Reading Prepration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiAZIbRFsIBk",
        "outputId": "be8fb4eb-9fff-4e5b-b0c7-46ef8b2a8623"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\kheli\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LayerNormalization\n",
        "from keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "from dateutil.parser import parse\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiALauuH_5Gx",
        "outputId": "1b2e2f7b-c643-4c08-f293-e78a92f168e9"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32md:\\Work\\Cyrus\\API_FTransformer_ECT2023_04_07[12295].ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/gdrive\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCH0GJ3cs4Qq",
        "outputId": "349eaf52-85b8-45de-b5d5-c53b7d17ada7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Sajjad_cloned_ready\n"
          ]
        }
      ],
      "source": [
        "#id\n",
        "%cd gdrive/MyDrive/Sajjad_cloned_ready\n",
        "# !unzip 'Sajjad cloned_id.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEpCGLFwrA72",
        "outputId": "7dada1c9-cc8b-4547-8c28-a53ce38fedf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content/gdrive/MyDrive\n",
            "fatal: destination path 'trans-2022-17' already exists and is not an empty directory.\n",
            "/content/gdrive/MyDrive/trans-2022-17\n",
            "Archive:  transformers-main.zip\n",
            "replace transformers-main/.circleci/config.yml? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: transformers-main/.circleci/config.yml  \n",
            "  inflating: transformers-main/.circleci/create_circleci_config.py  \n",
            "  inflating: transformers-main/.circleci/TROUBLESHOOT.md  \n",
            "  inflating: transformers-main/.coveragerc  \n",
            "  inflating: transformers-main/.gitattributes  \n",
            "  inflating: transformers-main/.github/conda/build.sh  \n",
            "  inflating: transformers-main/.github/conda/meta.yaml  \n",
            "  inflating: transformers-main/.github/ISSUE_TEMPLATE/bug-report.yml  \n",
            "  inflating: transformers-main/.github/ISSUE_TEMPLATE/config.yml  \n",
            "  inflating: transformers-main/.github/ISSUE_TEMPLATE/feature-request.yml  \n",
            "  inflating: transformers-main/.github/ISSUE_TEMPLATE/migration.yml  \n",
            "  inflating: transformers-main/.github/ISSUE_TEMPLATE/new-model-addition.yml  \n",
            "  inflating: transformers-main/.github/PULL_REQUEST_TEMPLATE.md  \n",
            "  inflating: transformers-main/.github/workflows/add-model-like.yml  \n",
            "  inflating: transformers-main/.github/workflows/build-docker-images.yml  \n",
            "  inflating: transformers-main/.github/workflows/build-past-ci-docker-images.yml  \n",
            "  inflating: transformers-main/.github/workflows/build_documentation.yml  \n",
            "  inflating: transformers-main/.github/workflows/build_pr_documentation.yml  \n",
            "  inflating: transformers-main/.github/workflows/check_runner_status.yml  \n",
            "  inflating: transformers-main/.github/workflows/delete_doc_comment.yml  \n",
            "  inflating: transformers-main/.github/workflows/doctests.yml  \n",
            "  inflating: transformers-main/.github/workflows/model-templates.yml  \n",
            "  inflating: transformers-main/.github/workflows/release-conda.yml  \n",
            "  inflating: transformers-main/.github/workflows/self-nightly-scheduled.yml  \n",
            "  inflating: transformers-main/.github/workflows/self-past-caller.yml  \n",
            "  inflating: transformers-main/.github/workflows/self-past.yml  \n",
            "  inflating: transformers-main/.github/workflows/self-push-caller.yml  \n",
            "  inflating: transformers-main/.github/workflows/self-push.yml  \n",
            "  inflating: transformers-main/.github/workflows/self-scheduled.yml  \n",
            "  inflating: transformers-main/.github/workflows/stale.yml  \n",
            "  inflating: transformers-main/.github/workflows/TROUBLESHOOT.md  \n",
            "  inflating: transformers-main/.github/workflows/update_metdata.yml  \n",
            "  inflating: transformers-main/.gitignore  \n",
            "  inflating: transformers-main/CITATION.cff  \n",
            "  inflating: transformers-main/CODE_OF_CONDUCT.md  \n",
            "  inflating: transformers-main/conftest.py  \n",
            "  inflating: transformers-main/CONTRIBUTING.md  \n",
            "  inflating: transformers-main/docker/transformers-all-latest-gpu/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-cpu/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-doc-builder/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-gpu/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-past-gpu/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-pytorch-cpu/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-pytorch-deepspeed-nightly-gpu/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-pytorch-gpu/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-pytorch-tpu/bert-base-cased.jsonnet  \n",
            "  inflating: transformers-main/docker/transformers-pytorch-tpu/dataset.yaml  \n",
            "  inflating: transformers-main/docker/transformers-pytorch-tpu/docker-entrypoint.sh  \n",
            "  inflating: transformers-main/docker/transformers-pytorch-tpu/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-tensorflow-cpu/Dockerfile  \n",
            "  inflating: transformers-main/docker/transformers-tensorflow-gpu/Dockerfile  \n",
            "  inflating: transformers-main/docs/README.md  \n",
            "  inflating: transformers-main/docs/source/de/accelerate.mdx  \n",
            "  inflating: transformers-main/docs/source/de/autoclass_tutorial.mdx  \n",
            "  inflating: transformers-main/docs/source/de/index.mdx  \n",
            "  inflating: transformers-main/docs/source/de/installation.mdx  \n",
            "  inflating: transformers-main/docs/source/de/model_sharing.mdx  \n",
            "  inflating: transformers-main/docs/source/de/pipeline_tutorial.mdx  \n",
            "  inflating: transformers-main/docs/source/de/preprocessing.mdx  \n",
            "  inflating: transformers-main/docs/source/de/quicktour.mdx  \n",
            "  inflating: transformers-main/docs/source/de/training.mdx  \n",
            "  inflating: transformers-main/docs/source/de/_config.py  \n",
            "  inflating: transformers-main/docs/source/de/_toctree.yml  \n",
            "  inflating: transformers-main/docs/source/en/accelerate.mdx  \n",
            "  inflating: transformers-main/docs/source/en/add_new_model.mdx  \n",
            "  inflating: transformers-main/docs/source/en/add_new_pipeline.mdx  \n",
            "  inflating: transformers-main/docs/source/en/add_tensorflow_model.mdx  \n",
            "  inflating: transformers-main/docs/source/en/autoclass_tutorial.mdx  \n",
            "  inflating: transformers-main/docs/source/en/benchmarks.mdx  \n",
            "  inflating: transformers-main/docs/source/en/bertology.mdx  \n",
            "  inflating: transformers-main/docs/source/en/big_models.mdx  \n",
            "  inflating: transformers-main/docs/source/en/community.mdx  \n",
            "  inflating: transformers-main/docs/source/en/contributing.md  \n",
            "  inflating: transformers-main/docs/source/en/converting_tensorflow_models.mdx  \n",
            "  inflating: transformers-main/docs/source/en/create_a_model.mdx  \n",
            "  inflating: transformers-main/docs/source/en/custom_models.mdx  \n",
            "  inflating: transformers-main/docs/source/en/debugging.mdx  \n",
            "  inflating: transformers-main/docs/source/en/fast_tokenizers.mdx  \n",
            "  inflating: transformers-main/docs/source/en/glossary.mdx  \n",
            "  inflating: transformers-main/docs/source/en/hpo_train.mdx  \n",
            "  inflating: transformers-main/docs/source/en/index.mdx  \n",
            "  inflating: transformers-main/docs/source/en/installation.mdx  \n",
            "  inflating: transformers-main/docs/source/en/internal/file_utils.mdx  \n",
            "  inflating: transformers-main/docs/source/en/internal/generation_utils.mdx  \n",
            "  inflating: transformers-main/docs/source/en/internal/image_processing_utils.mdx  \n",
            "  inflating: transformers-main/docs/source/en/internal/modeling_utils.mdx  \n",
            "  inflating: transformers-main/docs/source/en/internal/pipelines_utils.mdx  \n",
            "  inflating: transformers-main/docs/source/en/internal/tokenization_utils.mdx  \n",
            "  inflating: transformers-main/docs/source/en/internal/trainer_utils.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/callback.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/configuration.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/data_collator.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/deepspeed.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/feature_extractor.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/keras_callbacks.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/logging.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/model.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/onnx.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/optimizer_schedules.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/output.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/pipelines.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/processors.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/text_generation.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/tokenizer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/main_classes/trainer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/migration.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/albert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/auto.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/bart.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/barthez.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/bartpho.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/beit.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/bert-generation.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/bert-japanese.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/bert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/bertweet.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/bigbird_pegasus.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/big_bird.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/blenderbot-small.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/blenderbot.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/bloom.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/bort.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/byt5.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/camembert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/canine.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/clip.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/codegen.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/conditional_detr.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/convbert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/convnext.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/cpm.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/ctrl.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/cvt.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/data2vec.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/deberta-v2.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/deberta.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/decision_transformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/deformable_detr.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/deit.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/detr.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/dialogpt.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/distilbert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/dit.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/donut.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/dpr.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/dpt.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/electra.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/encoder-decoder.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/ernie.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/esm.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/flaubert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/flava.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/fnet.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/fsmt.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/funnel.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/glpn.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/gpt2.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/gptj.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/gpt_neo.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/gpt_neox.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/gpt_neox_japanese.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/groupvit.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/herbert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/hubert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/ibert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/imagegpt.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/layoutlm.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/layoutlmv2.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/layoutlmv3.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/layoutxlm.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/led.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/levit.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/lilt.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/longformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/longt5.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/luke.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/lxmert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/m2m_100.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/marian.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/markuplm.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/maskformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/mbart.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/mctct.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/megatron-bert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/megatron_gpt2.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/mluke.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/mobilebert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/mobilevit.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/mpnet.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/mt5.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/mvp.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/nezha.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/nllb.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/nystromformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/openai-gpt.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/opt.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/owlvit.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/pegasus.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/pegasus_x.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/perceiver.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/phobert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/plbart.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/poolformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/prophetnet.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/qdqbert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/rag.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/realm.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/reformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/regnet.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/rembert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/resnet.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/retribert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/roberta.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/roformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/segformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/sew-d.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/sew.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/speech-encoder-decoder.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/speech_to_text.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/speech_to_text_2.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/splinter.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/squeezebert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/swin.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/swinv2.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/t5.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/t5v1.1.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/tapas.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/tapex.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/time_series_transformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/trajectory_transformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/transfo-xl.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/trocr.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/ul2.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/unispeech-sat.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/unispeech.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/van.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/videomae.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/vilt.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/vision-encoder-decoder.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/vision-text-dual-encoder.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/visual_bert.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/vit.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/vit_mae.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/vit_msn.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/wav2vec2-conformer.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/wav2vec2.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/wav2vec2_phoneme.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/wavlm.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/whisper.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/xclip.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/xglm.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/xlm-prophetnet.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/xlm-roberta-xl.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/xlm-roberta.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/xlm.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/xlnet.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/xlsr_wav2vec2.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/xls_r.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/yolos.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_doc/yoso.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_sharing.mdx  \n",
            "  inflating: transformers-main/docs/source/en/model_summary.mdx  \n",
            "  inflating: transformers-main/docs/source/en/multilingual.mdx  \n",
            "  inflating: transformers-main/docs/source/en/notebooks.md  \n",
            "  inflating: transformers-main/docs/source/en/pad_truncation.mdx  \n",
            "  inflating: transformers-main/docs/source/en/performance.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_hardware.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_infer_cpu.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_infer_gpu_many.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_infer_gpu_one.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_infer_special.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_train_cpu.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_train_cpu_many.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_train_gpu_many.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_train_gpu_one.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_train_special.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perf_train_tpu.mdx  \n",
            "  inflating: transformers-main/docs/source/en/perplexity.mdx  \n",
            "  inflating: transformers-main/docs/source/en/philosophy.mdx  \n",
            "  inflating: transformers-main/docs/source/en/pipeline_tutorial.mdx  \n",
            "  inflating: transformers-main/docs/source/en/preprocessing.mdx  \n",
            "  inflating: transformers-main/docs/source/en/pr_checks.mdx  \n",
            "  inflating: transformers-main/docs/source/en/quicktour.mdx  \n",
            "  inflating: transformers-main/docs/source/en/run_scripts.mdx  \n",
            "  inflating: transformers-main/docs/source/en/sagemaker.mdx  \n",
            "  inflating: transformers-main/docs/source/en/serialization.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/asr.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/audio_classification.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/image_classification.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/language_modeling.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/multiple_choice.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/question_answering.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/semantic_segmentation.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/sequence_classification.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/summarization.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/token_classification.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tasks/translation.mdx  \n",
            "  inflating: transformers-main/docs/source/en/task_summary.mdx  \n",
            "  inflating: transformers-main/docs/source/en/testing.mdx  \n",
            "  inflating: transformers-main/docs/source/en/tokenizer_summary.mdx  \n",
            "  inflating: transformers-main/docs/source/en/torchscript.mdx  \n",
            "  inflating: transformers-main/docs/source/en/training.mdx  \n",
            "  inflating: transformers-main/docs/source/en/troubleshooting.mdx  \n",
            "  inflating: transformers-main/docs/source/en/_config.py  \n",
            "  inflating: transformers-main/docs/source/en/_toctree.yml  \n",
            "  inflating: transformers-main/docs/source/es/accelerate.mdx  \n",
            "  inflating: transformers-main/docs/source/es/autoclass_tutorial.mdx  \n",
            "  inflating: transformers-main/docs/source/es/bertology.mdx  \n",
            "  inflating: transformers-main/docs/source/es/converting_tensorflow_models.mdx  \n",
            "  inflating: transformers-main/docs/source/es/create_a_model.mdx  \n",
            "  inflating: transformers-main/docs/source/es/custom_models.mdx  \n",
            "  inflating: transformers-main/docs/source/es/fast_tokenizers.mdx  \n",
            "  inflating: transformers-main/docs/source/es/index.mdx  \n",
            "  inflating: transformers-main/docs/source/es/installation.mdx  \n",
            "  inflating: transformers-main/docs/source/es/model_sharing.mdx  \n",
            "  inflating: transformers-main/docs/source/es/multilingual.mdx  \n",
            "  inflating: transformers-main/docs/source/es/philosophy.mdx  \n",
            "  inflating: transformers-main/docs/source/es/pipeline_tutorial.mdx  \n",
            "  inflating: transformers-main/docs/source/es/preprocessing.mdx  \n",
            "  inflating: transformers-main/docs/source/es/quicktour.mdx  \n",
            "  inflating: transformers-main/docs/source/es/run_scripts.mdx  \n",
            "  inflating: transformers-main/docs/source/es/sagemaker.mdx  \n",
            "  inflating: transformers-main/docs/source/es/tasks/image_classification.mdx  \n",
            "  inflating: transformers-main/docs/source/es/tasks/language_modeling.mdx  \n",
            "  inflating: transformers-main/docs/source/es/tasks/summarization.mdx  \n",
            "  inflating: transformers-main/docs/source/es/training.mdx  \n",
            "  inflating: transformers-main/docs/source/es/_config.py  \n",
            "  inflating: transformers-main/docs/source/es/_toctree.yml  \n",
            "  inflating: transformers-main/docs/source/it/accelerate.mdx  \n",
            "  inflating: transformers-main/docs/source/it/add_new_model.mdx  \n",
            "  inflating: transformers-main/docs/source/it/add_new_pipeline.mdx  \n",
            "  inflating: transformers-main/docs/source/it/autoclass_tutorial.mdx  \n",
            "  inflating: transformers-main/docs/source/it/converting_tensorflow_models.mdx  \n",
            "  inflating: transformers-main/docs/source/it/create_a_model.mdx  \n",
            "  inflating: transformers-main/docs/source/it/custom_models.mdx  \n",
            "  inflating: transformers-main/docs/source/it/debugging.mdx  \n",
            "  inflating: transformers-main/docs/source/it/index.mdx  \n",
            "  inflating: transformers-main/docs/source/it/installation.mdx  \n",
            "  inflating: transformers-main/docs/source/it/model_sharing.mdx  \n",
            "  inflating: transformers-main/docs/source/it/multilingual.mdx  \n",
            "  inflating: transformers-main/docs/source/it/pipeline_tutorial.mdx  \n",
            "  inflating: transformers-main/docs/source/it/preprocessing.mdx  \n",
            "  inflating: transformers-main/docs/source/it/quicktour.mdx  \n",
            "  inflating: transformers-main/docs/source/it/run_scripts.mdx  \n",
            "  inflating: transformers-main/docs/source/it/serialization.mdx  \n",
            "  inflating: transformers-main/docs/source/it/training.mdx  \n",
            "  inflating: transformers-main/docs/source/it/_config.py  \n",
            "  inflating: transformers-main/docs/source/it/_toctree.yml  \n",
            "  inflating: transformers-main/docs/source/pt/accelerate.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/create_a_model.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/fast_tokenizers.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/index.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/installation.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/multilingual.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/pipeline_tutorial.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/quicktour.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/tasks/sequence_classification.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/tasks/token_classification.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/training.mdx  \n",
            "  inflating: transformers-main/docs/source/pt/_config.py  \n",
            "  inflating: transformers-main/docs/source/pt/_toctree.yml  \n",
            "  inflating: transformers-main/docs/source/_config.py  \n",
            "  inflating: transformers-main/docs/TRANSLATING.md  \n",
            "  inflating: transformers-main/examples/flax/conftest.py  \n",
            "  inflating: transformers-main/examples/flax/image-captioning/create_model_from_encoder_decoder_models.py  \n",
            "  inflating: transformers-main/examples/flax/image-captioning/README.md  \n",
            "  inflating: transformers-main/examples/flax/image-captioning/run_image_captioning_flax.py  \n",
            "  inflating: transformers-main/examples/flax/language-modeling/README.md  \n",
            "  inflating: transformers-main/examples/flax/language-modeling/requirements.txt  \n",
            "  inflating: transformers-main/examples/flax/language-modeling/run_bart_dlm_flax.py  \n",
            "  inflating: transformers-main/examples/flax/language-modeling/run_clm_flax.py  \n",
            "  inflating: transformers-main/examples/flax/language-modeling/run_mlm_flax.py  \n",
            "  inflating: transformers-main/examples/flax/language-modeling/run_t5_mlm_flax.py  \n",
            "  inflating: transformers-main/examples/flax/language-modeling/t5_tokenizer_model.py  \n",
            "  inflating: transformers-main/examples/flax/question-answering/README.md  \n",
            "  inflating: transformers-main/examples/flax/question-answering/requirements.txt  \n",
            "  inflating: transformers-main/examples/flax/question-answering/run_qa.py  \n",
            "  inflating: transformers-main/examples/flax/question-answering/utils_qa.py  \n",
            "  inflating: transformers-main/examples/flax/README.md  \n",
            "  inflating: transformers-main/examples/flax/summarization/README.md  \n",
            "  inflating: transformers-main/examples/flax/summarization/requirements.txt  \n",
            "  inflating: transformers-main/examples/flax/summarization/run_summarization_flax.py  \n",
            "  inflating: transformers-main/examples/flax/test_flax_examples.py  \n",
            "  inflating: transformers-main/examples/flax/text-classification/README.md  \n",
            "  inflating: transformers-main/examples/flax/text-classification/requirements.txt  \n",
            "  inflating: transformers-main/examples/flax/text-classification/run_flax_glue.py  \n",
            "  inflating: transformers-main/examples/flax/token-classification/README.md  \n",
            "  inflating: transformers-main/examples/flax/token-classification/requirements.txt  \n",
            "  inflating: transformers-main/examples/flax/token-classification/run_flax_ner.py  \n",
            "  inflating: transformers-main/examples/flax/vision/README.md  \n",
            "  inflating: transformers-main/examples/flax/vision/requirements.txt  \n",
            "  inflating: transformers-main/examples/flax/vision/run_image_classification.py  \n",
            "  inflating: transformers-main/examples/flax/_tests_requirements.txt  \n",
            "  inflating: transformers-main/examples/legacy/multiple_choice/run_multiple_choice.py  \n",
            "  inflating: transformers-main/examples/legacy/multiple_choice/utils_multiple_choice.py  \n",
            "  inflating: transformers-main/examples/legacy/pytorch-lightning/lightning_base.py  \n",
            "  inflating: transformers-main/examples/legacy/pytorch-lightning/requirements.txt  \n",
            "  inflating: transformers-main/examples/legacy/pytorch-lightning/run_glue.py  \n",
            "  inflating: transformers-main/examples/legacy/pytorch-lightning/run_glue.sh  \n",
            "  inflating: transformers-main/examples/legacy/pytorch-lightning/run_ner.py  \n",
            "  inflating: transformers-main/examples/legacy/pytorch-lightning/run_ner.sh  \n",
            "  inflating: transformers-main/examples/legacy/pytorch-lightning/run_pos.sh  \n",
            "  inflating: transformers-main/examples/legacy/question-answering/README.md  \n",
            "  inflating: transformers-main/examples/legacy/question-answering/run_squad.py  \n",
            "  inflating: transformers-main/examples/legacy/question-answering/run_squad_trainer.py  \n",
            "  inflating: transformers-main/examples/legacy/README.md  \n",
            "  inflating: transformers-main/examples/legacy/run_camembert.py  \n",
            "  inflating: transformers-main/examples/legacy/run_chinese_ref.py  \n",
            "  inflating: transformers-main/examples/legacy/run_language_modeling.py  \n",
            "  inflating: transformers-main/examples/legacy/run_openai_gpt.py  \n",
            "  inflating: transformers-main/examples/legacy/run_swag.py  \n",
            "  inflating: transformers-main/examples/legacy/run_transfo_xl.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/convert_model_to_fp16.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/download_wmt.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/finetune.sh  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/finetune_tpu.sh  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/finetune_trainer.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/minify_dataset.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/old_test_calculate_rouge.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/old_test_datasets.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/old_test_fsmt_bleu_score.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/old_test_seq2seq_examples.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/old_test_seq2seq_examples_multi_gpu.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/old_test_tatoeba_conversion.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/pack_dataset.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/README.md  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/requirements.txt  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/romanian_postprocessing.md  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/rouge_cli.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/run_distributed_eval.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/run_eval.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/run_eval_search.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/save_len_file.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/save_randomly_initialized_model.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/sentence_splitter.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/seq2seq_trainer.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/seq2seq_training_args.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/fsmt/build-eval-data.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/fsmt/fsmt_val_data.json  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/test_data  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/wmt_en_ro/test.source  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/wmt_en_ro/test.target  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/wmt_en_ro/train.len  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/wmt_en_ro/train.source  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/wmt_en_ro/train.target  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/wmt_en_ro/val.len  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/wmt_en_ro/val.source  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/test_data/wmt_en_ro/val.target  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/train_distilbart_cnn.sh  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/train_distil_marian_enro.sh  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/train_distil_marian_enro_tpu.sh  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/train_mbart_cc25_enro.sh  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/utils.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/xla_spawn.py  \n",
            "  inflating: transformers-main/examples/legacy/seq2seq/__init__.py  \n",
            "  inflating: transformers-main/examples/legacy/text-classification/run_tf_text_classification.py  \n",
            "  inflating: transformers-main/examples/legacy/token-classification/README.md  \n",
            "  inflating: transformers-main/examples/legacy/token-classification/run.sh  \n",
            "  inflating: transformers-main/examples/legacy/token-classification/run_chunk.sh  \n",
            "  inflating: transformers-main/examples/legacy/token-classification/run_ner.py  \n",
            "  inflating: transformers-main/examples/legacy/token-classification/run_pos.sh  \n",
            "  inflating: transformers-main/examples/legacy/token-classification/run_tf_ner.py  \n",
            "  inflating: transformers-main/examples/legacy/token-classification/scripts/preprocess.py  \n",
            "  inflating: transformers-main/examples/legacy/token-classification/tasks.py  \n",
            "  inflating: transformers-main/examples/legacy/token-classification/utils_ner.py  \n",
            "  inflating: transformers-main/examples/pytorch/audio-classification/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/audio-classification/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/audio-classification/run_audio_classification.py  \n",
            "  inflating: transformers-main/examples/pytorch/benchmarking/plot_csv_file.py  \n",
            "  inflating: transformers-main/examples/pytorch/benchmarking/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/benchmarking/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/benchmarking/run_benchmark.py  \n",
            "  inflating: transformers-main/examples/pytorch/conftest.py  \n",
            "  inflating: transformers-main/examples/pytorch/contrastive-image-text/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/contrastive-image-text/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/contrastive-image-text/run_clip.py  \n",
            "  inflating: transformers-main/examples/pytorch/image-classification/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/image-classification/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/image-classification/run_image_classification.py  \n",
            "  inflating: transformers-main/examples/pytorch/image-classification/run_image_classification_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/image-pretraining/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/image-pretraining/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/image-pretraining/run_mae.py  \n",
            "  inflating: transformers-main/examples/pytorch/image-pretraining/run_mim.py  \n",
            "  inflating: transformers-main/examples/pytorch/language-modeling/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/language-modeling/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/language-modeling/run_clm.py  \n",
            "  inflating: transformers-main/examples/pytorch/language-modeling/run_clm_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/language-modeling/run_mlm.py  \n",
            "  inflating: transformers-main/examples/pytorch/language-modeling/run_mlm_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/language-modeling/run_plm.py  \n",
            "  inflating: transformers-main/examples/pytorch/multiple-choice/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/multiple-choice/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/multiple-choice/run_no_trainer.sh  \n",
            "  inflating: transformers-main/examples/pytorch/multiple-choice/run_swag.py  \n",
            "  inflating: transformers-main/examples/pytorch/multiple-choice/run_swag_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/question-answering/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/question-answering/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/question-answering/run_qa.py  \n",
            "  inflating: transformers-main/examples/pytorch/question-answering/run_qa_beam_search.py  \n",
            "  inflating: transformers-main/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/question-answering/run_qa_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/question-answering/run_seq2seq_qa.py  \n",
            "  inflating: transformers-main/examples/pytorch/question-answering/trainer_qa.py  \n",
            "  inflating: transformers-main/examples/pytorch/question-answering/trainer_seq2seq_qa.py  \n",
            "  inflating: transformers-main/examples/pytorch/question-answering/utils_qa.py  \n",
            "  inflating: transformers-main/examples/pytorch/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/semantic-segmentation/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/semantic-segmentation/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py  \n",
            "  inflating: transformers-main/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/speech-pretraining/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/speech-pretraining/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/speech-recognition/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/speech-recognition/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py  \n",
            "  inflating: transformers-main/examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py  \n",
            "  inflating: transformers-main/examples/pytorch/summarization/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/summarization/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/summarization/run_summarization.py  \n",
            "  inflating: transformers-main/examples/pytorch/summarization/run_summarization_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/test_accelerate_examples.py  \n",
            "  inflating: transformers-main/examples/pytorch/test_pytorch_examples.py  \n",
            "  inflating: transformers-main/examples/pytorch/test_xla_examples.py  \n",
            "  inflating: transformers-main/examples/pytorch/text-classification/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/text-classification/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/text-classification/run_glue.py  \n",
            "  inflating: transformers-main/examples/pytorch/text-classification/run_glue_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/text-classification/run_xnli.py  \n",
            "  inflating: transformers-main/examples/pytorch/text-generation/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/text-generation/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/text-generation/run_generation.py  \n",
            "  inflating: transformers-main/examples/pytorch/token-classification/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/token-classification/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/token-classification/run.sh  \n",
            "  inflating: transformers-main/examples/pytorch/token-classification/run_ner.py  \n",
            "  inflating: transformers-main/examples/pytorch/token-classification/run_ner_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/token-classification/run_no_trainer.sh  \n",
            "  inflating: transformers-main/examples/pytorch/translation/README.md  \n",
            "  inflating: transformers-main/examples/pytorch/translation/requirements.txt  \n",
            "  inflating: transformers-main/examples/pytorch/translation/run_translation.py  \n",
            "  inflating: transformers-main/examples/pytorch/translation/run_translation_no_trainer.py  \n",
            "  inflating: transformers-main/examples/pytorch/xla_spawn.py  \n",
            "  inflating: transformers-main/examples/pytorch/_tests_requirements.txt  \n",
            "  inflating: transformers-main/examples/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/adversarial/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/adversarial/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/adversarial/run_hans.py  \n",
            "  inflating: transformers-main/examples/research_projects/adversarial/utils_hans.py  \n",
            "  inflating: transformers-main/examples/research_projects/bert-loses-patience/pabee/modeling_pabee_albert.py  \n",
            "  inflating: transformers-main/examples/research_projects/bert-loses-patience/pabee/modeling_pabee_bert.py  \n",
            " extracting: transformers-main/examples/research_projects/bert-loses-patience/pabee/__init__.py  \n",
            "  inflating: transformers-main/examples/research_projects/bert-loses-patience/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/bert-loses-patience/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/bert-loses-patience/run_glue_with_pabee.py  \n",
            "  inflating: transformers-main/examples/research_projects/bert-loses-patience/test_run_glue_with_pabee.py  \n",
            "  inflating: transformers-main/examples/research_projects/bertabs/configuration_bertabs.py  \n",
            "  inflating: transformers-main/examples/research_projects/bertabs/convert_bertabs_original_pytorch_checkpoint.py  \n",
            "  inflating: transformers-main/examples/research_projects/bertabs/modeling_bertabs.py  \n",
            "  inflating: transformers-main/examples/research_projects/bertabs/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/bertabs/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/bertabs/run_summarization.py  \n",
            "  inflating: transformers-main/examples/research_projects/bertabs/test_utils_summarization.py  \n",
            "  inflating: transformers-main/examples/research_projects/bertabs/utils_summarization.py  \n",
            " extracting: transformers-main/examples/research_projects/bertabs/__init__.py  \n",
            "  inflating: transformers-main/examples/research_projects/bertology/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/bertology/run_bertology.py  \n",
            "  inflating: transformers-main/examples/research_projects/bertology/run_prune_gpt.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/examples/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/examples/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/examples/train_complexity_predictor.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/scripts/arguments.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/scripts/bpe_training.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/scripts/codeparrot_training.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/scripts/human_eval.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/scripts/initialize_model.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/scripts/minhash_deduplication.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/scripts/preprocessing.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/scripts/pretokenizing.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/scripts/tests/test_deduplicate.py  \n",
            " extracting: transformers-main/examples/research_projects/codeparrot/scripts/tests/__init__.py  \n",
            "  inflating: transformers-main/examples/research_projects/codeparrot/scripts/validation_loss.py  \n",
            "  inflating: transformers-main/examples/research_projects/decision_transformer/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/decision_transformer/run_decision_transformer.py  \n",
            "  inflating: transformers-main/examples/research_projects/deebert/entropy_eval.sh  \n",
            "  inflating: transformers-main/examples/research_projects/deebert/eval_deebert.sh  \n",
            "  inflating: transformers-main/examples/research_projects/deebert/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/deebert/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/deebert/run_glue_deebert.py  \n",
            "  inflating: transformers-main/examples/research_projects/deebert/src/modeling_highway_bert.py  \n",
            "  inflating: transformers-main/examples/research_projects/deebert/src/modeling_highway_roberta.py  \n",
            " extracting: transformers-main/examples/research_projects/deebert/src/__init__.py  \n",
            "  inflating: transformers-main/examples/research_projects/deebert/test_glue_deebert.py  \n",
            "  inflating: transformers-main/examples/research_projects/deebert/train_deebert.sh  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/distiller.py  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/grouped_batch_sampler.py  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/lm_seqs_dataset.py  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/run_squad_w_distillation.py  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/scripts/binarized_data.py  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/scripts/extract.py  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/scripts/extract_distilbert.py  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/scripts/token_counts.py  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/train.py  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/training_configs/distilbert-base-cased.json  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/training_configs/distilbert-base-multilingual-cased.json  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/training_configs/distilbert-base-uncased.json  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/training_configs/distilgpt2.json  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/training_configs/distilroberta-base.json  \n",
            "  inflating: transformers-main/examples/research_projects/distillation/utils.py  \n",
            "  inflating: transformers-main/examples/research_projects/fsner/pyproject.toml  \n",
            "  inflating: transformers-main/examples/research_projects/fsner/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/fsner/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/fsner/setup.py  \n",
            "  inflating: transformers-main/examples/research_projects/fsner/src/fsner/model.py  \n",
            "  inflating: transformers-main/examples/research_projects/fsner/src/fsner/tokenizer_utils.py  \n",
            "  inflating: transformers-main/examples/research_projects/fsner/src/fsner/__init__.py  \n",
            "  inflating: transformers-main/examples/research_projects/information-gain-filtration/igf/igf.py  \n",
            " extracting: transformers-main/examples/research_projects/information-gain-filtration/igf/__init__.py  \n",
            "  inflating: transformers-main/examples/research_projects/information-gain-filtration/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/information-gain-filtration/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/information-gain-filtration/result_igf.png  \n",
            "  inflating: transformers-main/examples/research_projects/information-gain-filtration/run_clm_igf.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/big_bird/bigbird_flax.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/big_bird/evaluate.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/big_bird/prepare_natural_questions.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/big_bird/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/big_bird/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/big_bird/sweep_flax.yaml  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/big_bird/train.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/dataset-streaming/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/dataset-streaming/run_mlm_flax_stream.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/HOW_TO_PROPOSE_PROJECT.md  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/hybrid_clip/configuration_hybrid_clip.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/hybrid_clip/modeling_hybrid_clip.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/hybrid_clip/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/hybrid_clip/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/hybrid_clip/run_hybrid_clip.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/model_parallel/partitions.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/model_parallel/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/model_parallel/run_clm_mp.py  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/wav2vec2/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/jax-projects/wav2vec2/run_wav2vec2_pretrain_flax.py  \n",
            "  inflating: transformers-main/examples/research_projects/layoutlmv3/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/layoutlmv3/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/layoutlmv3/run_funsd_cord.py  \n",
            "  inflating: transformers-main/examples/research_projects/longform-qa/eli5_app.py  \n",
            "  inflating: transformers-main/examples/research_projects/longform-qa/eli5_utils.py  \n",
            "  inflating: transformers-main/examples/research_projects/longform-qa/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/longform-qa/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/luke/luke_utils.py  \n",
            "  inflating: transformers-main/examples/research_projects/luke/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/luke/run_luke_ner_no_trainer.py  \n",
            "  inflating: transformers-main/examples/research_projects/lxmert/demo.ipynb  \n",
            "  inflating: transformers-main/examples/research_projects/lxmert/extracting_data.py  \n",
            "  inflating: transformers-main/examples/research_projects/lxmert/modeling_frcnn.py  \n",
            "  inflating: transformers-main/examples/research_projects/lxmert/processing_image.py  \n",
            "  inflating: transformers-main/examples/research_projects/lxmert/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/lxmert/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/lxmert/utils.py  \n",
            "  inflating: transformers-main/examples/research_projects/lxmert/visualizing_image.py  \n",
            "  inflating: transformers-main/examples/research_projects/mlm_wwm/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/mlm_wwm/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/mlm_wwm/run_chinese_ref.py  \n",
            "  inflating: transformers-main/examples/research_projects/mlm_wwm/run_mlm_wwm.py  \n",
            "  inflating: transformers-main/examples/research_projects/mm-imdb/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/mm-imdb/run_mmimdb.py  \n",
            "  inflating: transformers-main/examples/research_projects/mm-imdb/utils_mmimdb.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/bertarize.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/counts_parameters.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/emmental/configuration_bert_masked.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/emmental/modeling_bert_masked.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/emmental/modules/binarizer.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/emmental/modules/masked_nn.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/emmental/modules/__init__.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/emmental/__init__.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/masked_run_glue.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/masked_run_squad.py  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/movement-pruning/Saving_PruneBERT.ipynb  \n",
            "  inflating: transformers-main/examples/research_projects/onnx/summarization/bart_onnx/generation_onnx.py  \n",
            "  inflating: transformers-main/examples/research_projects/onnx/summarization/bart_onnx/reduce_onnx_size.py  \n",
            "  inflating: transformers-main/examples/research_projects/onnx/summarization/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/onnx/summarization/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/onnx/summarization/run_onnx_exporter.py  \n",
            "  inflating: transformers-main/examples/research_projects/performer/full_script.sh  \n",
            "  inflating: transformers-main/examples/research_projects/performer/modeling_flax_performer.py  \n",
            "  inflating: transformers-main/examples/research_projects/performer/modeling_flax_performer_utils.py  \n",
            "  inflating: transformers-main/examples/research_projects/performer/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/performer/run_mlm_performer.py  \n",
            "  inflating: transformers-main/examples/research_projects/performer/sanity_script.sh  \n",
            "  inflating: transformers-main/examples/research_projects/pplm/imgs/headfigure.png  \n",
            "  inflating: transformers-main/examples/research_projects/pplm/imgs/wooly.png  \n",
            "  inflating: transformers-main/examples/research_projects/pplm/pplm_classification_head.py  \n",
            "  inflating: transformers-main/examples/research_projects/pplm/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/pplm/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/pplm/run_pplm.py  \n",
            "  inflating: transformers-main/examples/research_projects/pplm/run_pplm_discrim_train.py  \n",
            "  inflating: transformers-main/examples/research_projects/quantization-qdqbert/Dockerfile  \n",
            "  inflating: transformers-main/examples/research_projects/quantization-qdqbert/evaluate-hf-trt-qa.py  \n",
            "  inflating: transformers-main/examples/research_projects/quantization-qdqbert/ort-infer-benchmark.py  \n",
            "  inflating: transformers-main/examples/research_projects/quantization-qdqbert/quant_trainer.py  \n",
            "  inflating: transformers-main/examples/research_projects/quantization-qdqbert/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/quantization-qdqbert/run_quant_qa.py  \n",
            "  inflating: transformers-main/examples/research_projects/quantization-qdqbert/trainer_quant_qa.py  \n",
            "  inflating: transformers-main/examples/research_projects/quantization-qdqbert/utils_qa.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/callbacks_rag.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/consolidate_rag_checkpoint.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/distributed_pytorch_retriever.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/distributed_ray_retriever.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/eval_rag.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/finetune_rag.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/finetune_rag.sh  \n",
            "  inflating: transformers-main/examples/research_projects/rag/finetune_rag_ray.sh  \n",
            "  inflating: transformers-main/examples/research_projects/rag/lightning_base.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/parse_dpr_relevance_data.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/rag/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/rag/test_data/my_knowledge_dataset.csv  \n",
            "  inflating: transformers-main/examples/research_projects/rag/test_distributed_retriever.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/use_own_knowledge_dataset.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/utils_rag.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/_test_finetune_rag.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag/__init__.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/callbacks_rag.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/distributed_ray_retriever.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/eval_rag.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/finetune_rag.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/finetune_rag_ray_end2end.sh  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/kb_encode_utils.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/lightning_base.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/test_run/dummy-kb/my_knowledge_dataset.csv  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/test_run/dummy-train-data/train.source  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/test_run/dummy-train-data/train.target  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/test_run/dummy-train-data/val.source  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/test_run/dummy-train-data/val.target  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/test_run/test_finetune.sh  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/test_run/test_rag_new_features.sh  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/use_own_knowledge_dataset.py  \n",
            "  inflating: transformers-main/examples/research_projects/rag-end2end-retriever/utils_rag.py  \n",
            "  inflating: transformers-main/examples/research_projects/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/robust-speech-event/eval.py  \n",
            "  inflating: transformers-main/examples/research_projects/robust-speech-event/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/robust-speech-event/run_speech_recognition_ctc_bnb.py  \n",
            "  inflating: transformers-main/examples/research_projects/robust-speech-event/run_speech_recognition_ctc_streaming.py  \n",
            "  inflating: transformers-main/examples/research_projects/self-training-text-classification/finetuning.py  \n",
            "  inflating: transformers-main/examples/research_projects/self-training-text-classification/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/self-training-text-classification/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/self-training-text-classification/run.sh  \n",
            "  inflating: transformers-main/examples/research_projects/self-training-text-classification/selftraining.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/callbacks.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/convert_pl_checkpoint_to_hf.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/distillation.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/distil_marian_enro_teacher.sh  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/distil_marian_no_teacher.sh  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/dynamic_bs_example.sh  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/finetune.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/finetune.sh  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/finetune_bart_tiny.sh  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/finetune_pegasus_xsum.sh  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/finetune_t5.sh  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/lightning_base.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/make_student.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/precomputed_pseudo_labels.md  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/run_eval.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/sentence_splitter.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/train_distilbart_cnn.sh  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/train_distilbart_xsum.sh  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/train_mbart_cc25_enro.sh  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/utils.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/_test_bash_script.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/_test_make_student.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/_test_seq2seq_examples.py  \n",
            "  inflating: transformers-main/examples/research_projects/seq2seq-distillation/_test_seq2seq_examples_multi_gpu.py  \n",
            "  inflating: transformers-main/examples/research_projects/tapex/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/tapex/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/tapex/run_tabfact_with_tapex.py  \n",
            "  inflating: transformers-main/examples/research_projects/tapex/run_wikisql_with_tapex.py  \n",
            "  inflating: transformers-main/examples/research_projects/tapex/run_wikitablequestions_with_tapex.py  \n",
            "  inflating: transformers-main/examples/research_projects/tapex/wikisql_utils.py  \n",
            "  inflating: transformers-main/examples/research_projects/visual_bert/demo.ipynb  \n",
            "  inflating: transformers-main/examples/research_projects/visual_bert/extracting_data.py  \n",
            "  inflating: transformers-main/examples/research_projects/visual_bert/modeling_frcnn.py  \n",
            "  inflating: transformers-main/examples/research_projects/visual_bert/processing_image.py  \n",
            "  inflating: transformers-main/examples/research_projects/visual_bert/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/visual_bert/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/visual_bert/utils.py  \n",
            "  inflating: transformers-main/examples/research_projects/visual_bert/visualizing_image.py  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/alignment.py  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/ds_config_wav2vec2_zero2.json  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/ds_config_wav2vec2_zero3.json  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/finetune_base_100.sh  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/finetune_base_timit_asr.sh  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/finetune_large_lv60_100.sh  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/finetune_large_lv60_timit_asr.sh  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/finetune_large_xlsr_53_arabic_speech_corpus.sh  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/finetune_wav2vec2_xlsr_turkish.sh  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/FINE_TUNE_XLSR_WAV2VEC2.md  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/run_alignment.sh  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/run_asr.py  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/run_common_voice.py  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/run_pretrain.py  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/test_wav2vec2_deepspeed.py  \n",
            "  inflating: transformers-main/examples/research_projects/wav2vec2/vocab/buckwalter.json  \n",
            "  inflating: transformers-main/examples/research_projects/xtreme-s/README.md  \n",
            "  inflating: transformers-main/examples/research_projects/xtreme-s/requirements.txt  \n",
            "  inflating: transformers-main/examples/research_projects/xtreme-s/run_xtreme_s.py  \n",
            "  inflating: transformers-main/examples/research_projects/zero-shot-distillation/distill_classifier.py  \n",
            "  inflating: transformers-main/examples/research_projects/zero-shot-distillation/README.md  \n",
            "  inflating: transformers-main/examples/tensorflow/benchmarking/plot_csv_file.py  \n",
            "  inflating: transformers-main/examples/tensorflow/benchmarking/README.md  \n",
            "  inflating: transformers-main/examples/tensorflow/benchmarking/requirements.txt  \n",
            "  inflating: transformers-main/examples/tensorflow/benchmarking/run_benchmark_tf.py  \n",
            "  inflating: transformers-main/examples/tensorflow/language-modeling/README.md  \n",
            "  inflating: transformers-main/examples/tensorflow/language-modeling/requirements.txt  \n",
            "  inflating: transformers-main/examples/tensorflow/language-modeling/run_clm.py  \n",
            "  inflating: transformers-main/examples/tensorflow/language-modeling/run_mlm.py  \n",
            "  inflating: transformers-main/examples/tensorflow/multiple-choice/README.md  \n",
            "  inflating: transformers-main/examples/tensorflow/multiple-choice/requirements.txt  \n",
            "  inflating: transformers-main/examples/tensorflow/multiple-choice/run_swag.py  \n",
            "  inflating: transformers-main/examples/tensorflow/question-answering/README.md  \n",
            "  inflating: transformers-main/examples/tensorflow/question-answering/requirements.txt  \n",
            "  inflating: transformers-main/examples/tensorflow/question-answering/run_qa.py  \n",
            "  inflating: transformers-main/examples/tensorflow/question-answering/utils_qa.py  \n",
            "  inflating: transformers-main/examples/tensorflow/README.md  \n",
            "  inflating: transformers-main/examples/tensorflow/summarization/README.md  \n",
            "  inflating: transformers-main/examples/tensorflow/summarization/requirements.txt  \n",
            "  inflating: transformers-main/examples/tensorflow/summarization/run_summarization.py  \n",
            "  inflating: transformers-main/examples/tensorflow/test_tensorflow_examples.py  \n",
            "  inflating: transformers-main/examples/tensorflow/text-classification/README.md  \n",
            "  inflating: transformers-main/examples/tensorflow/text-classification/requirements.txt  \n",
            "  inflating: transformers-main/examples/tensorflow/text-classification/run_glue.py  \n",
            "  inflating: transformers-main/examples/tensorflow/text-classification/run_text_classification.py  \n",
            "  inflating: transformers-main/examples/tensorflow/token-classification/README.md  \n",
            "  inflating: transformers-main/examples/tensorflow/token-classification/requirements.txt  \n",
            "  inflating: transformers-main/examples/tensorflow/token-classification/run_ner.py  \n",
            "  inflating: transformers-main/examples/tensorflow/translation/README.md  \n",
            "  inflating: transformers-main/examples/tensorflow/translation/requirements.txt  \n",
            "  inflating: transformers-main/examples/tensorflow/translation/run_translation.py  \n",
            "  inflating: transformers-main/examples/tensorflow/_tests_requirements.txt  \n",
            "  inflating: transformers-main/hubconf.py  \n",
            "  inflating: transformers-main/ISSUES.md  \n",
            "  inflating: transformers-main/LICENSE  \n",
            "  inflating: transformers-main/Makefile  \n",
            "  inflating: transformers-main/MANIFEST.in  \n",
            "  inflating: transformers-main/model_cards/README.md  \n",
            "  inflating: transformers-main/notebooks/README.md  \n",
            "  inflating: transformers-main/pyproject.toml  \n",
            "  inflating: transformers-main/README.md  \n",
            "  inflating: transformers-main/README_es.md  \n",
            "  inflating: transformers-main/README_ko.md  \n",
            "  inflating: transformers-main/README_zh-hans.md  \n",
            "  inflating: transformers-main/README_zh-hant.md  \n",
            "  inflating: transformers-main/scripts/benchmark/trainer-benchmark.py  \n",
            "  inflating: transformers-main/scripts/check_tokenizers.py  \n",
            "  inflating: transformers-main/scripts/distributed/torch-distributed-gpu-test.py  \n",
            "  inflating: transformers-main/scripts/fsmt/convert-allenai-wmt16.sh  \n",
            "  inflating: transformers-main/scripts/fsmt/convert-allenai-wmt19.sh  \n",
            "  inflating: transformers-main/scripts/fsmt/convert-facebook-wmt19.sh  \n",
            "  inflating: transformers-main/scripts/fsmt/eval-allenai-wmt16.sh  \n",
            "  inflating: transformers-main/scripts/fsmt/eval-allenai-wmt19.sh  \n",
            "  inflating: transformers-main/scripts/fsmt/eval-facebook-wmt19.sh  \n",
            "  inflating: transformers-main/scripts/fsmt/fsmt-make-super-tiny-model.py  \n",
            "  inflating: transformers-main/scripts/fsmt/fsmt-make-tiny-model.py  \n",
            "  inflating: transformers-main/scripts/fsmt/gen-card-allenai-wmt16.py  \n",
            "  inflating: transformers-main/scripts/fsmt/gen-card-allenai-wmt19.py  \n",
            "  inflating: transformers-main/scripts/fsmt/gen-card-facebook-wmt19.py  \n",
            "  inflating: transformers-main/scripts/fsmt/s3-move.sh  \n",
            "  inflating: transformers-main/scripts/fsmt/tests-to-run.sh  \n",
            "  inflating: transformers-main/scripts/pegasus/build_test_sample_spm_no_bos.py  \n",
            "  inflating: transformers-main/scripts/stale.py  \n",
            "  inflating: transformers-main/scripts/tatoeba/README.md  \n",
            "  inflating: transformers-main/scripts/tatoeba/upload_models.sh  \n",
            "  inflating: transformers-main/setup.cfg  \n",
            "  inflating: transformers-main/setup.py  \n",
            "  inflating: transformers-main/src/transformers/activations.py  \n",
            "  inflating: transformers-main/src/transformers/activations_tf.py  \n",
            "  inflating: transformers-main/src/transformers/benchmark/benchmark.py  \n",
            "  inflating: transformers-main/src/transformers/benchmark/benchmark_args.py  \n",
            "  inflating: transformers-main/src/transformers/benchmark/benchmark_args_tf.py  \n",
            "  inflating: transformers-main/src/transformers/benchmark/benchmark_args_utils.py  \n",
            "  inflating: transformers-main/src/transformers/benchmark/benchmark_tf.py  \n",
            "  inflating: transformers-main/src/transformers/benchmark/benchmark_utils.py  \n",
            " extracting: transformers-main/src/transformers/benchmark/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/commands/add_new_model.py  \n",
            "  inflating: transformers-main/src/transformers/commands/add_new_model_like.py  \n",
            "  inflating: transformers-main/src/transformers/commands/convert.py  \n",
            "  inflating: transformers-main/src/transformers/commands/download.py  \n",
            "  inflating: transformers-main/src/transformers/commands/env.py  \n",
            "  inflating: transformers-main/src/transformers/commands/lfs.py  \n",
            "  inflating: transformers-main/src/transformers/commands/pt_to_tf.py  \n",
            "  inflating: transformers-main/src/transformers/commands/run.py  \n",
            "  inflating: transformers-main/src/transformers/commands/serving.py  \n",
            "  inflating: transformers-main/src/transformers/commands/train.py  \n",
            "  inflating: transformers-main/src/transformers/commands/transformers_cli.py  \n",
            "  inflating: transformers-main/src/transformers/commands/user.py  \n",
            "  inflating: transformers-main/src/transformers/commands/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/configuration_utils.py  \n",
            "  inflating: transformers-main/src/transformers/convert_graph_to_onnx.py  \n",
            "  inflating: transformers-main/src/transformers/convert_pytorch_checkpoint_to_tf2.py  \n",
            "  inflating: transformers-main/src/transformers/convert_slow_tokenizer.py  \n",
            "  inflating: transformers-main/src/transformers/convert_slow_tokenizers_checkpoints_to_fast.py  \n",
            "  inflating: transformers-main/src/transformers/convert_tf_hub_seq_to_seq_bert_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/data/datasets/glue.py  \n",
            "  inflating: transformers-main/src/transformers/data/datasets/language_modeling.py  \n",
            "  inflating: transformers-main/src/transformers/data/datasets/squad.py  \n",
            "  inflating: transformers-main/src/transformers/data/datasets/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/data/data_collator.py  \n",
            "  inflating: transformers-main/src/transformers/data/metrics/squad_metrics.py  \n",
            "  inflating: transformers-main/src/transformers/data/metrics/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/data/processors/glue.py  \n",
            "  inflating: transformers-main/src/transformers/data/processors/squad.py  \n",
            "  inflating: transformers-main/src/transformers/data/processors/utils.py  \n",
            "  inflating: transformers-main/src/transformers/data/processors/xnli.py  \n",
            "  inflating: transformers-main/src/transformers/data/processors/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/data/test_generation_utils.py  \n",
            "  inflating: transformers-main/src/transformers/data/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/debug_utils.py  \n",
            "  inflating: transformers-main/src/transformers/deepspeed.py  \n",
            "  inflating: transformers-main/src/transformers/dependency_versions_check.py  \n",
            "  inflating: transformers-main/src/transformers/dependency_versions_table.py  \n",
            "  inflating: transformers-main/src/transformers/dynamic_module_utils.py  \n",
            "  inflating: transformers-main/src/transformers/feature_extraction_sequence_utils.py  \n",
            "  inflating: transformers-main/src/transformers/feature_extraction_utils.py  \n",
            "  inflating: transformers-main/src/transformers/file_utils.py  \n",
            "  inflating: transformers-main/src/transformers/generation_beam_constraints.py  \n",
            "  inflating: transformers-main/src/transformers/generation_beam_search.py  \n",
            "  inflating: transformers-main/src/transformers/generation_flax_logits_process.py  \n",
            "  inflating: transformers-main/src/transformers/generation_flax_utils.py  \n",
            "  inflating: transformers-main/src/transformers/generation_logits_process.py  \n",
            "  inflating: transformers-main/src/transformers/generation_stopping_criteria.py  \n",
            "  inflating: transformers-main/src/transformers/generation_tf_logits_process.py  \n",
            "  inflating: transformers-main/src/transformers/generation_tf_utils.py  \n",
            "  inflating: transformers-main/src/transformers/generation_utils.py  \n",
            "  inflating: transformers-main/src/transformers/hf_argparser.py  \n",
            "  inflating: transformers-main/src/transformers/image_processing_utils.py  \n",
            "  inflating: transformers-main/src/transformers/image_transforms.py  \n",
            "  inflating: transformers-main/src/transformers/image_utils.py  \n",
            "  inflating: transformers-main/src/transformers/integrations.py  \n",
            "  inflating: transformers-main/src/transformers/keras_callbacks.py  \n",
            "  inflating: transformers-main/src/transformers/modelcard.py  \n",
            "  inflating: transformers-main/src/transformers/modeling_flax_outputs.py  \n",
            "  inflating: transformers-main/src/transformers/modeling_flax_pytorch_utils.py  \n",
            "  inflating: transformers-main/src/transformers/modeling_flax_utils.py  \n",
            "  inflating: transformers-main/src/transformers/modeling_outputs.py  \n",
            "  inflating: transformers-main/src/transformers/modeling_tf_outputs.py  \n",
            "  inflating: transformers-main/src/transformers/modeling_tf_pytorch_utils.py  \n",
            "  inflating: transformers-main/src/transformers/modeling_tf_utils.py  \n",
            "  inflating: transformers-main/src/transformers/modeling_utils.py  \n",
            "  inflating: transformers-main/src/transformers/models/albert/configuration_albert.py  \n",
            "  inflating: transformers-main/src/transformers/models/albert/convert_albert_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/albert/modeling_albert.py  \n",
            "  inflating: transformers-main/src/transformers/models/albert/modeling_flax_albert.py  \n",
            "  inflating: transformers-main/src/transformers/models/albert/modeling_tf_albert.py  \n",
            "  inflating: transformers-main/src/transformers/models/albert/tokenization_albert.py  \n",
            "  inflating: transformers-main/src/transformers/models/albert/tokenization_albert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/albert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/auto/auto_factory.py  \n",
            "  inflating: transformers-main/src/transformers/models/auto/configuration_auto.py  \n",
            "  inflating: transformers-main/src/transformers/models/auto/feature_extraction_auto.py  \n",
            "  inflating: transformers-main/src/transformers/models/auto/modeling_auto.py  \n",
            "  inflating: transformers-main/src/transformers/models/auto/modeling_flax_auto.py  \n",
            "  inflating: transformers-main/src/transformers/models/auto/modeling_tf_auto.py  \n",
            "  inflating: transformers-main/src/transformers/models/auto/processing_auto.py  \n",
            "  inflating: transformers-main/src/transformers/models/auto/tokenization_auto.py  \n",
            "  inflating: transformers-main/src/transformers/models/auto/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/bart/configuration_bart.py  \n",
            "  inflating: transformers-main/src/transformers/models/bart/convert_bart_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/bart/modeling_bart.py  \n",
            "  inflating: transformers-main/src/transformers/models/bart/modeling_flax_bart.py  \n",
            "  inflating: transformers-main/src/transformers/models/bart/modeling_tf_bart.py  \n",
            "  inflating: transformers-main/src/transformers/models/bart/tokenization_bart.py  \n",
            "  inflating: transformers-main/src/transformers/models/bart/tokenization_bart_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/bart/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/barthez/tokenization_barthez.py  \n",
            "  inflating: transformers-main/src/transformers/models/barthez/tokenization_barthez_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/barthez/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/bartpho/tokenization_bartpho.py  \n",
            "  inflating: transformers-main/src/transformers/models/bartpho/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/beit/configuration_beit.py  \n",
            "  inflating: transformers-main/src/transformers/models/beit/convert_beit_unilm_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/beit/feature_extraction_beit.py  \n",
            "  inflating: transformers-main/src/transformers/models/beit/modeling_beit.py  \n",
            "  inflating: transformers-main/src/transformers/models/beit/modeling_flax_beit.py  \n",
            "  inflating: transformers-main/src/transformers/models/beit/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/configuration_bert.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/convert_bert_original_tf2_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/convert_bert_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/convert_bert_pytorch_checkpoint_to_original_tf.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/convert_bert_token_dropping_original_tf2_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/modeling_bert.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/modeling_flax_bert.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/modeling_tf_bert.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/tokenization_bert.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/tokenization_bert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/tokenization_bert_tf.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/bertweet/tokenization_bertweet.py  \n",
            "  inflating: transformers-main/src/transformers/models/bertweet/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert_generation/configuration_bert_generation.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert_generation/modeling_bert_generation.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert_generation/tokenization_bert_generation.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert_generation/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert_japanese/tokenization_bert_japanese.py  \n",
            "  inflating: transformers-main/src/transformers/models/bert_japanese/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py  \n",
            "  inflating: transformers-main/src/transformers/models/bigbird_pegasus/convert_bigbird_pegasus_tf_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py  \n",
            "  inflating: transformers-main/src/transformers/models/bigbird_pegasus/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/big_bird/configuration_big_bird.py  \n",
            "  inflating: transformers-main/src/transformers/models/big_bird/convert_bigbird_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/big_bird/modeling_big_bird.py  \n",
            "  inflating: transformers-main/src/transformers/models/big_bird/modeling_flax_big_bird.py  \n",
            "  inflating: transformers-main/src/transformers/models/big_bird/tokenization_big_bird.py  \n",
            "  inflating: transformers-main/src/transformers/models/big_bird/tokenization_big_bird_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/big_bird/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot/configuration_blenderbot.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot/convert_blenderbot_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot/modeling_blenderbot.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot/modeling_flax_blenderbot.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot/modeling_tf_blenderbot.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot/tokenization_blenderbot.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot/tokenization_blenderbot_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot_small/configuration_blenderbot_small.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot_small/modeling_blenderbot_small.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot_small/tokenization_blenderbot_small_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/blenderbot_small/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/bloom/configuration_bloom.py  \n",
            "  inflating: transformers-main/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/bloom/modeling_bloom.py  \n",
            "  inflating: transformers-main/src/transformers/models/bloom/tokenization_bloom_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/bloom/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/bort/convert_bort_original_gluonnlp_checkpoint_to_pytorch.py  \n",
            " extracting: transformers-main/src/transformers/models/bort/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/byt5/convert_byt5_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/byt5/tokenization_byt5.py  \n",
            "  inflating: transformers-main/src/transformers/models/byt5/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/camembert/configuration_camembert.py  \n",
            "  inflating: transformers-main/src/transformers/models/camembert/modeling_camembert.py  \n",
            "  inflating: transformers-main/src/transformers/models/camembert/modeling_tf_camembert.py  \n",
            "  inflating: transformers-main/src/transformers/models/camembert/tokenization_camembert.py  \n",
            "  inflating: transformers-main/src/transformers/models/camembert/tokenization_camembert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/camembert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/canine/configuration_canine.py  \n",
            "  inflating: transformers-main/src/transformers/models/canine/convert_canine_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/canine/modeling_canine.py  \n",
            "  inflating: transformers-main/src/transformers/models/canine/tokenization_canine.py  \n",
            "  inflating: transformers-main/src/transformers/models/canine/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/clip/configuration_clip.py  \n",
            "  inflating: transformers-main/src/transformers/models/clip/convert_clip_original_pytorch_to_hf.py  \n",
            "  inflating: transformers-main/src/transformers/models/clip/feature_extraction_clip.py  \n",
            "  inflating: transformers-main/src/transformers/models/clip/modeling_clip.py  \n",
            "  inflating: transformers-main/src/transformers/models/clip/modeling_flax_clip.py  \n",
            "  inflating: transformers-main/src/transformers/models/clip/modeling_tf_clip.py  \n",
            "  inflating: transformers-main/src/transformers/models/clip/processing_clip.py  \n",
            "  inflating: transformers-main/src/transformers/models/clip/tokenization_clip.py  \n",
            "  inflating: transformers-main/src/transformers/models/clip/tokenization_clip_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/clip/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/codegen/configuration_codegen.py  \n",
            "  inflating: transformers-main/src/transformers/models/codegen/modeling_codegen.py  \n",
            "  inflating: transformers-main/src/transformers/models/codegen/tokenization_codegen.py  \n",
            "  inflating: transformers-main/src/transformers/models/codegen/tokenization_codegen_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/codegen/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/conditional_detr/configuration_conditional_detr.py  \n",
            "  inflating: transformers-main/src/transformers/models/conditional_detr/convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/conditional_detr/feature_extraction_conditional_detr.py  \n",
            "  inflating: transformers-main/src/transformers/models/conditional_detr/modeling_conditional_detr.py  \n",
            "  inflating: transformers-main/src/transformers/models/conditional_detr/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/convbert/configuration_convbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/convbert/convert_convbert_original_tf1_checkpoint_to_pytorch_and_tf2.py  \n",
            "  inflating: transformers-main/src/transformers/models/convbert/modeling_convbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/convbert/modeling_tf_convbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/convbert/tokenization_convbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/convbert/tokenization_convbert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/convbert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/convnext/configuration_convnext.py  \n",
            "  inflating: transformers-main/src/transformers/models/convnext/convert_convnext_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/convnext/feature_extraction_convnext.py  \n",
            "  inflating: transformers-main/src/transformers/models/convnext/modeling_convnext.py  \n",
            "  inflating: transformers-main/src/transformers/models/convnext/modeling_tf_convnext.py  \n",
            "  inflating: transformers-main/src/transformers/models/convnext/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/cpm/tokenization_cpm.py  \n",
            "  inflating: transformers-main/src/transformers/models/cpm/tokenization_cpm_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/cpm/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/ctrl/configuration_ctrl.py  \n",
            "  inflating: transformers-main/src/transformers/models/ctrl/modeling_ctrl.py  \n",
            "  inflating: transformers-main/src/transformers/models/ctrl/modeling_tf_ctrl.py  \n",
            "  inflating: transformers-main/src/transformers/models/ctrl/tokenization_ctrl.py  \n",
            "  inflating: transformers-main/src/transformers/models/ctrl/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/cvt/configuration_cvt.py  \n",
            "  inflating: transformers-main/src/transformers/models/cvt/convert_cvt_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/cvt/modeling_cvt.py  \n",
            "  inflating: transformers-main/src/transformers/models/cvt/modeling_tf_cvt.py  \n",
            "  inflating: transformers-main/src/transformers/models/cvt/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/configuration_data2vec_audio.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/configuration_data2vec_text.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/configuration_data2vec_vision.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/convert_data2vec_audio_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/convert_data2vec_text_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/modeling_data2vec_audio.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/modeling_data2vec_text.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/modeling_data2vec_vision.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/modeling_tf_data2vec_vision.py  \n",
            "  inflating: transformers-main/src/transformers/models/data2vec/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta/configuration_deberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta/modeling_deberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta/modeling_tf_deberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta/tokenization_deberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta/tokenization_deberta_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta_v2/configuration_deberta_v2.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta_v2/modeling_deberta_v2.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta_v2/modeling_tf_deberta_v2.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta_v2/tokenization_deberta_v2.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta_v2/tokenization_deberta_v2_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/deberta_v2/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/decision_transformer/configuration_decision_transformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/decision_transformer/modeling_decision_transformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/decision_transformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/configuration_deformable_detr.py  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/custom_kernel/cpu/ms_deform_attn_cpu.cpp  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/custom_kernel/cpu/ms_deform_attn_cpu.h  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/custom_kernel/cuda/ms_deform_attn_cuda.cu  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/custom_kernel/cuda/ms_deform_attn_cuda.cuh  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/custom_kernel/cuda/ms_deform_attn_cuda.h  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/custom_kernel/cuda/ms_deform_im2col_cuda.cuh  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/custom_kernel/ms_deform_attn.h  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/custom_kernel/vision.cpp  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/feature_extraction_deformable_detr.py  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/load_custom.py  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/modeling_deformable_detr.py  \n",
            "  inflating: transformers-main/src/transformers/models/deformable_detr/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/deit/configuration_deit.py  \n",
            "  inflating: transformers-main/src/transformers/models/deit/convert_deit_timm_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/deit/feature_extraction_deit.py  \n",
            "  inflating: transformers-main/src/transformers/models/deit/modeling_deit.py  \n",
            "  inflating: transformers-main/src/transformers/models/deit/modeling_tf_deit.py  \n",
            "  inflating: transformers-main/src/transformers/models/deit/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/detr/configuration_detr.py  \n",
            "  inflating: transformers-main/src/transformers/models/detr/convert_detr_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/detr/feature_extraction_detr.py  \n",
            "  inflating: transformers-main/src/transformers/models/detr/modeling_detr.py  \n",
            "  inflating: transformers-main/src/transformers/models/detr/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/dialogpt/convert_dialogpt_original_pytorch_checkpoint_to_pytorch.py  \n",
            " extracting: transformers-main/src/transformers/models/dialogpt/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/distilbert/configuration_distilbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/distilbert/modeling_distilbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/distilbert/modeling_flax_distilbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/distilbert/modeling_tf_distilbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/distilbert/tokenization_distilbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/distilbert/tokenization_distilbert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/distilbert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/dit/convert_dit_unilm_to_pytorch.py  \n",
            " extracting: transformers-main/src/transformers/models/dit/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/donut/configuration_donut_swin.py  \n",
            "  inflating: transformers-main/src/transformers/models/donut/convert_donut_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/donut/feature_extraction_donut.py  \n",
            "  inflating: transformers-main/src/transformers/models/donut/modeling_donut_swin.py  \n",
            "  inflating: transformers-main/src/transformers/models/donut/processing_donut.py  \n",
            "  inflating: transformers-main/src/transformers/models/donut/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpr/configuration_dpr.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpr/convert_dpr_original_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpr/modeling_dpr.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpr/modeling_tf_dpr.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpr/tokenization_dpr.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpr/tokenization_dpr_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpr/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpt/configuration_dpt.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpt/convert_dpt_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpt/feature_extraction_dpt.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpt/modeling_dpt.py  \n",
            "  inflating: transformers-main/src/transformers/models/dpt/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/electra/configuration_electra.py  \n",
            "  inflating: transformers-main/src/transformers/models/electra/convert_electra_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/electra/modeling_electra.py  \n",
            "  inflating: transformers-main/src/transformers/models/electra/modeling_flax_electra.py  \n",
            "  inflating: transformers-main/src/transformers/models/electra/modeling_tf_electra.py  \n",
            "  inflating: transformers-main/src/transformers/models/electra/tokenization_electra.py  \n",
            "  inflating: transformers-main/src/transformers/models/electra/tokenization_electra_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/electra/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/encoder_decoder/configuration_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/encoder_decoder/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/ernie/configuration_ernie.py  \n",
            "  inflating: transformers-main/src/transformers/models/ernie/modeling_ernie.py  \n",
            "  inflating: transformers-main/src/transformers/models/ernie/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/esm/configuration_esm.py  \n",
            "  inflating: transformers-main/src/transformers/models/esm/convert_esm.py  \n",
            "  inflating: transformers-main/src/transformers/models/esm/modeling_esm.py  \n",
            "  inflating: transformers-main/src/transformers/models/esm/modeling_tf_esm.py  \n",
            "  inflating: transformers-main/src/transformers/models/esm/tokenization_esm.py  \n",
            "  inflating: transformers-main/src/transformers/models/esm/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/flaubert/configuration_flaubert.py  \n",
            "  inflating: transformers-main/src/transformers/models/flaubert/modeling_flaubert.py  \n",
            "  inflating: transformers-main/src/transformers/models/flaubert/modeling_tf_flaubert.py  \n",
            "  inflating: transformers-main/src/transformers/models/flaubert/tokenization_flaubert.py  \n",
            "  inflating: transformers-main/src/transformers/models/flaubert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/flava/configuration_flava.py  \n",
            "  inflating: transformers-main/src/transformers/models/flava/convert_dalle_to_flava_codebook.py  \n",
            "  inflating: transformers-main/src/transformers/models/flava/convert_flava_original_pytorch_to_hf.py  \n",
            "  inflating: transformers-main/src/transformers/models/flava/feature_extraction_flava.py  \n",
            "  inflating: transformers-main/src/transformers/models/flava/modeling_flava.py  \n",
            "  inflating: transformers-main/src/transformers/models/flava/processing_flava.py  \n",
            "  inflating: transformers-main/src/transformers/models/flava/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/fnet/configuration_fnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/fnet/convert_fnet_original_flax_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/fnet/modeling_fnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/fnet/tokenization_fnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/fnet/tokenization_fnet_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/fnet/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/fsmt/configuration_fsmt.py  \n",
            "  inflating: transformers-main/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/fsmt/modeling_fsmt.py  \n",
            "  inflating: transformers-main/src/transformers/models/fsmt/tokenization_fsmt.py  \n",
            "  inflating: transformers-main/src/transformers/models/fsmt/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/funnel/configuration_funnel.py  \n",
            "  inflating: transformers-main/src/transformers/models/funnel/convert_funnel_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/funnel/modeling_funnel.py  \n",
            "  inflating: transformers-main/src/transformers/models/funnel/modeling_tf_funnel.py  \n",
            "  inflating: transformers-main/src/transformers/models/funnel/tokenization_funnel.py  \n",
            "  inflating: transformers-main/src/transformers/models/funnel/tokenization_funnel_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/funnel/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/glpn/configuration_glpn.py  \n",
            "  inflating: transformers-main/src/transformers/models/glpn/convert_glpn_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/glpn/feature_extraction_glpn.py  \n",
            "  inflating: transformers-main/src/transformers/models/glpn/image_processing_glpn.py  \n",
            "  inflating: transformers-main/src/transformers/models/glpn/modeling_glpn.py  \n",
            "  inflating: transformers-main/src/transformers/models/glpn/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt2/configuration_gpt2.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt2/modeling_flax_gpt2.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt2/modeling_gpt2.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt2/modeling_tf_gpt2.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt2/tokenization_gpt2.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt2/tokenization_gpt2_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt2/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/gptj/configuration_gptj.py  \n",
            "  inflating: transformers-main/src/transformers/models/gptj/modeling_flax_gptj.py  \n",
            "  inflating: transformers-main/src/transformers/models/gptj/modeling_gptj.py  \n",
            "  inflating: transformers-main/src/transformers/models/gptj/modeling_tf_gptj.py  \n",
            "  inflating: transformers-main/src/transformers/models/gptj/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neo/configuration_gpt_neo.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neo/convert_gpt_neo_mesh_tf_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neo/modeling_flax_gpt_neo.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neo/modeling_gpt_neo.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neo/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neox/configuration_gpt_neox.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neox/modeling_gpt_neox.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neox/tokenization_gpt_neox_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neox/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neox_japanese/configuration_gpt_neox_japanese.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py  \n",
            "  inflating: transformers-main/src/transformers/models/gpt_neox_japanese/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/groupvit/configuration_groupvit.py  \n",
            "  inflating: transformers-main/src/transformers/models/groupvit/convert_groupvit_nvlab_to_hf.py  \n",
            "  inflating: transformers-main/src/transformers/models/groupvit/modeling_groupvit.py  \n",
            "  inflating: transformers-main/src/transformers/models/groupvit/modeling_tf_groupvit.py  \n",
            "  inflating: transformers-main/src/transformers/models/groupvit/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/herbert/tokenization_herbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/herbert/tokenization_herbert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/herbert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/hubert/configuration_hubert.py  \n",
            "  inflating: transformers-main/src/transformers/models/hubert/convert_distilhubert_original_s3prl_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/hubert/convert_hubert_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/hubert/convert_hubert_original_s3prl_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/hubert/modeling_hubert.py  \n",
            "  inflating: transformers-main/src/transformers/models/hubert/modeling_tf_hubert.py  \n",
            "  inflating: transformers-main/src/transformers/models/hubert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/ibert/configuration_ibert.py  \n",
            "  inflating: transformers-main/src/transformers/models/ibert/modeling_ibert.py  \n",
            "  inflating: transformers-main/src/transformers/models/ibert/quant_modules.py  \n",
            "  inflating: transformers-main/src/transformers/models/ibert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/imagegpt/configuration_imagegpt.py  \n",
            "  inflating: transformers-main/src/transformers/models/imagegpt/convert_imagegpt_original_tf2_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/imagegpt/feature_extraction_imagegpt.py  \n",
            "  inflating: transformers-main/src/transformers/models/imagegpt/modeling_imagegpt.py  \n",
            "  inflating: transformers-main/src/transformers/models/imagegpt/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlm/configuration_layoutlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlm/modeling_layoutlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlm/modeling_tf_layoutlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlm/tokenization_layoutlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlm/tokenization_layoutlm_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlm/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv2/configuration_layoutlmv2.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv2/feature_extraction_layoutlmv2.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv2/processing_layoutlmv2.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv2/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv3/configuration_layoutlmv3.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv3/feature_extraction_layoutlmv3.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv3/processing_layoutlmv3.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutlmv3/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutxlm/processing_layoutxlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutxlm/tokenization_layoutxlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutxlm/tokenization_layoutxlm_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/layoutxlm/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/led/configuration_led.py  \n",
            "  inflating: transformers-main/src/transformers/models/led/modeling_led.py  \n",
            "  inflating: transformers-main/src/transformers/models/led/modeling_tf_led.py  \n",
            "  inflating: transformers-main/src/transformers/models/led/tokenization_led.py  \n",
            "  inflating: transformers-main/src/transformers/models/led/tokenization_led_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/led/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/levit/configuration_levit.py  \n",
            "  inflating: transformers-main/src/transformers/models/levit/convert_levit_timm_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/levit/feature_extraction_levit.py  \n",
            "  inflating: transformers-main/src/transformers/models/levit/modeling_levit.py  \n",
            "  inflating: transformers-main/src/transformers/models/levit/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/lilt/configuration_lilt.py  \n",
            "  inflating: transformers-main/src/transformers/models/lilt/modeling_lilt.py  \n",
            "  inflating: transformers-main/src/transformers/models/lilt/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/longformer/configuration_longformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/longformer/convert_longformer_original_pytorch_lightning_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/longformer/modeling_longformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/longformer/modeling_tf_longformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/longformer/tokenization_longformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/longformer/tokenization_longformer_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/longformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/longt5/configuration_longt5.py  \n",
            "  inflating: transformers-main/src/transformers/models/longt5/convert_longt5x_checkpoint_to_flax.py  \n",
            "  inflating: transformers-main/src/transformers/models/longt5/modeling_flax_longt5.py  \n",
            "  inflating: transformers-main/src/transformers/models/longt5/modeling_longt5.py  \n",
            "  inflating: transformers-main/src/transformers/models/longt5/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/luke/configuration_luke.py  \n",
            "  inflating: transformers-main/src/transformers/models/luke/convert_luke_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/luke/modeling_luke.py  \n",
            "  inflating: transformers-main/src/transformers/models/luke/tokenization_luke.py  \n",
            "  inflating: transformers-main/src/transformers/models/luke/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/lxmert/configuration_lxmert.py  \n",
            "  inflating: transformers-main/src/transformers/models/lxmert/convert_lxmert_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/lxmert/modeling_lxmert.py  \n",
            "  inflating: transformers-main/src/transformers/models/lxmert/modeling_tf_lxmert.py  \n",
            "  inflating: transformers-main/src/transformers/models/lxmert/tokenization_lxmert.py  \n",
            "  inflating: transformers-main/src/transformers/models/lxmert/tokenization_lxmert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/lxmert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/m2m_100/configuration_m2m_100.py  \n",
            "  inflating: transformers-main/src/transformers/models/m2m_100/convert_m2m100_original_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/m2m_100/modeling_m2m_100.py  \n",
            "  inflating: transformers-main/src/transformers/models/m2m_100/tokenization_m2m_100.py  \n",
            "  inflating: transformers-main/src/transformers/models/m2m_100/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/marian/configuration_marian.py  \n",
            "  inflating: transformers-main/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/marian/convert_marian_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/marian/modeling_flax_marian.py  \n",
            "  inflating: transformers-main/src/transformers/models/marian/modeling_marian.py  \n",
            "  inflating: transformers-main/src/transformers/models/marian/modeling_tf_marian.py  \n",
            "  inflating: transformers-main/src/transformers/models/marian/tokenization_marian.py  \n",
            "  inflating: transformers-main/src/transformers/models/marian/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/markuplm/configuration_markuplm.py  \n",
            "  inflating: transformers-main/src/transformers/models/markuplm/feature_extraction_markuplm.py  \n",
            "  inflating: transformers-main/src/transformers/models/markuplm/modeling_markuplm.py  \n",
            "  inflating: transformers-main/src/transformers/models/markuplm/processing_markuplm.py  \n",
            "  inflating: transformers-main/src/transformers/models/markuplm/tokenization_markuplm.py  \n",
            "  inflating: transformers-main/src/transformers/models/markuplm/tokenization_markuplm_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/markuplm/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/maskformer/configuration_maskformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/maskformer/convert_maskformer_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/maskformer/feature_extraction_maskformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/maskformer/modeling_maskformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/maskformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart/configuration_mbart.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart/convert_mbart_original_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart/modeling_flax_mbart.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart/modeling_mbart.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart/modeling_tf_mbart.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart/tokenization_mbart.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart/tokenization_mbart_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart50/tokenization_mbart50.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart50/tokenization_mbart50_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/mbart50/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/mctct/configuration_mctct.py  \n",
            "  inflating: transformers-main/src/transformers/models/mctct/feature_extraction_mctct.py  \n",
            "  inflating: transformers-main/src/transformers/models/mctct/modeling_mctct.py  \n",
            "  inflating: transformers-main/src/transformers/models/mctct/processing_mctct.py  \n",
            "  inflating: transformers-main/src/transformers/models/mctct/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/megatron_bert/configuration_megatron_bert.py  \n",
            "  inflating: transformers-main/src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py  \n",
            "  inflating: transformers-main/src/transformers/models/megatron_bert/modeling_megatron_bert.py  \n",
            "  inflating: transformers-main/src/transformers/models/megatron_bert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py  \n",
            "  inflating: transformers-main/src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py  \n",
            "  inflating: transformers-main/src/transformers/models/megatron_gpt2/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/mluke/tokenization_mluke.py  \n",
            "  inflating: transformers-main/src/transformers/models/mluke/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/mmbt/configuration_mmbt.py  \n",
            "  inflating: transformers-main/src/transformers/models/mmbt/modeling_mmbt.py  \n",
            "  inflating: transformers-main/src/transformers/models/mmbt/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilebert/configuration_mobilebert.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilebert/convert_mobilebert_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilebert/modeling_mobilebert.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilebert/modeling_tf_mobilebert.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilebert/tokenization_mobilebert.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilebert/tokenization_mobilebert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilebert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilevit/configuration_mobilevit.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilevit/feature_extraction_mobilevit.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilevit/modeling_mobilevit.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilevit/modeling_tf_mobilevit.py  \n",
            "  inflating: transformers-main/src/transformers/models/mobilevit/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/mpnet/configuration_mpnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/mpnet/modeling_mpnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/mpnet/modeling_tf_mpnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/mpnet/tokenization_mpnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/mpnet/tokenization_mpnet_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/mpnet/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/mt5/configuration_mt5.py  \n",
            "  inflating: transformers-main/src/transformers/models/mt5/modeling_flax_mt5.py  \n",
            "  inflating: transformers-main/src/transformers/models/mt5/modeling_mt5.py  \n",
            "  inflating: transformers-main/src/transformers/models/mt5/modeling_tf_mt5.py  \n",
            "  inflating: transformers-main/src/transformers/models/mt5/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/mvp/configuration_mvp.py  \n",
            "  inflating: transformers-main/src/transformers/models/mvp/modeling_mvp.py  \n",
            "  inflating: transformers-main/src/transformers/models/mvp/tokenization_mvp.py  \n",
            "  inflating: transformers-main/src/transformers/models/mvp/tokenization_mvp_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/mvp/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/nezha/configuration_nezha.py  \n",
            "  inflating: transformers-main/src/transformers/models/nezha/modeling_nezha.py  \n",
            "  inflating: transformers-main/src/transformers/models/nezha/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/nllb/tokenization_nllb.py  \n",
            "  inflating: transformers-main/src/transformers/models/nllb/tokenization_nllb_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/nllb/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/nystromformer/configuration_nystromformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/nystromformer/convert_nystromformer_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/nystromformer/modeling_nystromformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/nystromformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/openai/configuration_openai.py  \n",
            "  inflating: transformers-main/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/openai/modeling_openai.py  \n",
            "  inflating: transformers-main/src/transformers/models/openai/modeling_tf_openai.py  \n",
            "  inflating: transformers-main/src/transformers/models/openai/tokenization_openai.py  \n",
            "  inflating: transformers-main/src/transformers/models/openai/tokenization_openai_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/openai/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/opt/configuration_opt.py  \n",
            "  inflating: transformers-main/src/transformers/models/opt/convert_opt_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/opt/modeling_flax_opt.py  \n",
            "  inflating: transformers-main/src/transformers/models/opt/modeling_opt.py  \n",
            "  inflating: transformers-main/src/transformers/models/opt/modeling_tf_opt.py  \n",
            "  inflating: transformers-main/src/transformers/models/opt/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/owlvit/configuration_owlvit.py  \n",
            "  inflating: transformers-main/src/transformers/models/owlvit/convert_owlvit_original_flax_to_hf.py  \n",
            "  inflating: transformers-main/src/transformers/models/owlvit/feature_extraction_owlvit.py  \n",
            "  inflating: transformers-main/src/transformers/models/owlvit/modeling_owlvit.py  \n",
            "  inflating: transformers-main/src/transformers/models/owlvit/processing_owlvit.py  \n",
            "  inflating: transformers-main/src/transformers/models/owlvit/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus/configuration_pegasus.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus/convert_pegasus_tf_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus/modeling_flax_pegasus.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus/modeling_pegasus.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus/modeling_tf_pegasus.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus/tokenization_pegasus.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus/tokenization_pegasus_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus_x/configuration_pegasus_x.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus_x/modeling_pegasus_x.py  \n",
            "  inflating: transformers-main/src/transformers/models/pegasus_x/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/perceiver/configuration_perceiver.py  \n",
            "  inflating: transformers-main/src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/perceiver/feature_extraction_perceiver.py  \n",
            "  inflating: transformers-main/src/transformers/models/perceiver/modeling_perceiver.py  \n",
            "  inflating: transformers-main/src/transformers/models/perceiver/tokenization_perceiver.py  \n",
            "  inflating: transformers-main/src/transformers/models/perceiver/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/phobert/tokenization_phobert.py  \n",
            "  inflating: transformers-main/src/transformers/models/phobert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/plbart/configuration_plbart.py  \n",
            "  inflating: transformers-main/src/transformers/models/plbart/convert_plbart_original_checkpoint_to_torch.py  \n",
            "  inflating: transformers-main/src/transformers/models/plbart/modeling_plbart.py  \n",
            "  inflating: transformers-main/src/transformers/models/plbart/tokenization_plbart.py  \n",
            "  inflating: transformers-main/src/transformers/models/plbart/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/poolformer/configuration_poolformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/poolformer/convert_poolformer_original_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/poolformer/feature_extraction_poolformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/poolformer/modeling_poolformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/poolformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/prophetnet/configuration_prophetnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/prophetnet/convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/prophetnet/modeling_prophetnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/prophetnet/tokenization_prophetnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/prophetnet/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/qdqbert/configuration_qdqbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/qdqbert/modeling_qdqbert.py  \n",
            "  inflating: transformers-main/src/transformers/models/qdqbert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/rag/configuration_rag.py  \n",
            "  inflating: transformers-main/src/transformers/models/rag/modeling_rag.py  \n",
            "  inflating: transformers-main/src/transformers/models/rag/modeling_tf_rag.py  \n",
            "  inflating: transformers-main/src/transformers/models/rag/retrieval_rag.py  \n",
            "  inflating: transformers-main/src/transformers/models/rag/tokenization_rag.py  \n",
            "  inflating: transformers-main/src/transformers/models/rag/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/realm/configuration_realm.py  \n",
            "  inflating: transformers-main/src/transformers/models/realm/modeling_realm.py  \n",
            "  inflating: transformers-main/src/transformers/models/realm/retrieval_realm.py  \n",
            "  inflating: transformers-main/src/transformers/models/realm/tokenization_realm.py  \n",
            "  inflating: transformers-main/src/transformers/models/realm/tokenization_realm_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/realm/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/reformer/configuration_reformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/reformer/convert_reformer_trax_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/reformer/modeling_reformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/reformer/tokenization_reformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/reformer/tokenization_reformer_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/reformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/regnet/configuration_regnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/regnet/convert_regnet_seer_10b_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/regnet/convert_regnet_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/regnet/modeling_regnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/regnet/modeling_tf_regnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/regnet/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/rembert/configuration_rembert.py  \n",
            "  inflating: transformers-main/src/transformers/models/rembert/convert_rembert_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/rembert/modeling_rembert.py  \n",
            "  inflating: transformers-main/src/transformers/models/rembert/modeling_tf_rembert.py  \n",
            "  inflating: transformers-main/src/transformers/models/rembert/tokenization_rembert.py  \n",
            "  inflating: transformers-main/src/transformers/models/rembert/tokenization_rembert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/rembert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/resnet/configuration_resnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/resnet/convert_resnet_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/resnet/modeling_resnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/resnet/modeling_tf_resnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/resnet/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/retribert/configuration_retribert.py  \n",
            "  inflating: transformers-main/src/transformers/models/retribert/modeling_retribert.py  \n",
            "  inflating: transformers-main/src/transformers/models/retribert/tokenization_retribert.py  \n",
            "  inflating: transformers-main/src/transformers/models/retribert/tokenization_retribert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/retribert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/roberta/configuration_roberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/roberta/convert_roberta_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/roberta/modeling_flax_roberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/roberta/modeling_roberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/roberta/modeling_tf_roberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/roberta/tokenization_roberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/roberta/tokenization_roberta_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/roberta/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/roformer/configuration_roformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/roformer/convert_roformer_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/roformer/modeling_flax_roformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/roformer/modeling_roformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/roformer/modeling_tf_roformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/roformer/tokenization_roformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/roformer/tokenization_roformer_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/roformer/tokenization_utils.py  \n",
            "  inflating: transformers-main/src/transformers/models/roformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/segformer/configuration_segformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/segformer/convert_segformer_original_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/segformer/feature_extraction_segformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/segformer/modeling_segformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/segformer/modeling_tf_segformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/segformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/sew/configuration_sew.py  \n",
            "  inflating: transformers-main/src/transformers/models/sew/convert_sew_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/sew/modeling_sew.py  \n",
            "  inflating: transformers-main/src/transformers/models/sew/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/sew_d/configuration_sew_d.py  \n",
            "  inflating: transformers-main/src/transformers/models/sew_d/convert_sew_d_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/sew_d/modeling_sew_d.py  \n",
            "  inflating: transformers-main/src/transformers/models/sew_d/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_encoder_decoder/configuration_speech_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_encoder_decoder/convert_mbart_wav2vec2_seq2seq_original_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_encoder_decoder/convert_speech_to_text_wav2vec2_seq2seq_original_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_encoder_decoder/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text/configuration_speech_to_text.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text/convert_s2t_fairseq_to_tfms.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text/feature_extraction_speech_to_text.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text/modeling_speech_to_text.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text/modeling_tf_speech_to_text.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text/processing_speech_to_text.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text/tokenization_speech_to_text.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text_2/configuration_speech_to_text_2.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text_2/processing_speech_to_text_2.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text_2/tokenization_speech_to_text_2.py  \n",
            "  inflating: transformers-main/src/transformers/models/speech_to_text_2/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/splinter/configuration_splinter.py  \n",
            "  inflating: transformers-main/src/transformers/models/splinter/modeling_splinter.py  \n",
            "  inflating: transformers-main/src/transformers/models/splinter/tokenization_splinter.py  \n",
            "  inflating: transformers-main/src/transformers/models/splinter/tokenization_splinter_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/splinter/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/squeezebert/configuration_squeezebert.py  \n",
            "  inflating: transformers-main/src/transformers/models/squeezebert/modeling_squeezebert.py  \n",
            "  inflating: transformers-main/src/transformers/models/squeezebert/tokenization_squeezebert.py  \n",
            "  inflating: transformers-main/src/transformers/models/squeezebert/tokenization_squeezebert_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/squeezebert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/swin/configuration_swin.py  \n",
            "  inflating: transformers-main/src/transformers/models/swin/convert_swin_timm_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/swin/modeling_swin.py  \n",
            "  inflating: transformers-main/src/transformers/models/swin/modeling_tf_swin.py  \n",
            "  inflating: transformers-main/src/transformers/models/swin/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/swinv2/configuration_swinv2.py  \n",
            "  inflating: transformers-main/src/transformers/models/swinv2/convert_swinv2_timm_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/swinv2/modeling_swinv2.py  \n",
            "  inflating: transformers-main/src/transformers/models/swinv2/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/t5/configuration_t5.py  \n",
            "  inflating: transformers-main/src/transformers/models/t5/convert_t5x_checkpoint_to_flax.py  \n",
            "  inflating: transformers-main/src/transformers/models/t5/convert_t5_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/t5/download_from_gcp.sh  \n",
            "  inflating: transformers-main/src/transformers/models/t5/modeling_flax_t5.py  \n",
            "  inflating: transformers-main/src/transformers/models/t5/modeling_t5.py  \n",
            "  inflating: transformers-main/src/transformers/models/t5/modeling_tf_t5.py  \n",
            "  inflating: transformers-main/src/transformers/models/t5/tokenization_t5.py  \n",
            "  inflating: transformers-main/src/transformers/models/t5/tokenization_t5_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/t5/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/tapas/configuration_tapas.py  \n",
            "  inflating: transformers-main/src/transformers/models/tapas/convert_tapas_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/tapas/modeling_tapas.py  \n",
            "  inflating: transformers-main/src/transformers/models/tapas/modeling_tf_tapas.py  \n",
            "  inflating: transformers-main/src/transformers/models/tapas/tokenization_tapas.py  \n",
            "  inflating: transformers-main/src/transformers/models/tapas/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/tapex/tokenization_tapex.py  \n",
            "  inflating: transformers-main/src/transformers/models/tapex/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/time_series_transformer/configuration_time_series_transformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/time_series_transformer/modeling_time_series_transformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/time_series_transformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/trajectory_transformer/configuration_trajectory_transformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/trajectory_transformer/convert_trajectory_transformer_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/trajectory_transformer/modeling_trajectory_transformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/trajectory_transformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/transfo_xl/configuration_transfo_xl.py  \n",
            "  inflating: transformers-main/src/transformers/models/transfo_xl/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/transfo_xl/modeling_tf_transfo_xl.py  \n",
            "  inflating: transformers-main/src/transformers/models/transfo_xl/modeling_tf_transfo_xl_utilities.py  \n",
            "  inflating: transformers-main/src/transformers/models/transfo_xl/modeling_transfo_xl.py  \n",
            "  inflating: transformers-main/src/transformers/models/transfo_xl/modeling_transfo_xl_utilities.py  \n",
            "  inflating: transformers-main/src/transformers/models/transfo_xl/tokenization_transfo_xl.py  \n",
            "  inflating: transformers-main/src/transformers/models/transfo_xl/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/trocr/configuration_trocr.py  \n",
            "  inflating: transformers-main/src/transformers/models/trocr/convert_trocr_unilm_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/trocr/modeling_trocr.py  \n",
            "  inflating: transformers-main/src/transformers/models/trocr/processing_trocr.py  \n",
            "  inflating: transformers-main/src/transformers/models/trocr/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/unispeech/configuration_unispeech.py  \n",
            "  inflating: transformers-main/src/transformers/models/unispeech/convert_unispeech_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/unispeech/modeling_unispeech.py  \n",
            "  inflating: transformers-main/src/transformers/models/unispeech/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/unispeech_sat/configuration_unispeech_sat.py  \n",
            "  inflating: transformers-main/src/transformers/models/unispeech_sat/convert_unispeech_original_s3prl_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/unispeech_sat/convert_unispeech_sat_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/unispeech_sat/modeling_unispeech_sat.py  \n",
            "  inflating: transformers-main/src/transformers/models/unispeech_sat/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/van/configuration_van.py  \n",
            "  inflating: transformers-main/src/transformers/models/van/convert_van_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/van/modeling_van.py  \n",
            "  inflating: transformers-main/src/transformers/models/van/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/videomae/configuration_videomae.py  \n",
            "  inflating: transformers-main/src/transformers/models/videomae/convert_videomae_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/videomae/feature_extraction_videomae.py  \n",
            "  inflating: transformers-main/src/transformers/models/videomae/modeling_videomae.py  \n",
            "  inflating: transformers-main/src/transformers/models/videomae/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/vilt/configuration_vilt.py  \n",
            "  inflating: transformers-main/src/transformers/models/vilt/convert_vilt_original_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/vilt/feature_extraction_vilt.py  \n",
            "  inflating: transformers-main/src/transformers/models/vilt/modeling_vilt.py  \n",
            "  inflating: transformers-main/src/transformers/models/vilt/processing_vilt.py  \n",
            "  inflating: transformers-main/src/transformers/models/vilt/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/vision_encoder_decoder/configuration_vision_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/vision_encoder_decoder/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/vision_text_dual_encoder/configuration_vision_text_dual_encoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/vision_text_dual_encoder/modeling_flax_vision_text_dual_encoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/vision_text_dual_encoder/processing_vision_text_dual_encoder.py  \n",
            "  inflating: transformers-main/src/transformers/models/vision_text_dual_encoder/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/visual_bert/configuration_visual_bert.py  \n",
            "  inflating: transformers-main/src/transformers/models/visual_bert/convert_visual_bert_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/visual_bert/modeling_visual_bert.py  \n",
            "  inflating: transformers-main/src/transformers/models/visual_bert/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit/configuration_vit.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit/convert_dino_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit/convert_vit_timm_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit/feature_extraction_vit.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit/modeling_flax_vit.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit/modeling_tf_vit.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit/modeling_vit.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit_mae/configuration_vit_mae.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit_mae/convert_vit_mae_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit_mae/modeling_tf_vit_mae.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit_mae/modeling_vit_mae.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit_mae/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit_msn/configuration_vit_msn.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit_msn/convert_msn_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit_msn/modeling_vit_msn.py  \n",
            "  inflating: transformers-main/src/transformers/models/vit_msn/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2/configuration_wav2vec2.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2/convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2/convert_wav2vec2_original_s3prl_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2/modeling_flax_wav2vec2.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2/modeling_tf_wav2vec2.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2/modeling_wav2vec2.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2/processing_wav2vec2.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2/tokenization_wav2vec2.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2_conformer/configuration_wav2vec2_conformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2_conformer/convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2_conformer/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2_phoneme/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py  \n",
            "  inflating: transformers-main/src/transformers/models/wav2vec2_with_lm/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/wavlm/configuration_wavlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/wavlm/convert_wavlm_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/wavlm/convert_wavlm_original_s3prl_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/wavlm/modeling_wavlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/wavlm/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/whisper/configuration_whisper.py  \n",
            "  inflating: transformers-main/src/transformers/models/whisper/english_normalizer.py  \n",
            "  inflating: transformers-main/src/transformers/models/whisper/feature_extraction_whisper.py  \n",
            "  inflating: transformers-main/src/transformers/models/whisper/modeling_tf_whisper.py  \n",
            "  inflating: transformers-main/src/transformers/models/whisper/modeling_whisper.py  \n",
            "  inflating: transformers-main/src/transformers/models/whisper/processing_whisper.py  \n",
            "  inflating: transformers-main/src/transformers/models/whisper/tokenization_whisper.py  \n",
            "  inflating: transformers-main/src/transformers/models/whisper/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/xglm/configuration_xglm.py  \n",
            "  inflating: transformers-main/src/transformers/models/xglm/convert_xglm_original_ckpt_to_trfms.py  \n",
            "  inflating: transformers-main/src/transformers/models/xglm/modeling_flax_xglm.py  \n",
            "  inflating: transformers-main/src/transformers/models/xglm/modeling_tf_xglm.py  \n",
            "  inflating: transformers-main/src/transformers/models/xglm/modeling_xglm.py  \n",
            "  inflating: transformers-main/src/transformers/models/xglm/tokenization_xglm.py  \n",
            "  inflating: transformers-main/src/transformers/models/xglm/tokenization_xglm_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/xglm/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm/configuration_xlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm/modeling_tf_xlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm/modeling_xlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm/tokenization_xlm.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_prophetnet/configuration_xlm_prophetnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_prophetnet/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta/configuration_xlm_roberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta/modeling_xlm_roberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta_xl/configuration_xlm_roberta_xl.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta_xl/convert_xlm_roberta_xl_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlm_roberta_xl/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlnet/configuration_xlnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlnet/convert_xlnet_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlnet/modeling_tf_xlnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlnet/modeling_xlnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlnet/tokenization_xlnet.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlnet/tokenization_xlnet_fast.py  \n",
            "  inflating: transformers-main/src/transformers/models/xlnet/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/x_clip/configuration_x_clip.py  \n",
            "  inflating: transformers-main/src/transformers/models/x_clip/convert_x_clip_original_pytorch_to_hf.py  \n",
            "  inflating: transformers-main/src/transformers/models/x_clip/modeling_x_clip.py  \n",
            "  inflating: transformers-main/src/transformers/models/x_clip/processing_x_clip.py  \n",
            "  inflating: transformers-main/src/transformers/models/x_clip/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/yolos/configuration_yolos.py  \n",
            "  inflating: transformers-main/src/transformers/models/yolos/convert_yolos_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/yolos/feature_extraction_yolos.py  \n",
            "  inflating: transformers-main/src/transformers/models/yolos/modeling_yolos.py  \n",
            "  inflating: transformers-main/src/transformers/models/yolos/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/common.h  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/common_cuda.h  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/common_cuda_device.h  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/configuration_yoso.py  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/convert_yoso_pytorch_to_pytorch.py  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/fast_lsh_cumulation.cu  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/fast_lsh_cumulation.h  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/fast_lsh_cumulation_cuda.cu  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/fast_lsh_cumulation_cuda.h  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/fast_lsh_cumulation_torch.cpp  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/modeling_yoso.py  \n",
            "  inflating: transformers-main/src/transformers/models/yoso/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/models/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/onnx/config.py  \n",
            "  inflating: transformers-main/src/transformers/onnx/convert.py  \n",
            "  inflating: transformers-main/src/transformers/onnx/features.py  \n",
            "  inflating: transformers-main/src/transformers/onnx/utils.py  \n",
            "  inflating: transformers-main/src/transformers/onnx/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/onnx/__main__.py  \n",
            "  inflating: transformers-main/src/transformers/optimization.py  \n",
            "  inflating: transformers-main/src/transformers/optimization_tf.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/audio_classification.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/audio_utils.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/automatic_speech_recognition.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/base.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/conversational.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/depth_estimation.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/document_question_answering.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/feature_extraction.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/fill_mask.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/image_classification.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/image_segmentation.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/image_to_text.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/object_detection.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/pt_utils.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/question_answering.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/table_question_answering.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/text2text_generation.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/text_classification.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/text_generation.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/token_classification.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/visual_question_answering.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/zero_shot_classification.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/zero_shot_image_classification.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/zero_shot_object_detection.py  \n",
            "  inflating: transformers-main/src/transformers/pipelines/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/processing_utils.py  \n",
            "  inflating: transformers-main/src/transformers/pytorch_utils.py  \n",
            "  inflating: transformers-main/src/transformers/sagemaker/trainer_sm.py  \n",
            "  inflating: transformers-main/src/transformers/sagemaker/training_args_sm.py  \n",
            "  inflating: transformers-main/src/transformers/sagemaker/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/testing_utils.py  \n",
            "  inflating: transformers-main/src/transformers/tf_utils.py  \n",
            "  inflating: transformers-main/src/transformers/tokenization_utils.py  \n",
            "  inflating: transformers-main/src/transformers/tokenization_utils_base.py  \n",
            "  inflating: transformers-main/src/transformers/tokenization_utils_fast.py  \n",
            "  inflating: transformers-main/src/transformers/trainer.py  \n",
            "  inflating: transformers-main/src/transformers/trainer_callback.py  \n",
            "  inflating: transformers-main/src/transformers/trainer_pt_utils.py  \n",
            "  inflating: transformers-main/src/transformers/trainer_seq2seq.py  \n",
            "  inflating: transformers-main/src/transformers/trainer_tf.py  \n",
            "  inflating: transformers-main/src/transformers/trainer_utils.py  \n",
            "  inflating: transformers-main/src/transformers/training_args.py  \n",
            "  inflating: transformers-main/src/transformers/training_args_seq2seq.py  \n",
            "  inflating: transformers-main/src/transformers/training_args_tf.py  \n",
            "  inflating: transformers-main/src/transformers/Transformer_BigBird.so  \n",
            "  inflating: transformers-main/src/transformers/utils/bitsandbytes.py  \n",
            "  inflating: transformers-main/src/transformers/utils/constants.py  \n",
            "  inflating: transformers-main/src/transformers/utils/doc.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_detectron2_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_flax_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_pt_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_scatter_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_sentencepiece_and_speech_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_sentencepiece_and_tokenizers_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_sentencepiece_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_speech_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_tensorflow_text_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_tf_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_timm_and_vision_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_tokenizers_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/dummy_vision_objects.py  \n",
            "  inflating: transformers-main/src/transformers/utils/fx.py  \n",
            "  inflating: transformers-main/src/transformers/utils/generic.py  \n",
            "  inflating: transformers-main/src/transformers/utils/hp_naming.py  \n",
            "  inflating: transformers-main/src/transformers/utils/hub.py  \n",
            "  inflating: transformers-main/src/transformers/utils/import_utils.py  \n",
            "  inflating: transformers-main/src/transformers/utils/logging.py  \n",
            "  inflating: transformers-main/src/transformers/utils/model_parallel_utils.py  \n",
            "  inflating: transformers-main/src/transformers/utils/notebook.py  \n",
            "  inflating: transformers-main/src/transformers/utils/sentencepiece_model_pb2.py  \n",
            "  inflating: transformers-main/src/transformers/utils/versions.py  \n",
            "  inflating: transformers-main/src/transformers/utils/__init__.py  \n",
            "  inflating: transformers-main/src/transformers/__init__.py  \n",
            "  inflating: transformers-main/templates/adding_a_missing_tokenization_test/cookiecutter-template-{{cookiecutter.modelname}}/test_tokenization_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_missing_tokenization_test/cookiecutter.json  \n",
            "  inflating: transformers-main/templates/adding_a_missing_tokenization_test/README.md  \n",
            "  inflating: transformers-main/templates/adding_a_new_example_script/cookiecutter.json  \n",
            "  inflating: transformers-main/templates/adding_a_new_example_script/README.md  \n",
            "  inflating: transformers-main/templates/adding_a_new_example_script/{{cookiecutter.directory_name}}/run_{{cookiecutter.example_shortcut}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/ADD_NEW_MODEL_PROPOSAL_TEMPLATE.md  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/configuration.json  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/configuration_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_flax_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_tf_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/test_modeling_flax_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/test_modeling_tf_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/test_modeling_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/tokenization_fast_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/tokenization_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/to_replace_{{cookiecutter.lowercase_modelname}}.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/__init__.py  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/{{cookiecutter.lowercase_modelname}}.mdx  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/cookiecutter.json  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/open_model_proposals/ADD_BIG_BIRD.md  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/open_model_proposals/README.md  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/README.md  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/tests/encoder-bert-tokenizer.json  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/tests/flax-encoder-bert-tokenizer.json  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/tests/flax-seq-2-seq-bart-tokenizer.json  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/tests/pt-encoder-bert-tokenizer.json  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/tests/pt-seq-2-seq-bart-tokenizer.json  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/tests/standalone.json  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/tests/tf-encoder-bert-tokenizer.json  \n",
            "  inflating: transformers-main/templates/adding_a_new_model/tests/tf-seq-2-seq-bart-tokenizer.json  \n",
            "  inflating: transformers-main/tests/benchmark/test_benchmark.py  \n",
            "  inflating: transformers-main/tests/benchmark/test_benchmark_tf.py  \n",
            " extracting: transformers-main/tests/benchmark/__init__.py  \n",
            "  inflating: transformers-main/tests/deepspeed/ds_config_zero2.json  \n",
            "  inflating: transformers-main/tests/deepspeed/ds_config_zero3.json  \n",
            "  inflating: transformers-main/tests/deepspeed/test_deepspeed.py  \n",
            "  inflating: transformers-main/tests/deepspeed/test_model_zoo.py  \n",
            "  inflating: transformers-main/tests/deepspeed/vit_feature_extractor.json  \n",
            "  inflating: transformers-main/tests/extended/test_trainer_ext.py  \n",
            "  inflating: transformers-main/tests/fixtures/add_distilbert_like_config.json  \n",
            "  inflating: transformers-main/tests/fixtures/dummy-config.json  \n",
            "  inflating: transformers-main/tests/fixtures/dummy_feature_extractor_config.json  \n",
            " extracting: transformers-main/tests/fixtures/empty.txt  \n",
            "  inflating: transformers-main/tests/fixtures/input.txt  \n",
            "  inflating: transformers-main/tests/fixtures/merges.txt  \n",
            "  inflating: transformers-main/tests/fixtures/preprocessor_config.json  \n",
            "  inflating: transformers-main/tests/fixtures/sample_text.txt  \n",
            "  inflating: transformers-main/tests/fixtures/sample_text_no_unicode.txt  \n",
            "  inflating: transformers-main/tests/fixtures/spiece.model  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/.gitignore  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/COCO/000000039769.png  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/COCO/coco_annotations.txt  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/COCO/coco_panoptic/000000039769.png  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/COCO/coco_panoptic_annotations.txt  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/conll/sample.json  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/GermEval/dev.txt  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/GermEval/labels.txt  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/GermEval/train.txt  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/MRPC/dev.csv  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/MRPC/dev.tsv  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/MRPC/train.csv  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/MRPC/train.tsv  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/SQUAD/sample.json  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/STS-B/dev.tsv  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/STS-B/train.tsv  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/swag/sample.json  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/wiki_text/wiki_00  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/wmt16/sample.json  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/wmt_en_ro/test.json  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/wmt_en_ro/train.json  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/wmt_en_ro/val.json  \n",
            "  inflating: transformers-main/tests/fixtures/tests_samples/xsum/sample.json  \n",
            "  inflating: transformers-main/tests/fixtures/test_entity_vocab.json  \n",
            "  inflating: transformers-main/tests/fixtures/test_sentencepiece.model  \n",
            "  inflating: transformers-main/tests/fixtures/test_sentencepiece_bpe.model  \n",
            "  inflating: transformers-main/tests/fixtures/test_sentencepiece_no_bos.model  \n",
            "  inflating: transformers-main/tests/fixtures/test_sentencepiece_with_bytefallback.model  \n",
            "  inflating: transformers-main/tests/fixtures/vocab.json  \n",
            "  inflating: transformers-main/tests/fixtures/vocab.txt  \n",
            "  inflating: transformers-main/tests/generation/test_generation_beam_constraints.py  \n",
            "  inflating: transformers-main/tests/generation/test_generation_beam_search.py  \n",
            "  inflating: transformers-main/tests/generation/test_generation_flax_logits_process.py  \n",
            "  inflating: transformers-main/tests/generation/test_generation_flax_utils.py  \n",
            "  inflating: transformers-main/tests/generation/test_generation_logits_process.py  \n",
            "  inflating: transformers-main/tests/generation/test_generation_stopping_criteria.py  \n",
            "  inflating: transformers-main/tests/generation/test_generation_tf_logits_process.py  \n",
            "  inflating: transformers-main/tests/generation/test_generation_tf_utils.py  \n",
            "  inflating: transformers-main/tests/generation/test_generation_utils.py  \n",
            " extracting: transformers-main/tests/generation/__init__.py  \n",
            "  inflating: transformers-main/tests/mixed_int8/README.md  \n",
            "  inflating: transformers-main/tests/mixed_int8/test_mixed_int8.py  \n",
            " extracting: transformers-main/tests/mixed_int8/__init__.py  \n",
            "  inflating: transformers-main/tests/models/albert/test_modeling_albert.py  \n",
            "  inflating: transformers-main/tests/models/albert/test_modeling_flax_albert.py  \n",
            "  inflating: transformers-main/tests/models/albert/test_modeling_tf_albert.py  \n",
            "  inflating: transformers-main/tests/models/albert/test_tokenization_albert.py  \n",
            " extracting: transformers-main/tests/models/albert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/auto/test_configuration_auto.py  \n",
            "  inflating: transformers-main/tests/models/auto/test_feature_extraction_auto.py  \n",
            "  inflating: transformers-main/tests/models/auto/test_modeling_auto.py  \n",
            "  inflating: transformers-main/tests/models/auto/test_modeling_flax_auto.py  \n",
            "  inflating: transformers-main/tests/models/auto/test_modeling_tf_auto.py  \n",
            "  inflating: transformers-main/tests/models/auto/test_modeling_tf_pytorch.py  \n",
            "  inflating: transformers-main/tests/models/auto/test_processor_auto.py  \n",
            "  inflating: transformers-main/tests/models/auto/test_tokenization_auto.py  \n",
            " extracting: transformers-main/tests/models/auto/__init__.py  \n",
            "  inflating: transformers-main/tests/models/bart/test_modeling_bart.py  \n",
            "  inflating: transformers-main/tests/models/bart/test_modeling_flax_bart.py  \n",
            "  inflating: transformers-main/tests/models/bart/test_modeling_tf_bart.py  \n",
            "  inflating: transformers-main/tests/models/bart/test_tokenization_bart.py  \n",
            " extracting: transformers-main/tests/models/bart/__init__.py  \n",
            "  inflating: transformers-main/tests/models/barthez/test_tokenization_barthez.py  \n",
            " extracting: transformers-main/tests/models/barthez/__init__.py  \n",
            "  inflating: transformers-main/tests/models/bartpho/test_tokenization_bartpho.py  \n",
            " extracting: transformers-main/tests/models/bartpho/__init__.py  \n",
            "  inflating: transformers-main/tests/models/beit/test_feature_extraction_beit.py  \n",
            "  inflating: transformers-main/tests/models/beit/test_modeling_beit.py  \n",
            "  inflating: transformers-main/tests/models/beit/test_modeling_flax_beit.py  \n",
            " extracting: transformers-main/tests/models/beit/__init__.py  \n",
            "  inflating: transformers-main/tests/models/bert/test_modeling_bert.py  \n",
            "  inflating: transformers-main/tests/models/bert/test_modeling_flax_bert.py  \n",
            "  inflating: transformers-main/tests/models/bert/test_modeling_tf_bert.py  \n",
            "  inflating: transformers-main/tests/models/bert/test_tokenization_bert.py  \n",
            "  inflating: transformers-main/tests/models/bert/test_tokenization_bert_tf.py  \n",
            " extracting: transformers-main/tests/models/bert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/bertweet/test_tokenization_bertweet.py  \n",
            " extracting: transformers-main/tests/models/bertweet/__init__.py  \n",
            "  inflating: transformers-main/tests/models/bert_generation/test_modeling_bert_generation.py  \n",
            "  inflating: transformers-main/tests/models/bert_generation/test_tokenization_bert_generation.py  \n",
            " extracting: transformers-main/tests/models/bert_generation/__init__.py  \n",
            "  inflating: transformers-main/tests/models/bert_japanese/test_tokenization_bert_japanese.py  \n",
            " extracting: transformers-main/tests/models/bert_japanese/__init__.py  \n",
            "  inflating: transformers-main/tests/models/bigbird_pegasus/test_modeling_bigbird_pegasus.py  \n",
            " extracting: transformers-main/tests/models/bigbird_pegasus/__init__.py  \n",
            "  inflating: transformers-main/tests/models/big_bird/test_modeling_big_bird.py  \n",
            "  inflating: transformers-main/tests/models/big_bird/test_modeling_flax_big_bird.py  \n",
            "  inflating: transformers-main/tests/models/big_bird/test_tokenization_big_bird.py  \n",
            " extracting: transformers-main/tests/models/big_bird/__init__.py  \n",
            "  inflating: transformers-main/tests/models/blenderbot/test_modeling_blenderbot.py  \n",
            "  inflating: transformers-main/tests/models/blenderbot/test_modeling_flax_blenderbot.py  \n",
            "  inflating: transformers-main/tests/models/blenderbot/test_modeling_tf_blenderbot.py  \n",
            "  inflating: transformers-main/tests/models/blenderbot/test_tokenization_blenderbot.py  \n",
            " extracting: transformers-main/tests/models/blenderbot/__init__.py  \n",
            "  inflating: transformers-main/tests/models/blenderbot_small/test_modeling_blenderbot_small.py  \n",
            "  inflating: transformers-main/tests/models/blenderbot_small/test_modeling_flax_blenderbot_small.py  \n",
            "  inflating: transformers-main/tests/models/blenderbot_small/test_modeling_tf_blenderbot_small.py  \n",
            "  inflating: transformers-main/tests/models/blenderbot_small/test_tokenization_blenderbot_small.py  \n",
            " extracting: transformers-main/tests/models/blenderbot_small/__init__.py  \n",
            "  inflating: transformers-main/tests/models/bloom/test_modeling_bloom.py  \n",
            "  inflating: transformers-main/tests/models/bloom/test_tokenization_bloom.py  \n",
            " extracting: transformers-main/tests/models/bloom/__init__.py  \n",
            "  inflating: transformers-main/tests/models/bort/test_modeling_bort.py  \n",
            "  inflating: transformers-main/tests/models/bort/test_modeling_tf_bort.py  \n",
            " extracting: transformers-main/tests/models/bort/__init__.py  \n",
            "  inflating: transformers-main/tests/models/byt5/test_tokenization_byt5.py  \n",
            " extracting: transformers-main/tests/models/byt5/__init__.py  \n",
            "  inflating: transformers-main/tests/models/camembert/test_modeling_camembert.py  \n",
            "  inflating: transformers-main/tests/models/camembert/test_modeling_tf_camembert.py  \n",
            "  inflating: transformers-main/tests/models/camembert/test_tokenization_camembert.py  \n",
            " extracting: transformers-main/tests/models/camembert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/canine/test_modeling_canine.py  \n",
            "  inflating: transformers-main/tests/models/canine/test_tokenization_canine.py  \n",
            " extracting: transformers-main/tests/models/canine/__init__.py  \n",
            "  inflating: transformers-main/tests/models/clip/test_feature_extraction_clip.py  \n",
            "  inflating: transformers-main/tests/models/clip/test_modeling_clip.py  \n",
            "  inflating: transformers-main/tests/models/clip/test_modeling_flax_clip.py  \n",
            "  inflating: transformers-main/tests/models/clip/test_modeling_tf_clip.py  \n",
            "  inflating: transformers-main/tests/models/clip/test_processor_clip.py  \n",
            "  inflating: transformers-main/tests/models/clip/test_tokenization_clip.py  \n",
            " extracting: transformers-main/tests/models/clip/__init__.py  \n",
            "  inflating: transformers-main/tests/models/codegen/test_modeling_codegen.py  \n",
            "  inflating: transformers-main/tests/models/codegen/test_tokenization_codegen.py  \n",
            " extracting: transformers-main/tests/models/codegen/__init__.py  \n",
            "  inflating: transformers-main/tests/models/conditional_detr/test_feature_extraction_conditional_detr.py  \n",
            "  inflating: transformers-main/tests/models/conditional_detr/test_modeling_conditional_detr.py  \n",
            " extracting: transformers-main/tests/models/conditional_detr/__init__.py  \n",
            "  inflating: transformers-main/tests/models/convbert/test_modeling_convbert.py  \n",
            "  inflating: transformers-main/tests/models/convbert/test_modeling_tf_convbert.py  \n",
            " extracting: transformers-main/tests/models/convbert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/convnext/test_feature_extraction_convnext.py  \n",
            "  inflating: transformers-main/tests/models/convnext/test_modeling_convnext.py  \n",
            "  inflating: transformers-main/tests/models/convnext/test_modeling_tf_convnext.py  \n",
            " extracting: transformers-main/tests/models/convnext/__init__.py  \n",
            "  inflating: transformers-main/tests/models/cpm/test_tokenization_cpm.py  \n",
            " extracting: transformers-main/tests/models/cpm/__init__.py  \n",
            "  inflating: transformers-main/tests/models/ctrl/test_modeling_ctrl.py  \n",
            "  inflating: transformers-main/tests/models/ctrl/test_modeling_tf_ctrl.py  \n",
            "  inflating: transformers-main/tests/models/ctrl/test_tokenization_ctrl.py  \n",
            " extracting: transformers-main/tests/models/ctrl/__init__.py  \n",
            "  inflating: transformers-main/tests/models/cvt/test_modeling_cvt.py  \n",
            "  inflating: transformers-main/tests/models/cvt/test_modeling_tf_cvt.py  \n",
            " extracting: transformers-main/tests/models/cvt/__init__.py  \n",
            "  inflating: transformers-main/tests/models/data2vec/test_modeling_data2vec_audio.py  \n",
            "  inflating: transformers-main/tests/models/data2vec/test_modeling_data2vec_text.py  \n",
            "  inflating: transformers-main/tests/models/data2vec/test_modeling_data2vec_vision.py  \n",
            "  inflating: transformers-main/tests/models/data2vec/test_modeling_tf_data2vec_vision.py  \n",
            " extracting: transformers-main/tests/models/data2vec/__init__.py  \n",
            "  inflating: transformers-main/tests/models/deberta/test_modeling_deberta.py  \n",
            "  inflating: transformers-main/tests/models/deberta/test_modeling_tf_deberta.py  \n",
            "  inflating: transformers-main/tests/models/deberta/test_tokenization_deberta.py  \n",
            " extracting: transformers-main/tests/models/deberta/__init__.py  \n",
            "  inflating: transformers-main/tests/models/deberta_v2/test_modeling_deberta_v2.py  \n",
            "  inflating: transformers-main/tests/models/deberta_v2/test_modeling_tf_deberta_v2.py  \n",
            "  inflating: transformers-main/tests/models/deberta_v2/test_tokenization_deberta_v2.py  \n",
            " extracting: transformers-main/tests/models/deberta_v2/__init__.py  \n",
            "  inflating: transformers-main/tests/models/decision_transformer/test_modeling_decision_transformer.py  \n",
            " extracting: transformers-main/tests/models/decision_transformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/deformable_detr/test_feature_extraction_deformable_detr.py  \n",
            "  inflating: transformers-main/tests/models/deformable_detr/test_modeling_deformable_detr.py  \n",
            " extracting: transformers-main/tests/models/deformable_detr/__init__.py  \n",
            "  inflating: transformers-main/tests/models/deit/test_feature_extraction_deit.py  \n",
            "  inflating: transformers-main/tests/models/deit/test_modeling_deit.py  \n",
            "  inflating: transformers-main/tests/models/deit/test_modeling_tf_deit.py  \n",
            " extracting: transformers-main/tests/models/deit/__init__.py  \n",
            "  inflating: transformers-main/tests/models/detr/test_feature_extraction_detr.py  \n",
            "  inflating: transformers-main/tests/models/detr/test_modeling_detr.py  \n",
            " extracting: transformers-main/tests/models/detr/__init__.py  \n",
            "  inflating: transformers-main/tests/models/distilbert/test_modeling_distilbert.py  \n",
            "  inflating: transformers-main/tests/models/distilbert/test_modeling_flax_distilbert.py  \n",
            "  inflating: transformers-main/tests/models/distilbert/test_modeling_tf_distilbert.py  \n",
            "  inflating: transformers-main/tests/models/distilbert/test_tokenization_distilbert.py  \n",
            " extracting: transformers-main/tests/models/distilbert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/dit/test_modeling_dit.py  \n",
            " extracting: transformers-main/tests/models/dit/__init__.py  \n",
            "  inflating: transformers-main/tests/models/donut/test_feature_extraction_donut.py  \n",
            "  inflating: transformers-main/tests/models/donut/test_modeling_donut_swin.py  \n",
            " extracting: transformers-main/tests/models/donut/__init__.py  \n",
            "  inflating: transformers-main/tests/models/dpr/test_modeling_dpr.py  \n",
            "  inflating: transformers-main/tests/models/dpr/test_modeling_tf_dpr.py  \n",
            "  inflating: transformers-main/tests/models/dpr/test_tokenization_dpr.py  \n",
            " extracting: transformers-main/tests/models/dpr/__init__.py  \n",
            "  inflating: transformers-main/tests/models/dpt/test_feature_extraction_dpt.py  \n",
            "  inflating: transformers-main/tests/models/dpt/test_modeling_dpt.py  \n",
            " extracting: transformers-main/tests/models/dpt/__init__.py  \n",
            "  inflating: transformers-main/tests/models/electra/test_modeling_electra.py  \n",
            "  inflating: transformers-main/tests/models/electra/test_modeling_flax_electra.py  \n",
            "  inflating: transformers-main/tests/models/electra/test_modeling_tf_electra.py  \n",
            " extracting: transformers-main/tests/models/electra/__init__.py  \n",
            "  inflating: transformers-main/tests/models/encoder_decoder/test_modeling_encoder_decoder.py  \n",
            "  inflating: transformers-main/tests/models/encoder_decoder/test_modeling_flax_encoder_decoder.py  \n",
            "  inflating: transformers-main/tests/models/encoder_decoder/test_modeling_tf_encoder_decoder.py  \n",
            " extracting: transformers-main/tests/models/encoder_decoder/__init__.py  \n",
            "  inflating: transformers-main/tests/models/ernie/test_modeling_ernie.py  \n",
            " extracting: transformers-main/tests/models/ernie/__init__.py  \n",
            "  inflating: transformers-main/tests/models/esm/test_modeling_esm.py  \n",
            "  inflating: transformers-main/tests/models/esm/test_modeling_tf_esm.py  \n",
            "  inflating: transformers-main/tests/models/esm/test_tokenization_esm.py  \n",
            " extracting: transformers-main/tests/models/esm/__init__.py  \n",
            "  inflating: transformers-main/tests/models/flaubert/test_modeling_flaubert.py  \n",
            "  inflating: transformers-main/tests/models/flaubert/test_modeling_tf_flaubert.py  \n",
            " extracting: transformers-main/tests/models/flaubert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/flava/test_feature_extraction_flava.py  \n",
            "  inflating: transformers-main/tests/models/flava/test_modeling_flava.py  \n",
            "  inflating: transformers-main/tests/models/flava/test_processor_flava.py  \n",
            " extracting: transformers-main/tests/models/flava/__init__.py  \n",
            "  inflating: transformers-main/tests/models/fnet/test_modeling_fnet.py  \n",
            "  inflating: transformers-main/tests/models/fnet/test_tokenization_fnet.py  \n",
            " extracting: transformers-main/tests/models/fnet/__init__.py  \n",
            "  inflating: transformers-main/tests/models/fsmt/test_modeling_fsmt.py  \n",
            "  inflating: transformers-main/tests/models/fsmt/test_tokenization_fsmt.py  \n",
            " extracting: transformers-main/tests/models/fsmt/__init__.py  \n",
            "  inflating: transformers-main/tests/models/funnel/test_modeling_funnel.py  \n",
            "  inflating: transformers-main/tests/models/funnel/test_modeling_tf_funnel.py  \n",
            "  inflating: transformers-main/tests/models/funnel/test_tokenization_funnel.py  \n",
            " extracting: transformers-main/tests/models/funnel/__init__.py  \n",
            "  inflating: transformers-main/tests/models/glpn/test_feature_extraction_glpn.py  \n",
            "  inflating: transformers-main/tests/models/glpn/test_modeling_glpn.py  \n",
            " extracting: transformers-main/tests/models/glpn/__init__.py  \n",
            "  inflating: transformers-main/tests/models/gpt2/test_modeling_flax_gpt2.py  \n",
            "  inflating: transformers-main/tests/models/gpt2/test_modeling_gpt2.py  \n",
            "  inflating: transformers-main/tests/models/gpt2/test_modeling_tf_gpt2.py  \n",
            "  inflating: transformers-main/tests/models/gpt2/test_tokenization_gpt2.py  \n",
            " extracting: transformers-main/tests/models/gpt2/__init__.py  \n",
            "  inflating: transformers-main/tests/models/gptj/test_modeling_flax_gptj.py  \n",
            "  inflating: transformers-main/tests/models/gptj/test_modeling_gptj.py  \n",
            "  inflating: transformers-main/tests/models/gptj/test_modeling_tf_gptj.py  \n",
            " extracting: transformers-main/tests/models/gptj/__init__.py  \n",
            "  inflating: transformers-main/tests/models/gpt_neo/test_modeling_flax_gpt_neo.py  \n",
            "  inflating: transformers-main/tests/models/gpt_neo/test_modeling_gpt_neo.py  \n",
            " extracting: transformers-main/tests/models/gpt_neo/__init__.py  \n",
            "  inflating: transformers-main/tests/models/gpt_neox/test_modeling_gpt_neox.py  \n",
            " extracting: transformers-main/tests/models/gpt_neox/__init__.py  \n",
            "  inflating: transformers-main/tests/models/gpt_neox_japanese/test_modeling_gpt_neox_japanese.py  \n",
            "  inflating: transformers-main/tests/models/gpt_neox_japanese/test_tokenization_gpt_neox_japanese.py  \n",
            " extracting: transformers-main/tests/models/gpt_neox_japanese/__init__.py  \n",
            "  inflating: transformers-main/tests/models/groupvit/test_modeling_groupvit.py  \n",
            "  inflating: transformers-main/tests/models/groupvit/test_modeling_tf_groupvit.py  \n",
            " extracting: transformers-main/tests/models/groupvit/__init__.py  \n",
            "  inflating: transformers-main/tests/models/herbert/test_tokenization_herbert.py  \n",
            " extracting: transformers-main/tests/models/herbert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/hubert/test_modeling_hubert.py  \n",
            "  inflating: transformers-main/tests/models/hubert/test_modeling_tf_hubert.py  \n",
            " extracting: transformers-main/tests/models/hubert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/ibert/test_modeling_ibert.py  \n",
            " extracting: transformers-main/tests/models/ibert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/imagegpt/test_feature_extraction_imagegpt.py  \n",
            "  inflating: transformers-main/tests/models/imagegpt/test_modeling_imagegpt.py  \n",
            " extracting: transformers-main/tests/models/imagegpt/__init__.py  \n",
            "  inflating: transformers-main/tests/models/layoutlm/test_modeling_layoutlm.py  \n",
            "  inflating: transformers-main/tests/models/layoutlm/test_modeling_tf_layoutlm.py  \n",
            "  inflating: transformers-main/tests/models/layoutlm/test_tokenization_layoutlm.py  \n",
            " extracting: transformers-main/tests/models/layoutlm/__init__.py  \n",
            "  inflating: transformers-main/tests/models/layoutlmv2/test_feature_extraction_layoutlmv2.py  \n",
            "  inflating: transformers-main/tests/models/layoutlmv2/test_modeling_layoutlmv2.py  \n",
            "  inflating: transformers-main/tests/models/layoutlmv2/test_processor_layoutlmv2.py  \n",
            "  inflating: transformers-main/tests/models/layoutlmv2/test_tokenization_layoutlmv2.py  \n",
            " extracting: transformers-main/tests/models/layoutlmv2/__init__.py  \n",
            "  inflating: transformers-main/tests/models/layoutlmv3/test_feature_extraction_layoutlmv3.py  \n",
            "  inflating: transformers-main/tests/models/layoutlmv3/test_modeling_layoutlmv3.py  \n",
            "  inflating: transformers-main/tests/models/layoutlmv3/test_modeling_tf_layoutlmv3.py  \n",
            "  inflating: transformers-main/tests/models/layoutlmv3/test_processor_layoutlmv3.py  \n",
            "  inflating: transformers-main/tests/models/layoutlmv3/test_tokenization_layoutlmv3.py  \n",
            " extracting: transformers-main/tests/models/layoutlmv3/__init__.py  \n",
            "  inflating: transformers-main/tests/models/layoutxlm/test_processor_layoutxlm.py  \n",
            "  inflating: transformers-main/tests/models/layoutxlm/test_tokenization_layoutxlm.py  \n",
            " extracting: transformers-main/tests/models/layoutxlm/__init__.py  \n",
            "  inflating: transformers-main/tests/models/led/test_modeling_led.py  \n",
            "  inflating: transformers-main/tests/models/led/test_modeling_tf_led.py  \n",
            " extracting: transformers-main/tests/models/led/__init__.py  \n",
            "  inflating: transformers-main/tests/models/levit/test_feature_extraction_levit.py  \n",
            "  inflating: transformers-main/tests/models/levit/test_modeling_levit.py  \n",
            " extracting: transformers-main/tests/models/levit/__init__.py  \n",
            "  inflating: transformers-main/tests/models/lilt/test_modeling_lilt.py  \n",
            " extracting: transformers-main/tests/models/lilt/__init__.py  \n",
            "  inflating: transformers-main/tests/models/longformer/test_modeling_longformer.py  \n",
            "  inflating: transformers-main/tests/models/longformer/test_modeling_tf_longformer.py  \n",
            "  inflating: transformers-main/tests/models/longformer/test_tokenization_longformer.py  \n",
            " extracting: transformers-main/tests/models/longformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/longt5/test_modeling_flax_longt5.py  \n",
            "  inflating: transformers-main/tests/models/longt5/test_modeling_longt5.py  \n",
            " extracting: transformers-main/tests/models/longt5/__init__.py  \n",
            "  inflating: transformers-main/tests/models/luke/test_modeling_luke.py  \n",
            "  inflating: transformers-main/tests/models/luke/test_tokenization_luke.py  \n",
            " extracting: transformers-main/tests/models/luke/__init__.py  \n",
            "  inflating: transformers-main/tests/models/lxmert/test_modeling_lxmert.py  \n",
            "  inflating: transformers-main/tests/models/lxmert/test_modeling_tf_lxmert.py  \n",
            "  inflating: transformers-main/tests/models/lxmert/test_tokenization_lxmert.py  \n",
            " extracting: transformers-main/tests/models/lxmert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/m2m_100/test_modeling_m2m_100.py  \n",
            "  inflating: transformers-main/tests/models/m2m_100/test_tokenization_m2m_100.py  \n",
            " extracting: transformers-main/tests/models/m2m_100/__init__.py  \n",
            "  inflating: transformers-main/tests/models/marian/test_modeling_flax_marian.py  \n",
            "  inflating: transformers-main/tests/models/marian/test_modeling_marian.py  \n",
            "  inflating: transformers-main/tests/models/marian/test_modeling_tf_marian.py  \n",
            "  inflating: transformers-main/tests/models/marian/test_tokenization_marian.py  \n",
            " extracting: transformers-main/tests/models/marian/__init__.py  \n",
            "  inflating: transformers-main/tests/models/markuplm/test_feature_extraction_markuplm.py  \n",
            "  inflating: transformers-main/tests/models/markuplm/test_modeling_markuplm.py  \n",
            "  inflating: transformers-main/tests/models/markuplm/test_processor_markuplm.py  \n",
            "  inflating: transformers-main/tests/models/markuplm/test_tokenization_markuplm.py  \n",
            " extracting: transformers-main/tests/models/markuplm/__init__.py  \n",
            "  inflating: transformers-main/tests/models/maskformer/test_feature_extraction_maskformer.py  \n",
            "  inflating: transformers-main/tests/models/maskformer/test_modeling_maskformer.py  \n",
            " extracting: transformers-main/tests/models/maskformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/mbart/test_modeling_flax_mbart.py  \n",
            "  inflating: transformers-main/tests/models/mbart/test_modeling_mbart.py  \n",
            "  inflating: transformers-main/tests/models/mbart/test_modeling_tf_mbart.py  \n",
            "  inflating: transformers-main/tests/models/mbart/test_tokenization_mbart.py  \n",
            " extracting: transformers-main/tests/models/mbart/__init__.py  \n",
            "  inflating: transformers-main/tests/models/mbart50/test_tokenization_mbart50.py  \n",
            " extracting: transformers-main/tests/models/mbart50/__init__.py  \n",
            "  inflating: transformers-main/tests/models/mctct/test_feature_extraction_mctct.py  \n",
            "  inflating: transformers-main/tests/models/mctct/test_modeling_mctct.py  \n",
            "  inflating: transformers-main/tests/models/mctct/test_processor_mctct.py  \n",
            " extracting: transformers-main/tests/models/mctct/__init__.py  \n",
            "  inflating: transformers-main/tests/models/megatron_bert/test_modeling_megatron_bert.py  \n",
            " extracting: transformers-main/tests/models/megatron_bert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/megatron_gpt2/test_modeling_megatron_gpt2.py  \n",
            " extracting: transformers-main/tests/models/megatron_gpt2/__init__.py  \n",
            "  inflating: transformers-main/tests/models/mluke/test_tokenization_mluke.py  \n",
            " extracting: transformers-main/tests/models/mluke/__init__.py  \n",
            "  inflating: transformers-main/tests/models/mobilebert/test_modeling_mobilebert.py  \n",
            "  inflating: transformers-main/tests/models/mobilebert/test_modeling_tf_mobilebert.py  \n",
            "  inflating: transformers-main/tests/models/mobilebert/test_tokenization_mobilebert.py  \n",
            " extracting: transformers-main/tests/models/mobilebert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/mobilevit/test_feature_extraction_mobilevit.py  \n",
            "  inflating: transformers-main/tests/models/mobilevit/test_modeling_mobilevit.py  \n",
            "  inflating: transformers-main/tests/models/mobilevit/test_modeling_tf_mobilevit.py  \n",
            " extracting: transformers-main/tests/models/mobilevit/__init__.py  \n",
            "  inflating: transformers-main/tests/models/mpnet/test_modeling_mpnet.py  \n",
            "  inflating: transformers-main/tests/models/mpnet/test_modeling_tf_mpnet.py  \n",
            "  inflating: transformers-main/tests/models/mpnet/test_tokenization_mpnet.py  \n",
            " extracting: transformers-main/tests/models/mpnet/__init__.py  \n",
            "  inflating: transformers-main/tests/models/mt5/test_modeling_flax_mt5.py  \n",
            "  inflating: transformers-main/tests/models/mt5/test_modeling_mt5.py  \n",
            "  inflating: transformers-main/tests/models/mt5/test_modeling_tf_mt5.py  \n",
            " extracting: transformers-main/tests/models/mt5/__init__.py  \n",
            "  inflating: transformers-main/tests/models/mvp/test_modeling_mvp.py  \n",
            "  inflating: transformers-main/tests/models/mvp/test_tokenization_mvp.py  \n",
            " extracting: transformers-main/tests/models/mvp/__init__.py  \n",
            "  inflating: transformers-main/tests/models/nezha/test_modeling_nezha.py  \n",
            " extracting: transformers-main/tests/models/nezha/__init__.py  \n",
            "  inflating: transformers-main/tests/models/nllb/test_tokenization_nllb.py  \n",
            " extracting: transformers-main/tests/models/nllb/__init__.py  \n",
            "  inflating: transformers-main/tests/models/nystromformer/test_modeling_nystromformer.py  \n",
            " extracting: transformers-main/tests/models/nystromformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/openai/test_modeling_openai.py  \n",
            "  inflating: transformers-main/tests/models/openai/test_modeling_tf_openai.py  \n",
            "  inflating: transformers-main/tests/models/openai/test_tokenization_openai.py  \n",
            " extracting: transformers-main/tests/models/openai/__init__.py  \n",
            "  inflating: transformers-main/tests/models/opt/test_modeling_flax_opt.py  \n",
            "  inflating: transformers-main/tests/models/opt/test_modeling_opt.py  \n",
            "  inflating: transformers-main/tests/models/opt/test_modeling_tf_opt.py  \n",
            " extracting: transformers-main/tests/models/opt/__init__.py  \n",
            "  inflating: transformers-main/tests/models/owlvit/test_feature_extraction_owlvit.py  \n",
            "  inflating: transformers-main/tests/models/owlvit/test_modeling_owlvit.py  \n",
            "  inflating: transformers-main/tests/models/owlvit/test_processor_owlvit.py  \n",
            " extracting: transformers-main/tests/models/owlvit/__init__.py  \n",
            "  inflating: transformers-main/tests/models/pegasus/test_modeling_flax_pegasus.py  \n",
            "  inflating: transformers-main/tests/models/pegasus/test_modeling_pegasus.py  \n",
            "  inflating: transformers-main/tests/models/pegasus/test_modeling_tf_pegasus.py  \n",
            "  inflating: transformers-main/tests/models/pegasus/test_tokenization_pegasus.py  \n",
            " extracting: transformers-main/tests/models/pegasus/__init__.py  \n",
            "  inflating: transformers-main/tests/models/pegasus_x/test_modeling_pegasus_x.py  \n",
            " extracting: transformers-main/tests/models/pegasus_x/__init__.py  \n",
            "  inflating: transformers-main/tests/models/perceiver/test_modeling_perceiver.py  \n",
            "  inflating: transformers-main/tests/models/perceiver/test_tokenization_perceiver.py  \n",
            " extracting: transformers-main/tests/models/perceiver/__init__.py  \n",
            "  inflating: transformers-main/tests/models/phobert/test_tokenization_phobert.py  \n",
            " extracting: transformers-main/tests/models/phobert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/plbart/test_modeling_plbart.py  \n",
            "  inflating: transformers-main/tests/models/plbart/test_tokenization_plbart.py  \n",
            " extracting: transformers-main/tests/models/plbart/__init__.py  \n",
            "  inflating: transformers-main/tests/models/poolformer/test_feature_extraction_poolformer.py  \n",
            "  inflating: transformers-main/tests/models/poolformer/test_modeling_poolformer.py  \n",
            " extracting: transformers-main/tests/models/poolformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/prophetnet/test_modeling_prophetnet.py  \n",
            "  inflating: transformers-main/tests/models/prophetnet/test_tokenization_prophetnet.py  \n",
            " extracting: transformers-main/tests/models/prophetnet/__init__.py  \n",
            "  inflating: transformers-main/tests/models/qdqbert/test_modeling_qdqbert.py  \n",
            " extracting: transformers-main/tests/models/qdqbert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/rag/test_modeling_rag.py  \n",
            "  inflating: transformers-main/tests/models/rag/test_modeling_tf_rag.py  \n",
            "  inflating: transformers-main/tests/models/rag/test_retrieval_rag.py  \n",
            "  inflating: transformers-main/tests/models/rag/test_tokenization_rag.py  \n",
            " extracting: transformers-main/tests/models/rag/__init__.py  \n",
            "  inflating: transformers-main/tests/models/realm/test_modeling_realm.py  \n",
            "  inflating: transformers-main/tests/models/realm/test_retrieval_realm.py  \n",
            "  inflating: transformers-main/tests/models/realm/test_tokenization_realm.py  \n",
            " extracting: transformers-main/tests/models/realm/__init__.py  \n",
            "  inflating: transformers-main/tests/models/reformer/test_modeling_reformer.py  \n",
            "  inflating: transformers-main/tests/models/reformer/test_tokenization_reformer.py  \n",
            " extracting: transformers-main/tests/models/reformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/regnet/test_modeling_regnet.py  \n",
            "  inflating: transformers-main/tests/models/regnet/test_modeling_tf_regnet.py  \n",
            " extracting: transformers-main/tests/models/regnet/__init__.py  \n",
            "  inflating: transformers-main/tests/models/rembert/test_modeling_rembert.py  \n",
            "  inflating: transformers-main/tests/models/rembert/test_modeling_tf_rembert.py  \n",
            " extracting: transformers-main/tests/models/rembert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/resnet/test_modeling_resnet.py  \n",
            "  inflating: transformers-main/tests/models/resnet/test_modeling_tf_resnet.py  \n",
            " extracting: transformers-main/tests/models/resnet/__init__.py  \n",
            "  inflating: transformers-main/tests/models/retribert/test_tokenization_retribert.py  \n",
            " extracting: transformers-main/tests/models/retribert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/roberta/test_modeling_flax_roberta.py  \n",
            "  inflating: transformers-main/tests/models/roberta/test_modeling_roberta.py  \n",
            "  inflating: transformers-main/tests/models/roberta/test_modeling_tf_roberta.py  \n",
            "  inflating: transformers-main/tests/models/roberta/test_tokenization_roberta.py  \n",
            " extracting: transformers-main/tests/models/roberta/__init__.py  \n",
            "  inflating: transformers-main/tests/models/roformer/test_modeling_flax_roformer.py  \n",
            "  inflating: transformers-main/tests/models/roformer/test_modeling_roformer.py  \n",
            "  inflating: transformers-main/tests/models/roformer/test_modeling_tf_roformer.py  \n",
            "  inflating: transformers-main/tests/models/roformer/test_tokenization_roformer.py  \n",
            " extracting: transformers-main/tests/models/roformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/segformer/test_feature_extraction_segformer.py  \n",
            "  inflating: transformers-main/tests/models/segformer/test_modeling_segformer.py  \n",
            "  inflating: transformers-main/tests/models/segformer/test_modeling_tf_segformer.py  \n",
            " extracting: transformers-main/tests/models/segformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/sew/test_modeling_sew.py  \n",
            " extracting: transformers-main/tests/models/sew/__init__.py  \n",
            "  inflating: transformers-main/tests/models/sew_d/test_modeling_sew_d.py  \n",
            " extracting: transformers-main/tests/models/sew_d/__init__.py  \n",
            "  inflating: transformers-main/tests/models/speech_encoder_decoder/test_modeling_flax_speech_encoder_decoder.py  \n",
            "  inflating: transformers-main/tests/models/speech_encoder_decoder/test_modeling_speech_encoder_decoder.py  \n",
            " extracting: transformers-main/tests/models/speech_encoder_decoder/__init__.py  \n",
            "  inflating: transformers-main/tests/models/speech_to_text/test_feature_extraction_speech_to_text.py  \n",
            "  inflating: transformers-main/tests/models/speech_to_text/test_modeling_speech_to_text.py  \n",
            "  inflating: transformers-main/tests/models/speech_to_text/test_modeling_tf_speech_to_text.py  \n",
            "  inflating: transformers-main/tests/models/speech_to_text/test_processor_speech_to_text.py  \n",
            "  inflating: transformers-main/tests/models/speech_to_text/test_tokenization_speech_to_text.py  \n",
            " extracting: transformers-main/tests/models/speech_to_text/__init__.py  \n",
            "  inflating: transformers-main/tests/models/speech_to_text_2/test_modeling_speech_to_text_2.py  \n",
            "  inflating: transformers-main/tests/models/speech_to_text_2/test_tokenization_speech_to_text_2.py  \n",
            " extracting: transformers-main/tests/models/speech_to_text_2/__init__.py  \n",
            "  inflating: transformers-main/tests/models/splinter/test_modeling_splinter.py  \n",
            " extracting: transformers-main/tests/models/splinter/__init__.py  \n",
            "  inflating: transformers-main/tests/models/squeezebert/test_modeling_squeezebert.py  \n",
            "  inflating: transformers-main/tests/models/squeezebert/test_tokenization_squeezebert.py  \n",
            " extracting: transformers-main/tests/models/squeezebert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/swin/test_modeling_swin.py  \n",
            "  inflating: transformers-main/tests/models/swin/test_modeling_tf_swin.py  \n",
            " extracting: transformers-main/tests/models/swin/__init__.py  \n",
            "  inflating: transformers-main/tests/models/swinv2/test_modeling_swinv2.py  \n",
            " extracting: transformers-main/tests/models/swinv2/__init__.py  \n",
            "  inflating: transformers-main/tests/models/t5/test_modeling_flax_t5.py  \n",
            "  inflating: transformers-main/tests/models/t5/test_modeling_t5.py  \n",
            "  inflating: transformers-main/tests/models/t5/test_modeling_tf_t5.py  \n",
            "  inflating: transformers-main/tests/models/t5/test_tokenization_t5.py  \n",
            " extracting: transformers-main/tests/models/t5/__init__.py  \n",
            "  inflating: transformers-main/tests/models/tapas/test_modeling_tapas.py  \n",
            "  inflating: transformers-main/tests/models/tapas/test_modeling_tf_tapas.py  \n",
            "  inflating: transformers-main/tests/models/tapas/test_tokenization_tapas.py  \n",
            " extracting: transformers-main/tests/models/tapas/__init__.py  \n",
            "  inflating: transformers-main/tests/models/tapex/test_tokenization_tapex.py  \n",
            " extracting: transformers-main/tests/models/tapex/__init__.py  \n",
            "  inflating: transformers-main/tests/models/time_series_transformer/test_modeling_time_series_transformer.py  \n",
            " extracting: transformers-main/tests/models/time_series_transformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/trajectory_transformer/test_modeling_trajectory_transformer.py  \n",
            " extracting: transformers-main/tests/models/trajectory_transformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/transfo_xl/test_modeling_tf_transfo_xl.py  \n",
            "  inflating: transformers-main/tests/models/transfo_xl/test_modeling_transfo_xl.py  \n",
            "  inflating: transformers-main/tests/models/transfo_xl/test_tokenization_transfo_xl.py  \n",
            " extracting: transformers-main/tests/models/transfo_xl/__init__.py  \n",
            "  inflating: transformers-main/tests/models/trocr/test_modeling_trocr.py  \n",
            " extracting: transformers-main/tests/models/trocr/__init__.py  \n",
            "  inflating: transformers-main/tests/models/unispeech/test_modeling_unispeech.py  \n",
            " extracting: transformers-main/tests/models/unispeech/__init__.py  \n",
            "  inflating: transformers-main/tests/models/unispeech_sat/test_modeling_unispeech_sat.py  \n",
            " extracting: transformers-main/tests/models/unispeech_sat/__init__.py  \n",
            "  inflating: transformers-main/tests/models/van/test_modeling_van.py  \n",
            " extracting: transformers-main/tests/models/van/__init__.py  \n",
            "  inflating: transformers-main/tests/models/videomae/test_feature_extraction_videomae.py  \n",
            "  inflating: transformers-main/tests/models/videomae/test_modeling_videomae.py  \n",
            " extracting: transformers-main/tests/models/videomae/__init__.py  \n",
            "  inflating: transformers-main/tests/models/vilt/test_feature_extraction_vilt.py  \n",
            "  inflating: transformers-main/tests/models/vilt/test_modeling_vilt.py  \n",
            " extracting: transformers-main/tests/models/vilt/__init__.py  \n",
            "  inflating: transformers-main/tests/models/vision_encoder_decoder/test_modeling_flax_vision_encoder_decoder.py  \n",
            "  inflating: transformers-main/tests/models/vision_encoder_decoder/test_modeling_tf_vision_encoder_decoder.py  \n",
            "  inflating: transformers-main/tests/models/vision_encoder_decoder/test_modeling_vision_encoder_decoder.py  \n",
            " extracting: transformers-main/tests/models/vision_encoder_decoder/__init__.py  \n",
            "  inflating: transformers-main/tests/models/vision_text_dual_encoder/test_modeling_flax_vision_text_dual_encoder.py  \n",
            "  inflating: transformers-main/tests/models/vision_text_dual_encoder/test_modeling_vision_text_dual_encoder.py  \n",
            "  inflating: transformers-main/tests/models/vision_text_dual_encoder/test_processor_vision_text_dual_encoder.py  \n",
            " extracting: transformers-main/tests/models/vision_text_dual_encoder/__init__.py  \n",
            "  inflating: transformers-main/tests/models/visual_bert/test_modeling_visual_bert.py  \n",
            " extracting: transformers-main/tests/models/visual_bert/__init__.py  \n",
            "  inflating: transformers-main/tests/models/vit/test_feature_extraction_vit.py  \n",
            "  inflating: transformers-main/tests/models/vit/test_modeling_flax_vit.py  \n",
            "  inflating: transformers-main/tests/models/vit/test_modeling_tf_vit.py  \n",
            "  inflating: transformers-main/tests/models/vit/test_modeling_vit.py  \n",
            " extracting: transformers-main/tests/models/vit/__init__.py  \n",
            "  inflating: transformers-main/tests/models/vit_mae/test_modeling_tf_vit_mae.py  \n",
            "  inflating: transformers-main/tests/models/vit_mae/test_modeling_vit_mae.py  \n",
            " extracting: transformers-main/tests/models/vit_mae/__init__.py  \n",
            "  inflating: transformers-main/tests/models/vit_msn/test_modeling_vit_msn.py  \n",
            " extracting: transformers-main/tests/models/vit_msn/__init__.py  \n",
            "  inflating: transformers-main/tests/models/wav2vec2/test_feature_extraction_wav2vec2.py  \n",
            "  inflating: transformers-main/tests/models/wav2vec2/test_modeling_flax_wav2vec2.py  \n",
            "  inflating: transformers-main/tests/models/wav2vec2/test_modeling_tf_wav2vec2.py  \n",
            "  inflating: transformers-main/tests/models/wav2vec2/test_modeling_wav2vec2.py  \n",
            "  inflating: transformers-main/tests/models/wav2vec2/test_processor_wav2vec2.py  \n",
            "  inflating: transformers-main/tests/models/wav2vec2/test_tokenization_wav2vec2.py  \n",
            " extracting: transformers-main/tests/models/wav2vec2/__init__.py  \n",
            "  inflating: transformers-main/tests/models/wav2vec2_conformer/test_modeling_wav2vec2_conformer.py  \n",
            " extracting: transformers-main/tests/models/wav2vec2_conformer/__init__.py  \n",
            "  inflating: transformers-main/tests/models/wav2vec2_phoneme/test_tokenization_wav2vec2_phoneme.py  \n",
            " extracting: transformers-main/tests/models/wav2vec2_phoneme/__init__.py  \n",
            "  inflating: transformers-main/tests/models/wav2vec2_with_lm/test_processor_wav2vec2_with_lm.py  \n",
            " extracting: transformers-main/tests/models/wav2vec2_with_lm/__init__.py  \n",
            "  inflating: transformers-main/tests/models/wavlm/test_modeling_wavlm.py  \n",
            " extracting: transformers-main/tests/models/wavlm/__init__.py  \n",
            "  inflating: transformers-main/tests/models/whisper/test_feature_extraction_whisper.py  \n",
            "  inflating: transformers-main/tests/models/whisper/test_modeling_tf_whisper.py  \n",
            "  inflating: transformers-main/tests/models/whisper/test_modeling_whisper.py  \n",
            "  inflating: transformers-main/tests/models/whisper/test_processor_whisper.py  \n",
            "  inflating: transformers-main/tests/models/whisper/test_tokenization_whisper.py  \n",
            " extracting: transformers-main/tests/models/whisper/__init__.py  \n",
            "  inflating: transformers-main/tests/models/xglm/test_modeling_flax_xglm.py  \n",
            "  inflating: transformers-main/tests/models/xglm/test_modeling_tf_xglm.py  \n",
            "  inflating: transformers-main/tests/models/xglm/test_modeling_xglm.py  \n",
            "  inflating: transformers-main/tests/models/xglm/test_tokenization_xglm.py  \n",
            " extracting: transformers-main/tests/models/xglm/__init__.py  \n",
            "  inflating: transformers-main/tests/models/xlm/test_modeling_tf_xlm.py  \n",
            "  inflating: transformers-main/tests/models/xlm/test_modeling_xlm.py  \n",
            "  inflating: transformers-main/tests/models/xlm/test_tokenization_xlm.py  \n",
            " extracting: transformers-main/tests/models/xlm/__init__.py  \n",
            "  inflating: transformers-main/tests/models/xlm_prophetnet/test_modeling_xlm_prophetnet.py  \n",
            "  inflating: transformers-main/tests/models/xlm_prophetnet/test_tokenization_xlm_prophetnet.py  \n",
            " extracting: transformers-main/tests/models/xlm_prophetnet/__init__.py  \n",
            "  inflating: transformers-main/tests/models/xlm_roberta/test_modeling_flax_xlm_roberta.py  \n",
            "  inflating: transformers-main/tests/models/xlm_roberta/test_modeling_tf_xlm_roberta.py  \n",
            "  inflating: transformers-main/tests/models/xlm_roberta/test_modeling_xlm_roberta.py  \n",
            "  inflating: transformers-main/tests/models/xlm_roberta/test_tokenization_xlm_roberta.py  \n",
            " extracting: transformers-main/tests/models/xlm_roberta/__init__.py  \n",
            "  inflating: transformers-main/tests/models/xlm_roberta_xl/test_modeling_xlm_roberta_xl.py  \n",
            " extracting: transformers-main/tests/models/xlm_roberta_xl/__init__.py  \n",
            "  inflating: transformers-main/tests/models/xlnet/test_modeling_tf_xlnet.py  \n",
            "  inflating: transformers-main/tests/models/xlnet/test_modeling_xlnet.py  \n",
            "  inflating: transformers-main/tests/models/xlnet/test_tokenization_xlnet.py  \n",
            " extracting: transformers-main/tests/models/xlnet/__init__.py  \n",
            "  inflating: transformers-main/tests/models/x_clip/test_modeling_x_clip.py  \n",
            " extracting: transformers-main/tests/models/x_clip/__init__.py  \n",
            "  inflating: transformers-main/tests/models/yolos/test_feature_extraction_yolos.py  \n",
            "  inflating: transformers-main/tests/models/yolos/test_modeling_yolos.py  \n",
            " extracting: transformers-main/tests/models/yolos/__init__.py  \n",
            "  inflating: transformers-main/tests/models/yoso/test_modeling_yoso.py  \n",
            " extracting: transformers-main/tests/models/yoso/__init__.py  \n",
            " extracting: transformers-main/tests/models/__init__.py  \n",
            "  inflating: transformers-main/tests/onnx/test_features.py  \n",
            "  inflating: transformers-main/tests/onnx/test_onnx.py  \n",
            "  inflating: transformers-main/tests/onnx/test_onnx_v2.py  \n",
            " extracting: transformers-main/tests/onnx/__init__.py  \n",
            "  inflating: transformers-main/tests/optimization/test_optimization.py  \n",
            "  inflating: transformers-main/tests/optimization/test_optimization_tf.py  \n",
            " extracting: transformers-main/tests/optimization/__init__.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_audio_classification.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_automatic_speech_recognition.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_common.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_conversational.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_depth_estimation.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_document_question_answering.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_feature_extraction.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_fill_mask.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_image_classification.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_image_segmentation.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_image_to_text.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_object_detection.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_question_answering.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_summarization.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_table_question_answering.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_text2text_generation.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_text_classification.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_text_generation.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_token_classification.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_translation.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_visual_question_answering.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_zero_shot.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_zero_shot_image_classification.py  \n",
            "  inflating: transformers-main/tests/pipelines/test_pipelines_zero_shot_object_detection.py  \n",
            " extracting: transformers-main/tests/pipelines/__init__.py  \n",
            "  inflating: transformers-main/tests/repo_utils/test_check_copies.py  \n",
            "  inflating: transformers-main/tests/repo_utils/test_check_dummies.py  \n",
            "  inflating: transformers-main/tests/sagemaker/conftest.py  \n",
            "  inflating: transformers-main/tests/sagemaker/README.md  \n",
            "  inflating: transformers-main/tests/sagemaker/scripts/pytorch/requirements.txt  \n",
            "  inflating: transformers-main/tests/sagemaker/scripts/pytorch/run_ddp.py  \n",
            "  inflating: transformers-main/tests/sagemaker/scripts/pytorch/run_glue_model_parallelism.py  \n",
            "  inflating: transformers-main/tests/sagemaker/scripts/tensorflow/requirements.txt  \n",
            "  inflating: transformers-main/tests/sagemaker/scripts/tensorflow/run_tf.py  \n",
            "  inflating: transformers-main/tests/sagemaker/scripts/tensorflow/run_tf_dist.py  \n",
            "  inflating: transformers-main/tests/sagemaker/test_multi_node_data_parallel.py  \n",
            "  inflating: transformers-main/tests/sagemaker/test_multi_node_model_parallel.py  \n",
            "  inflating: transformers-main/tests/sagemaker/test_single_node_gpu.py  \n",
            "  inflating: transformers-main/tests/sagemaker/__init__.py  \n",
            "  inflating: transformers-main/tests/test_configuration_common.py  \n",
            "  inflating: transformers-main/tests/test_feature_extraction_common.py  \n",
            "  inflating: transformers-main/tests/test_image_transforms.py  \n",
            "  inflating: transformers-main/tests/test_modeling_common.py  \n",
            "  inflating: transformers-main/tests/test_modeling_flax_common.py  \n",
            "  inflating: transformers-main/tests/test_modeling_tf_common.py  \n",
            "  inflating: transformers-main/tests/test_sequence_feature_extraction_common.py  \n",
            "  inflating: transformers-main/tests/test_tokenization_common.py  \n",
            "  inflating: transformers-main/tests/tokenization/test_tokenization_fast.py  \n",
            "  inflating: transformers-main/tests/tokenization/test_tokenization_utils.py  \n",
            " extracting: transformers-main/tests/tokenization/__init__.py  \n",
            "  inflating: transformers-main/tests/trainer/test_data_collator.py  \n",
            "  inflating: transformers-main/tests/trainer/test_trainer.py  \n",
            "  inflating: transformers-main/tests/trainer/test_trainer_callback.py  \n",
            "  inflating: transformers-main/tests/trainer/test_trainer_distributed.py  \n",
            "  inflating: transformers-main/tests/trainer/test_trainer_seq2seq.py  \n",
            "  inflating: transformers-main/tests/trainer/test_trainer_tpu.py  \n",
            "  inflating: transformers-main/tests/trainer/test_trainer_utils.py  \n",
            " extracting: transformers-main/tests/trainer/__init__.py  \n",
            "  inflating: transformers-main/tests/utils/test_activations.py  \n",
            "  inflating: transformers-main/tests/utils/test_activations_tf.py  \n",
            "  inflating: transformers-main/tests/utils/test_add_new_model_like.py  \n",
            "  inflating: transformers-main/tests/utils/test_cli.py  \n",
            "  inflating: transformers-main/tests/utils/test_convert_slow_tokenizer.py  \n",
            "  inflating: transformers-main/tests/utils/test_doc_samples.py  \n",
            "  inflating: transformers-main/tests/utils/test_file_utils.py  \n",
            "  inflating: transformers-main/tests/utils/test_generic.py  \n",
            "  inflating: transformers-main/tests/utils/test_hf_argparser.py  \n",
            "  inflating: transformers-main/tests/utils/test_hub_utils.py  \n",
            "  inflating: transformers-main/tests/utils/test_image_utils.py  \n",
            "  inflating: transformers-main/tests/utils/test_logging.py  \n",
            "  inflating: transformers-main/tests/utils/test_modeling_tf_core.py  \n",
            "  inflating: transformers-main/tests/utils/test_model_card.py  \n",
            "  inflating: transformers-main/tests/utils/test_model_output.py  \n",
            "  inflating: transformers-main/tests/utils/test_offline.py  \n",
            "  inflating: transformers-main/tests/utils/test_skip_decorators.py  \n",
            "  inflating: transformers-main/tests/utils/test_versions_utils.py  \n",
            " extracting: transformers-main/tests/utils/__init__.py  \n",
            " extracting: transformers-main/tests/__init__.py  \n",
            "  inflating: transformers-main/utils/check_config_docstrings.py  \n",
            "  inflating: transformers-main/utils/check_copies.py  \n",
            "  inflating: transformers-main/utils/check_doc_toc.py  \n",
            "  inflating: transformers-main/utils/check_dummies.py  \n",
            "  inflating: transformers-main/utils/check_inits.py  \n",
            "  inflating: transformers-main/utils/check_repo.py  \n",
            "  inflating: transformers-main/utils/check_self_hosted_runner.py  \n",
            "  inflating: transformers-main/utils/check_table.py  \n",
            "  inflating: transformers-main/utils/check_tf_ops.py  \n",
            "  inflating: transformers-main/utils/custom_init_isort.py  \n",
            "  inflating: transformers-main/utils/documentation_tests.txt  \n",
            "  inflating: transformers-main/utils/download_glue_data.py  \n",
            "  inflating: transformers-main/utils/get_ci_error_statistics.py  \n",
            "  inflating: transformers-main/utils/get_github_job_time.py  \n",
            "  inflating: transformers-main/utils/get_modified_files.py  \n",
            "  inflating: transformers-main/utils/notification_service.py  \n",
            "  inflating: transformers-main/utils/notification_service_doc_tests.py  \n",
            "  inflating: transformers-main/utils/past_ci_versions.py  \n",
            "  inflating: transformers-main/utils/prepare_for_doc_test.py  \n",
            "  inflating: transformers-main/utils/print_env.py  \n",
            "  inflating: transformers-main/utils/release.py  \n",
            "  inflating: transformers-main/utils/sort_auto_mappings.py  \n",
            "  inflating: transformers-main/utils/tests_fetcher.py  \n",
            "  inflating: transformers-main/utils/test_module/custom_configuration.py  \n",
            "  inflating: transformers-main/utils/test_module/custom_feature_extraction.py  \n",
            "  inflating: transformers-main/utils/test_module/custom_modeling.py  \n",
            "  inflating: transformers-main/utils/test_module/custom_pipeline.py  \n",
            "  inflating: transformers-main/utils/test_module/custom_processing.py  \n",
            "  inflating: transformers-main/utils/test_module/custom_tokenization.py  \n",
            "  inflating: transformers-main/utils/test_module/custom_tokenization_fast.py  \n",
            " extracting: transformers-main/utils/test_module/__init__.py  \n",
            "  inflating: transformers-main/utils/tf_ops/onnx.json  \n",
            "  inflating: transformers-main/utils/update_metadata.py  \n",
            "/content/gdrive/MyDrive/trans-2022-17/transformers-main\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/gdrive/MyDrive/trans-2022-17/transformers-main\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.24.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.24.0.dev0) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.24.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.24.0.dev0) (23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.24.0.dev0) (3.10.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.24.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.24.0.dev0) (2022.10.31)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.24.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.24.0.dev0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.24.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.24.0.dev0) (2.0.12)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.24.0.dev0-py3-none-any.whl size=5458489 sha256=5a58c51ff9802cfe2e55b87ee02af60a05c1f832486734c4ed047b0ddff5b9ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/c0/cf/1f2237502faf2ac615895f16e1fe2349d896c7d8f0e069e08b\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.24.0.dev0\n"
          ]
        }
      ],
      "source": [
        "%cd\n",
        "%cd /content/gdrive/MyDrive/\n",
        "!git clone https://github.com/cyrus1123/trans-2022-17.git\n",
        "%cd trans-2022-17\n",
        "!unzip transformers-main.zip\n",
        "%cd transformers-main\n",
        "!pip install /content/gdrive/MyDrive/trans-2022-17/transformers-main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdTXjqh249Vv"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBds2N-tNxNX",
        "outputId": "a6080dbe-d41e-4819-c0d0-896e77230904"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'Transformer_BigBird' from 'transformers' (c:\\Users\\kheli\\anaconda3\\lib\\site-packages\\transformers\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32md:\\Work\\Cyrus\\API_FTransformer_ECT2023_04_07[12295].ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m CrossEntropyLoss, MSELoss\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m Transformer_BigBird\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m BIG_BIRD_PRETRAINED_MODEL_ARCHIVE_LIST \u001b[39m=\u001b[39m [\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgoogle/bigbird-roberta-base\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgoogle/bigbird-roberta-large\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgoogle/bigbird-base-trivia-itc\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# See all BigBird models at https://huggingface.co/models?filter=big_bird\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m _TRIVIA_QA_MAPPING \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbig_bird_attention\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mattention/self\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_layer_norm\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39moutput/LayerNorm\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdense_1\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mqa_outputs\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#W6sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m }\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'Transformer_BigBird' from 'transformers' (c:\\Users\\kheli\\anaconda3\\lib\\site-packages\\transformers\\__init__.py)"
          ]
        }
      ],
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2021 Google Research and The HuggingFace Inc. team. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\" PyTorch BigBird model. \"\"\"\n",
        "\n",
        "\n",
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "from transformers import Transformer_BigBird\n",
        "\n",
        "\n",
        "BIG_BIRD_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
        "    \"google/bigbird-roberta-base\",\n",
        "    \"google/bigbird-roberta-large\",\n",
        "    \"google/bigbird-base-trivia-itc\",\n",
        "    # See all BigBird models at https://huggingface.co/models?filter=big_bird\n",
        "]\n",
        "\n",
        "_TRIVIA_QA_MAPPING = {\n",
        "    \"big_bird_attention\": \"attention/self\",\n",
        "    \"output_layer_norm\": \"output/LayerNorm\",\n",
        "    \"attention_output\": \"attention/output/dense\",\n",
        "    \"output\": \"output/dense\",\n",
        "    \"self_attention_layer_norm\": \"attention/output/LayerNorm\",\n",
        "    \"intermediate\": \"intermediate/dense\",\n",
        "    \"word_embeddings\": \"bert/embeddings/word_embeddings\",\n",
        "    \"position_embedding\": \"bert/embeddings/position_embeddings\",\n",
        "    \"type_embeddings\": \"bert/embeddings/token_type_embeddings\",\n",
        "    \"embeddings\": \"bert/embeddings\",\n",
        "    \"layer_normalization\": \"output/LayerNorm\",\n",
        "    \"layer_norm\": \"LayerNorm\",\n",
        "    \"trivia_qa_head\": \"qa_classifier\",\n",
        "    \"dense\": \"intermediate/dense\",\n",
        "    \"dense_1\": \"qa_outputs\",\n",
        "}\n",
        "\n",
        "\n",
        "config='big_bird'\n",
        "def load_tf_weights_in_big_bird(model, tf_checkpoint_path, is_trivia_qa=False):\n",
        "    \"\"\"Load tf checkpoints in a pytorch model.\"\"\"\n",
        "\n",
        "    def load_tf_weights_bert(init_vars, tf_path):\n",
        "        names = []\n",
        "        tf_weights = {}\n",
        "\n",
        "        for name, shape in init_vars:\n",
        "            array = tf.train.load_variable(tf_path, name)\n",
        "            name = name.replace(\"bert/encoder/LayerNorm\", \"bert/embeddings/LayerNorm\")\n",
        "            logger.info(f\"Loading TF weight {name} with shape {shape}\")\n",
        "            names.append(name)\n",
        "            tf_weights[name] = array\n",
        "\n",
        "        return names, tf_weights\n",
        "\n",
        "    def load_tf_weights_trivia_qa(init_vars):\n",
        "        names = []\n",
        "        tf_weights = {}\n",
        "\n",
        "        for i, var in enumerate(init_vars):\n",
        "            name_items = var.name.split(\"/\")\n",
        "\n",
        "            if \"transformer_scaffold\" in name_items[0]:\n",
        "                layer_name_items = name_items[0].split(\"_\")\n",
        "                if len(layer_name_items) < 3:\n",
        "                    layer_name_items += [0]\n",
        "\n",
        "                name_items[0] = f\"bert/encoder/layer_{layer_name_items[2]}\"\n",
        "\n",
        "            name = \"/\".join([_TRIVIA_QA_MAPPING[x] if x in _TRIVIA_QA_MAPPING else x for x in name_items])[\n",
        "                :-2\n",
        "            ]  # remove last :0 in variable\n",
        "\n",
        "            if \"self/attention/output\" in name:\n",
        "                name = name.replace(\"self/attention/output\", \"output\")\n",
        "\n",
        "            if i >= len(init_vars) - 2:\n",
        "                name = name.replace(\"intermediate\", \"output\")\n",
        "\n",
        "            logger.info(f\"Loading TF weight {name} with shape {var.shape}\")\n",
        "            array = var.value().numpy()\n",
        "            names.append(name)\n",
        "            tf_weights[name] = array\n",
        "\n",
        "        return names, tf_weights\n",
        "\n",
        "    try:\n",
        "        import re\n",
        "\n",
        "        import numpy as np\n",
        "        import tensorflow as tf\n",
        "    except ImportError:\n",
        "        logger.error(\n",
        "            \"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"\n",
        "            \"https://www.tensorflow.org/install/ for installation instructions.\"\n",
        "        )\n",
        "        raise\n",
        "    tf_path = os.path.abspath(tf_checkpoint_path)\n",
        "    logger.info(f\"Converting TensorFlow checkpoint from {tf_path}\")\n",
        "\n",
        "    # Load weights from TF model\n",
        "    init_vars = tf.saved_model.load(tf_path).variables if is_trivia_qa else tf.train.list_variables(tf_path)\n",
        "\n",
        "    assert len(init_vars) > 0, \"Loaded trained variables cannot be empty.\"\n",
        "\n",
        "    pt_names = list(model.state_dict().keys())\n",
        "\n",
        "    if is_trivia_qa:\n",
        "        names, tf_weights = load_tf_weights_trivia_qa(init_vars)\n",
        "    else:\n",
        "        names, tf_weights = load_tf_weights_bert(init_vars, tf_path)\n",
        "\n",
        "    for txt_name in names:\n",
        "        array = tf_weights[txt_name]\n",
        "        name = txt_name.split(\"/\")\n",
        "        # adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v\n",
        "        # which are not required for using pretrained model\n",
        "        if any(\n",
        "            n in [\"adam_v\", \"adam_m\", \"AdamWeightDecayOptimizer\", \"AdamWeightDecayOptimizer_1\", \"global_step\"]\n",
        "            for n in name\n",
        "        ):\n",
        "            logger.info(f\"Skipping {'/'.join(name)}\")\n",
        "            continue\n",
        "        pointer = model\n",
        "        pt_name = []\n",
        "        for m_name in name:\n",
        "            if re.fullmatch(r\"[A-Za-z]+_\\d+\", m_name):\n",
        "                scope_names = re.split(r\"_(\\d+)\", m_name)\n",
        "            else:\n",
        "                scope_names = [m_name]\n",
        "            if scope_names[0] == \"kernel\" or scope_names[0] == \"gamma\":\n",
        "                pointer = getattr(pointer, \"weight\")\n",
        "                pt_name.append(\"weight\")\n",
        "            elif scope_names[0] == \"output_bias\" or scope_names[0] == \"beta\":\n",
        "                pointer = getattr(pointer, \"bias\")\n",
        "                pt_name.append(\"bias\")\n",
        "            elif scope_names[0] == \"output_weights\":\n",
        "                pointer = getattr(pointer, \"weight\")\n",
        "                pt_name.append(\"weight\")\n",
        "            elif scope_names[0] == \"squad\":\n",
        "                pointer = getattr(pointer, \"classifier\")\n",
        "                pt_name.append(\"classifier\")\n",
        "            elif scope_names[0] == \"transform\":\n",
        "                pointer = getattr(pointer, \"transform\")\n",
        "                pt_name.append(\"transform\")\n",
        "                if (\"bias\" in name) or (\"kernel\" in name):\n",
        "                    pointer = getattr(pointer, \"dense\")\n",
        "                    pt_name.append(\"dense\")\n",
        "                elif (\"beta\" in name) or (\"gamma\" in name):\n",
        "                    pointer = getattr(pointer, \"LayerNorm\")\n",
        "                    pt_name.append(\"LayerNorm\")\n",
        "            else:\n",
        "                try:\n",
        "                    pointer = getattr(pointer, scope_names[0])\n",
        "                    pt_name.append(f\"{scope_names[0]}\")\n",
        "                except AttributeError:\n",
        "                    logger.info(f\"Skipping {m_name}\")\n",
        "                    continue\n",
        "            if len(scope_names) >= 2:\n",
        "                num = int(scope_names[1])\n",
        "                pointer = pointer[num]\n",
        "                pt_name.append(f\"{num}\")\n",
        "        if m_name[-11:] == \"_embeddings\" or m_name == \"embeddings\":\n",
        "            pointer = getattr(pointer, \"weight\")\n",
        "            pt_name.append(\"weight\")\n",
        "        elif m_name == \"kernel\":\n",
        "            array = np.transpose(array)\n",
        "        try:\n",
        "            if len(array.shape) > len(pointer.shape) and math.prod(array.shape) == math.prod(pointer.shape):\n",
        "                # print(txt_name, array.shape)\n",
        "                if (\n",
        "                    txt_name.endswith(\"attention/self/key/kernel\")\n",
        "                    or txt_name.endswith(\"attention/self/query/kernel\")\n",
        "                    or txt_name.endswith(\"attention/self/value/kernel\")\n",
        "                ):\n",
        "                    array = array.transpose(1, 0, 2).reshape(pointer.shape)\n",
        "                elif txt_name.endswith(\"attention/output/dense/kernel\"):\n",
        "                    array = array.transpose(0, 2, 1).reshape(pointer.shape)\n",
        "                else:\n",
        "                    array = array.reshape(pointer.shape)\n",
        "\n",
        "            if pointer.shape != array.shape:\n",
        "                raise ValueError(\n",
        "                    f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched of {txt_name}.\"\n",
        "                )\n",
        "        except AssertionError as e:\n",
        "            e.args += (pointer.shape, array.shape)\n",
        "            raise\n",
        "        pt_weight_name = \".\".join(pt_name)\n",
        "        logger.info(f\"Initialize PyTorch weight {pt_weight_name} from {txt_name}.\")\n",
        "        pointer.data = torch.from_numpy(array)\n",
        "        tf_weights.pop(txt_name, None)\n",
        "        pt_names.remove(pt_weight_name)\n",
        "\n",
        "    logger.info(f\"Weights not copied to PyTorch model: {', '.join(tf_weights.keys())}.\")\n",
        "    logger.info(f\"Weights not initialized in PyTorch model: {', '.join(pt_names)}.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "class BigBirdEmbeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\"\"\"\n",
        "\n",
        "    # Copied from transformers.models.bert.modeling_bert.BertEmbeddings.__init__\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
        "        # any TensorFlow checkpoint file\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # position_ids (1, len position emb) is contiguous in memory and exported when serialized\n",
        "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n",
        "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
        "        # End copy\n",
        "\n",
        "        self.rescale_embeddings = config.rescale_embeddings\n",
        "        self.hidden_size = config.hidden_size\n",
        "\n",
        "    def forward(\n",
        "        self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None, past_key_values_length=0\n",
        "    ):\n",
        "        if input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        else:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "\n",
        "        seq_length = input_shape[1]\n",
        "\n",
        "        if position_ids is None:\n",
        "            position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.word_embeddings(input_ids)\n",
        "\n",
        "        if self.rescale_embeddings:\n",
        "            inputs_embeds = inputs_embeds * (self.hidden_size ** 0.5)\n",
        "\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        embeddings = inputs_embeds + token_type_embeddings\n",
        "\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        embeddings += position_embeddings\n",
        "\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class BigBirdSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size, bias=config.use_bias)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size, bias=config.use_bias)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size, bias=config.use_bias)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_value=None,\n",
        "        output_attentions=False,\n",
        "    ):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_layer = past_key_value[0]\n",
        "            value_layer = past_key_value[1]\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif past_key_value is not None:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
        "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BigBirdModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class BigBirdBlockSparseAttention(nn.Module):\n",
        "    def __init__(self, config, seed=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.max_seqlen = config.max_position_embeddings\n",
        "        self.seed = seed\n",
        "\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n",
        "                f\"heads {config.num_attention_heads}.\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.num_random_blocks = config.num_random_blocks\n",
        "        self.block_size = config.block_size\n",
        "\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size, bias=config.use_bias)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size, bias=config.use_bias)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size, bias=config.use_bias)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        band_mask=None,\n",
        "        from_mask=None,\n",
        "        to_mask=None,\n",
        "        from_blocked_mask=None,\n",
        "        to_blocked_mask=None,\n",
        "        output_attentions=None,\n",
        "    ):\n",
        "        # Currently this `class` can't be used in decoder.\n",
        "\n",
        "        batch_size, seqlen, _ = hidden_states.size()\n",
        "        to_seq_length = from_seq_length = seqlen\n",
        "        from_block_size = to_block_size = self.block_size\n",
        "\n",
        "        assert from_seq_length % from_block_size == 0, \"Query sided sequence length must be multiple of block size\"\n",
        "        assert to_seq_length % to_block_size == 0, \"Key/Value sided sequence length must be multiple of block size\"\n",
        "\n",
        "        query_layer = self.transpose_for_scores(self.query(hidden_states))\n",
        "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        context_layer, attention_probs = self.bigbird_block_sparse_attention(\n",
        "            query_layer,\n",
        "            key_layer,\n",
        "            value_layer,\n",
        "            band_mask,\n",
        "            from_mask,\n",
        "            to_mask,\n",
        "            from_blocked_mask,\n",
        "            to_blocked_mask,\n",
        "            self.num_attention_heads,\n",
        "            self.num_random_blocks,\n",
        "            self.attention_head_size,\n",
        "            from_block_size,\n",
        "            to_block_size,\n",
        "            batch_size,\n",
        "            from_seq_length,\n",
        "            to_seq_length,\n",
        "            seed=self.seed,\n",
        "            plan_from_length=None,\n",
        "            plan_num_rand_blocks=None,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "\n",
        "        context_layer = context_layer.contiguous().view(batch_size, from_seq_length, -1)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "        return outputs\n",
        "\n",
        "    @staticmethod\n",
        "    def torch_bmm_nd(inp_1, inp_2, ndim=None):\n",
        "        \"\"\"Fast nd matrix multiplication\"\"\"\n",
        "        # faster replacement of torch.einsum (\"bhqk,bhkd->bhqd\")\n",
        "        return torch.bmm(inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:])).view(\n",
        "            inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 1])\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def torch_bmm_nd_transpose(inp_1, inp_2, ndim=None):\n",
        "        \"\"\"Fast nd matrix multiplication with transpose\"\"\"\n",
        "        # faster replacement of torch.einsum (bhqd,bhkd->bhqk)\n",
        "        return torch.bmm(\n",
        "            inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:]).transpose(1, 2)\n",
        "        ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 2]))\n",
        "\n",
        "    def bigbird_block_sparse_attention(\n",
        "        self,\n",
        "        query_layer,\n",
        "        key_layer,\n",
        "        value_layer,\n",
        "        band_mask,\n",
        "        from_mask,\n",
        "        to_mask,\n",
        "        from_blocked_mask,\n",
        "        to_blocked_mask,\n",
        "        n_heads,\n",
        "        n_rand_blocks,\n",
        "        attention_head_size,\n",
        "        from_block_size,\n",
        "        to_block_size,\n",
        "        batch_size,\n",
        "        from_seq_len,\n",
        "        to_seq_len,\n",
        "        seed,\n",
        "        plan_from_length,\n",
        "        plan_num_rand_blocks,\n",
        "        output_attentions,\n",
        "    ):\n",
        "\n",
        "        # BigBird block-sparse attention as suggested in paper\n",
        "\n",
        "        # ITC:\n",
        "        #     global tokens: 2 x block_size\n",
        "        #     window tokens: 3 x block_size\n",
        "        #     random tokens: num_rand_tokens x block_size\n",
        "\n",
        "        # ETC:\n",
        "        #     global tokens: extra_globals_tokens + 2 x block_size\n",
        "        #     window tokens: 3 x block_size\n",
        "        #     random tokens: num_rand_tokens x block_size\n",
        "\n",
        "        # Note:\n",
        "        #     1) Currently, ETC is not supported.\n",
        "        #     2) Window size is fixed to 3 blocks & it can be changed only by\n",
        "        #     changing `block_size`.\n",
        "        #     3) Number of global blocks are fixed (2 blocks here) & global tokens can be\n",
        "        #     controlled only by `block_size`.\n",
        "\n",
        "        # attention is calculated separately for q[0], q[1], q[2:-2], q[-2], q[-1] in order to use special trick of shifting tokens (for calculating sliding attention)\n",
        "        # hence following code can be divided into 5 parts.\n",
        "\n",
        "        if from_seq_len // from_block_size != to_seq_len // to_block_size:\n",
        "            raise ValueError(\"Error the number of blocks needs to be same!\")\n",
        "\n",
        "        rsqrt_d = 1 / math.sqrt(attention_head_size)\n",
        "        bsz = batch_size\n",
        "\n",
        "        # generate random attention and corresponding masks\n",
        "        np.random.seed(seed)\n",
        "        if from_seq_len in [1024, 3072, 4096]:  # old plans used in paper\n",
        "            rand_attn = [\n",
        "                self._bigbird_block_rand_mask(\n",
        "                    self.max_seqlen, self.max_seqlen, from_block_size, to_block_size, n_rand_blocks, last_idx=1024\n",
        "                )[: (from_seq_len // from_block_size - 2)]\n",
        "                for _ in range(n_heads)\n",
        "            ]\n",
        "        else:\n",
        "            if plan_from_length is None:\n",
        "                plan_from_length, plan_num_rand_blocks = self._get_rand_attn_plan(\n",
        "                    from_seq_len, from_block_size, n_rand_blocks\n",
        "                )\n",
        "\n",
        "            rand_attn = self._bigbird_block_rand_mask_with_head(\n",
        "                from_seq_length=from_seq_len,\n",
        "                to_seq_length=to_seq_len,\n",
        "                from_block_size=from_block_size,\n",
        "                to_block_size=to_block_size,\n",
        "                num_heads=n_heads,\n",
        "                plan_from_length=plan_from_length,\n",
        "                plan_num_rand_blocks=plan_num_rand_blocks,\n",
        "            )\n",
        "\n",
        "        rand_attn = np.stack(rand_attn, axis=0)\n",
        "        rand_attn = torch.tensor(rand_attn, device=query_layer.device, dtype=torch.long)\n",
        "        rand_attn.unsqueeze_(0)\n",
        "        rand_attn = torch.cat([rand_attn for _ in range(batch_size)], dim=0)\n",
        "\n",
        "        rand_mask = self._create_rand_mask_from_inputs(\n",
        "            from_blocked_mask, to_blocked_mask, rand_attn, n_heads, n_rand_blocks, bsz, from_seq_len, from_block_size\n",
        "        )\n",
        "\n",
        "        blocked_query_matrix = query_layer.view(bsz, n_heads, from_seq_len // from_block_size, from_block_size, -1)\n",
        "        blocked_key_matrix = key_layer.view(bsz, n_heads, to_seq_len // to_block_size, to_block_size, -1)\n",
        "        blocked_value_matrix = value_layer.view(bsz, n_heads, to_seq_len // to_block_size, to_block_size, -1)\n",
        "\n",
        "        # preparing block for randn attn\n",
        "        gathered_key = self.torch_gather_b2(blocked_key_matrix, rand_attn)\n",
        "        gathered_key = gathered_key.view(\n",
        "            bsz, n_heads, to_seq_len // to_block_size - 2, n_rand_blocks * to_block_size, -1\n",
        "        )  # [bsz, n_heads, to_seq_len//to_block_size-2, n_rand_blocks, to_block_size, -1]\n",
        "        gathered_value = self.torch_gather_b2(blocked_value_matrix, rand_attn)\n",
        "        gathered_value = gathered_value.view(\n",
        "            bsz, n_heads, to_seq_len // to_block_size - 2, n_rand_blocks * to_block_size, -1\n",
        "        )  # [bsz, n_heads, to_seq_len//to_block_size-2, n_rand_blocks, to_block_size, -1]\n",
        "\n",
        "        # 1st PART\n",
        "        # 1st block (global block) attention scores\n",
        "        # q[0] x (k[0], k[1], k[2], k[3], k[4] .... )\n",
        "\n",
        "        # [bsz, n_heads, from_block_size, -1] x [bsz, n_heads, to_seq_len, -1] ==> [bsz, n_heads, from_block_size, to_seq_len]\n",
        "        first_product = self.torch_bmm_nd_transpose(blocked_query_matrix[:, :, 0], key_layer, ndim=4)\n",
        "\n",
        "        first_product = first_product * rsqrt_d\n",
        "        first_product += (1.0 - to_mask) * -10000.0\n",
        "        first_attn_weights = F.softmax(first_product, dim=-1)  # [bsz, n_heads, from_block_size, to_seq_len]\n",
        "\n",
        "        # [bsz, n_heads, from_block_size, to_seq_len] x [bsz, n_heads, to_seq_len, -1] ==> [bsz, n_heads, from_block_size, -1]\n",
        "        first_context_layer = self.torch_bmm_nd(first_attn_weights, value_layer, ndim=4)\n",
        "        first_context_layer.unsqueeze_(2)\n",
        "\n",
        "        # 2nd PART\n",
        "        # 2nd block attention scores\n",
        "        # q[1] x (sliding_keys, random_keys, global_keys)\n",
        "        # sliding key blocks -> 2nd, 3rd blocks\n",
        "        # global key blocks -> 1st block\n",
        "\n",
        "        second_key_mat = torch.cat(\n",
        "            [\n",
        "                blocked_key_matrix[:, :, 0],\n",
        "                blocked_key_matrix[:, :, 1],\n",
        "                blocked_key_matrix[:, :, 2],\n",
        "                blocked_key_matrix[:, :, -1],\n",
        "                gathered_key[:, :, 0],\n",
        "            ],\n",
        "            dim=2,\n",
        "        )  # [bsz, n_heads, (4+n_rand_blocks)*to_block_size, -1]\n",
        "        second_value_mat = torch.cat(\n",
        "            [\n",
        "                blocked_value_matrix[:, :, 0],\n",
        "                blocked_value_matrix[:, :, 1],\n",
        "                blocked_value_matrix[:, :, 2],\n",
        "                blocked_value_matrix[:, :, -1],\n",
        "                gathered_value[:, :, 0],\n",
        "            ],\n",
        "            dim=2,\n",
        "        )  # [bsz, n_heads, (4+n_rand_blocks)*to_block_size, -1]\n",
        "\n",
        "        # [bsz, n_heads, from_block_size, -1] x [bsz, n_heads, (4+n_rand_blocks)*to_block_size, -1] ==> [bsz, n_heads, from_block_size, (4+n_rand_blocks)*to_block_size]\n",
        "        second_product = self.torch_bmm_nd_transpose(blocked_query_matrix[:, :, 1], second_key_mat, ndim=4)\n",
        "        second_seq_pad = torch.cat(\n",
        "            [\n",
        "                to_mask[:, :, :, : 3 * to_block_size],\n",
        "                to_mask[:, :, :, -to_block_size:],\n",
        "                first_context_layer.new_ones([bsz, 1, 1, n_rand_blocks * to_block_size]),\n",
        "            ],\n",
        "            dim=3,\n",
        "        )\n",
        "        second_rand_pad = torch.cat(\n",
        "            [\n",
        "                first_context_layer.new_ones([bsz, n_heads, from_block_size, 4 * to_block_size]),\n",
        "                rand_mask[:, :, 0],\n",
        "            ],\n",
        "            dim=3,\n",
        "        )\n",
        "        second_product = second_product * rsqrt_d\n",
        "        second_product += (1.0 - torch.minimum(second_seq_pad, second_rand_pad)) * -10000.0\n",
        "        second_attn_weights = F.softmax(\n",
        "            second_product, dim=-1\n",
        "        )  # [bsz, n_heads, from_block_size, (4+n_rand_blocks)*to_block_size]\n",
        "\n",
        "        # [bsz, n_heads, from_block_size, (4+n_rand_blocks)*to_block_size] x [bsz, n_heads, (4+n_rand_blocks)*to_block_size, -1] ==> [bsz, n_heads, from_block_size, -1]\n",
        "        second_context_layer = self.torch_bmm_nd(second_attn_weights, second_value_mat, ndim=4)\n",
        "\n",
        "        second_context_layer.unsqueeze_(2)\n",
        "\n",
        "        # 3rd PART\n",
        "        # Middle blocks attention scores\n",
        "        # q[-2:2] x (sliding_keys, random_keys, global_keys)\n",
        "        # sliding attn is calculated using special trick of shifting tokens as discussed in paper\n",
        "        # random keys are generated by taking random indices as per `rand_attn`\n",
        "        # global keys -> 1st & last block\n",
        "\n",
        "        exp_blocked_key_matrix = torch.cat(\n",
        "            [blocked_key_matrix[:, :, 1:-3], blocked_key_matrix[:, :, 2:-2], blocked_key_matrix[:, :, 3:-1]], dim=3\n",
        "        )  # [bsz, n_heads, from_seq_len//from_block_size-4, 3*to_block_size, -1]\n",
        "        exp_blocked_value_matrix = torch.cat(\n",
        "            [blocked_value_matrix[:, :, 1:-3], blocked_value_matrix[:, :, 2:-2], blocked_value_matrix[:, :, 3:-1]],\n",
        "            dim=3,\n",
        "        )  # [bsz, n_heads, from_seq_len//from_block_size-4, 3*to_block_size, -1]\n",
        "        middle_query_matrix = blocked_query_matrix[:, :, 2:-2]\n",
        "\n",
        "        # sliding attention scores for q[-2:2]\n",
        "        # [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, -1] x [b, n_heads, from_seq_len//from_block_size-4, 3*to_block_size, -1]\n",
        "        inner_band_product = self.torch_bmm_nd_transpose(middle_query_matrix, exp_blocked_key_matrix, ndim=5)\n",
        "        #     ==> [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, 3*to_block_size]\n",
        "        inner_band_product = inner_band_product * rsqrt_d\n",
        "\n",
        "        # randn attention scores for q[-2:2]\n",
        "        # [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, -1] x [bsz, n_heads, from_seq_len//from_block_size-4, n_rand_blocks*to_block_size, -1]\n",
        "        rand_band_product = self.torch_bmm_nd_transpose(middle_query_matrix, gathered_key[:, :, 1:-1], ndim=5)\n",
        "        #     ==> [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, n_rand_blocks*to_block_size]\n",
        "        rand_band_product = rand_band_product * rsqrt_d\n",
        "\n",
        "        # Including 1st block (since it's global)\n",
        "        first_band_product = torch.einsum(\n",
        "            \"bhlqd,bhkd->bhlqk\", middle_query_matrix, blocked_key_matrix[:, :, 0]\n",
        "        )  # [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, -1] x [bsz, n_heads, to_block_size, -1] ==> [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, to_block_size]\n",
        "        first_band_product = first_band_product * rsqrt_d\n",
        "\n",
        "        # Including last block (since it's global)\n",
        "        last_band_product = torch.einsum(\n",
        "            \"bhlqd,bhkd->bhlqk\", middle_query_matrix, blocked_key_matrix[:, :, -1]\n",
        "        )  # [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, -1] x [bsz, n_heads, to_block_size, -1] ==> [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, to_block_size]\n",
        "        last_band_product = last_band_product * rsqrt_d\n",
        "\n",
        "        # masking padded tokens\n",
        "        inner_band_product += (1.0 - band_mask) * -10000.0\n",
        "        first_band_product += (1.0 - to_mask[:, :, :, :to_block_size].unsqueeze(3)) * -10000.0\n",
        "        last_band_product += (1.0 - to_mask[:, :, :, -to_block_size:].unsqueeze(3)) * -10000.0\n",
        "        rand_band_product += (1.0 - rand_mask[:, :, 1:-1]) * -10000.0\n",
        "\n",
        "        # completing attention scores matrix for all q[-2:2]\n",
        "        band_product = torch.cat(\n",
        "            [first_band_product, inner_band_product, rand_band_product, last_band_product], dim=-1\n",
        "        )  # [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, (5+n_rand_blocks)*to_block_size]\n",
        "\n",
        "        # safely doing softmax since attention matrix is completed\n",
        "        attn_weights = F.softmax(\n",
        "            band_product, dim=-1\n",
        "        )  # [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, (5+n_rand_blocks)*to_block_size]\n",
        "\n",
        "        # contribution of sliding keys\n",
        "        # [bsz, n_heads, m//from_block_size-4, from_block_size, 3*to_block_size] x [bsz, n_heads, from_seq_len//from_block_size-4, 3*to_block_size, -1]\n",
        "        context_layer = self.torch_bmm_nd(\n",
        "            attn_weights[:, :, :, :, to_block_size : 4 * to_block_size], exp_blocked_value_matrix, ndim=5\n",
        "        )\n",
        "        #     ==> [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, -1]\n",
        "\n",
        "        # adding contribution of random keys\n",
        "        # [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, n_rand_blocks*to_block_size] x [bsz, n_heads, from_seq_len//from_block_size-4, n_rand_blocks*to_block_size, -1]\n",
        "        context_layer += self.torch_bmm_nd(\n",
        "            attn_weights[:, :, :, :, 4 * to_block_size : -to_block_size], gathered_value[:, :, 1:-1], ndim=5\n",
        "        )\n",
        "        #     ==> [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, -1]\n",
        "\n",
        "        # adding contribution of global keys\n",
        "        context_layer += torch.einsum(\n",
        "            \"bhlqk,bhkd->bhlqd\", attn_weights[:, :, :, :, :to_block_size], blocked_value_matrix[:, :, 0]\n",
        "        )  # [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, to_block_size] x [bsz, n_heads, to_block_size, -1] ==> [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, -1]\n",
        "        context_layer += torch.einsum(\n",
        "            \"bhlqk,bhkd->bhlqd\", attn_weights[:, :, :, :, -to_block_size:], blocked_value_matrix[:, :, -1]\n",
        "        )  # [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, to_block_size] x [bsz, n_heads, to_block_size, -1] ==> [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, -1]\n",
        "\n",
        "        # 4th PART\n",
        "        # last 2nd token attention scores\n",
        "        # q[-2] x (sliding_keys, random_keys, global_keys)\n",
        "        # sliding key blocks -> last 3 blocks\n",
        "        # global key block -> 1st block\n",
        "        # random key block -> based on indices stored in `randn_attn`\n",
        "\n",
        "        second_last_key_mat = torch.cat(\n",
        "            [\n",
        "                blocked_key_matrix[:, :, 0],\n",
        "                blocked_key_matrix[:, :, -3],\n",
        "                blocked_key_matrix[:, :, -2],\n",
        "                blocked_key_matrix[:, :, -1],\n",
        "                gathered_key[:, :, -1],\n",
        "            ],\n",
        "            dim=2,\n",
        "        )  # [bsz, n_heads, (4+n_random_blocks)*to_block_size, -1]\n",
        "        second_last_value_mat = torch.cat(\n",
        "            [\n",
        "                blocked_value_matrix[:, :, 0],\n",
        "                blocked_value_matrix[:, :, -3],\n",
        "                blocked_value_matrix[:, :, -2],\n",
        "                blocked_value_matrix[:, :, -1],\n",
        "                gathered_value[:, :, -1],\n",
        "            ],\n",
        "            dim=2,\n",
        "        )  # [bsz, n_heads, (4+r)*to_block_size, -1]\n",
        "\n",
        "        # [bsz, n_heads, from_block_size, -1] x [bsz, n_heads, (4+n_rand_blocks)*to_block_size, -1] ==> [bsz, n_heads, from_block_size, (4+n_rand_blocks)*to_block_size]\n",
        "        second_last_product = self.torch_bmm_nd_transpose(blocked_query_matrix[:, :, -2], second_last_key_mat, ndim=4)\n",
        "        second_last_seq_pad = torch.cat(\n",
        "            [\n",
        "                to_mask[:, :, :, :to_block_size],\n",
        "                to_mask[:, :, :, -3 * to_block_size :],\n",
        "                context_layer.new_ones([bsz, 1, 1, n_rand_blocks * to_block_size]),\n",
        "            ],\n",
        "            dim=3,\n",
        "        )\n",
        "        second_last_rand_pad = torch.cat(\n",
        "            [\n",
        "                context_layer.new_ones([bsz, n_heads, from_block_size, 4 * to_block_size]),\n",
        "                rand_mask[:, :, -1],\n",
        "            ],\n",
        "            dim=3,\n",
        "        )\n",
        "        second_last_product = second_last_product * rsqrt_d\n",
        "        second_last_product += (1.0 - torch.minimum(second_last_seq_pad, second_last_rand_pad)) * -10000.0\n",
        "        second_last_attn_weights = F.softmax(\n",
        "            second_last_product, dim=-1\n",
        "        )  # [bsz, n_heads, from_block_size, (4+n_rand_blocks)*to_block_size]\n",
        "\n",
        "        # [bsz, n_heads, from_block_size, (4+n_rand_blocks)*to_block_size] x [bsz, n_heads, (4+n_rand_blocks)*to_block_size, -1] ==> [bsz, n_heads, from_block_size, -1]\n",
        "        second_last_context_layer = self.torch_bmm_nd(second_last_attn_weights, second_last_value_mat, ndim=4)\n",
        "        second_last_context_layer.unsqueeze_(2)\n",
        "\n",
        "        # 5th PART\n",
        "        # last block (global) attention scores\n",
        "        # q[-1] x (k[0], k[1], k[2], k[3], .... )\n",
        "\n",
        "        # [bsz, n_heads, from_block_size, -1] x [bsz, n_heads, to_seq_len, -1] ==> [bsz, n_heads, from_block_size, to_seq_len]\n",
        "        last_product = self.torch_bmm_nd_transpose(blocked_query_matrix[:, :, -1], key_layer, ndim=4)\n",
        "        last_product = last_product * rsqrt_d\n",
        "        last_product += (1.0 - to_mask) * -10000.0\n",
        "        last_attn_weights = F.softmax(last_product, dim=-1)  # [bsz, n_heads, from_block_size, n]\n",
        "\n",
        "        # [bsz, n_heads, from_block_size, to_seq_len] x [bsz, n_heads, to_seq_len, -1] ==> [bsz, n_heads, from_block_size, -1]\n",
        "        last_context_layer = self.torch_bmm_nd(last_attn_weights, value_layer, ndim=4)\n",
        "        last_context_layer.unsqueeze_(2)\n",
        "\n",
        "        # combining representations of all tokens\n",
        "        context_layer = torch.cat(\n",
        "            [first_context_layer, second_context_layer, context_layer, second_last_context_layer, last_context_layer],\n",
        "            dim=2,\n",
        "        )\n",
        "        context_layer = context_layer.view((bsz, n_heads, from_seq_len, -1)) * from_mask\n",
        "        context_layer = torch.transpose(context_layer, 1, 2)\n",
        "\n",
        "        # this is just for visualizing; forward pass doesn't depend on following code\n",
        "        if output_attentions:\n",
        "            # TODO(PVP): need to verify if below code is correct\n",
        "            attention_probs = torch.zeros(\n",
        "                bsz, n_heads, from_seq_len, to_seq_len, dtype=torch.float, device=context_layer.device\n",
        "            )\n",
        "\n",
        "            # 1st query block\n",
        "            # corresponding to `first_context_layer`\n",
        "            attention_probs[:, :, :from_block_size, :] = first_attn_weights  # all keys global\n",
        "\n",
        "            # 2nd query block\n",
        "            # corresponding to `second_context_layer`\n",
        "            attention_probs[:, :, from_block_size : 2 * from_block_size, : 3 * to_block_size] = second_attn_weights[\n",
        "                :, :, :, : 3 * to_block_size\n",
        "            ]  # 1st three key blocks (global + sliding)\n",
        "            attention_probs[:, :, from_block_size : 2 * from_block_size, -to_block_size:] = second_attn_weights[\n",
        "                :, :, :, 3 * to_block_size : 4 * to_block_size\n",
        "            ]  # last key block (global)\n",
        "            # random keys\n",
        "            for p1, i1, w1 in zip(range(bsz), rand_attn, second_attn_weights):\n",
        "                # p1, i1, w1 corresponds to batch_dim i.e. following operation is done for each sequence in batch\n",
        "                for p2, i2, w2 in zip(range(n_heads), i1, w1):\n",
        "                    # p2, i2, w2 corresponds to head_dim i.e. following operation is done for each heads\n",
        "                    attn_probs_view = attention_probs.view(\n",
        "                        bsz,\n",
        "                        n_heads,\n",
        "                        from_seq_len // from_block_size,\n",
        "                        from_block_size,\n",
        "                        to_seq_len // to_block_size,\n",
        "                        to_block_size,\n",
        "                    )\n",
        "                    right_slice = w2[:, 4 * to_block_size :]\n",
        "                    attn_probs_view[p1, p2, 1, :, i2[0]] = right_slice.view(\n",
        "                        from_block_size, n_rand_blocks, to_block_size\n",
        "                    )\n",
        "\n",
        "            # Middle query blocks\n",
        "            # corresponding to `context_layer`\n",
        "            # sliding keys\n",
        "            for q_idx in range(from_seq_len // from_block_size - 4):\n",
        "                attn_probs_view = attention_probs.view(\n",
        "                    bsz,\n",
        "                    n_heads,\n",
        "                    from_seq_len // from_block_size,\n",
        "                    from_block_size,\n",
        "                    to_seq_len // to_block_size,\n",
        "                    to_block_size,\n",
        "                )[:, :, 2:-2, :, 1:-1, :]\n",
        "                right_slice = attn_weights[:, :, q_idx, :, to_block_size : 4 * to_block_size]\n",
        "                attn_probs_view[:, :, q_idx, :, q_idx : q_idx + 3, :] = right_slice.view(\n",
        "                    bsz, n_heads, from_block_size, 3, to_block_size\n",
        "                )  # inner_band_product\n",
        "            # global keys (corresponding to 1st key block)\n",
        "            attention_probs[:, :, 2 * from_block_size : -2 * from_block_size, :to_block_size] = attn_weights[\n",
        "                :, :, :, :, :to_block_size\n",
        "            ].view(\n",
        "                bsz, n_heads, -1, to_block_size\n",
        "            )  # first_band_product\n",
        "            # global keys (corresponding to last key block)\n",
        "            attention_probs[:, :, 2 * from_block_size : -2 * from_block_size, -to_block_size:] = attn_weights[\n",
        "                :, :, :, :, -to_block_size:\n",
        "            ].view(\n",
        "                bsz, n_heads, -1, to_block_size\n",
        "            )  # last_band_product\n",
        "            # random keys\n",
        "            for p1, i1, w1 in zip(range(bsz), rand_attn, attn_weights):\n",
        "                # p1, i1, w1 corresponds to batch_dim i.e. following operation is done for each sequence in batch\n",
        "                for p2, i2, w2 in zip(range(n_heads), i1, w1):\n",
        "                    # p2, i2, w2 corresponds to head_dim i.e. following operation is done for each heads\n",
        "                    for q_idx in range(1, len(i2) - 1):\n",
        "                        attn_probs_view = attention_probs.view(\n",
        "                            bsz,\n",
        "                            n_heads,\n",
        "                            from_seq_len // from_block_size,\n",
        "                            from_block_size,\n",
        "                            to_seq_len // to_block_size,\n",
        "                            to_block_size,\n",
        "                        )\n",
        "                        right_slice = w2[q_idx - 1, :, 4 * to_block_size : -to_block_size]\n",
        "                        attn_probs_view[p1, p2, q_idx + 1, :, i2[q_idx]] = right_slice.view(\n",
        "                            from_block_size, n_rand_blocks, to_block_size\n",
        "                        )\n",
        "\n",
        "            # Second-last query block\n",
        "            # corresponding to `second_last_context_layer`\n",
        "            attention_probs[:, :, -2 * from_block_size : -from_block_size, :to_block_size] = second_last_attn_weights[\n",
        "                :, :, :, :to_block_size\n",
        "            ]  # 1st key block (global)\n",
        "            attention_probs[\n",
        "                :, :, -2 * from_block_size : -from_block_size, -3 * to_block_size :\n",
        "            ] = second_last_attn_weights[\n",
        "                :, :, :, to_block_size : 4 * to_block_size\n",
        "            ]  # last three blocks (global + sliding)\n",
        "            # random keys\n",
        "            for p1, i1, w1 in zip(range(bsz), rand_attn, second_last_attn_weights):\n",
        "                # p1, i1, w1 corresponds to batch_dim i.e. following operation is done for each sequence in batch\n",
        "                for p2, i2, w2 in zip(range(n_heads), i1, w1):\n",
        "                    # p2, i2, w2 corresponds to head_dim i.e. following operation is done for each heads\n",
        "                    attn_probs_view = attention_probs.view(\n",
        "                        bsz,\n",
        "                        n_heads,\n",
        "                        from_seq_len // from_block_size,\n",
        "                        from_block_size,\n",
        "                        to_seq_len // to_block_size,\n",
        "                        to_block_size,\n",
        "                    )\n",
        "                    right_slice = w2[:, 4 * to_block_size :]\n",
        "                    attn_probs_view[p1, p2, -2, :, i2[-1]] = right_slice.view(\n",
        "                        from_block_size, n_rand_blocks, to_block_size\n",
        "                    )\n",
        "\n",
        "            # last query block\n",
        "            # corresponding to `last_context_layer`\n",
        "            attention_probs[:, :, -from_block_size:, :] = last_attn_weights  # all keys global\n",
        "\n",
        "        else:\n",
        "            attention_probs = None\n",
        "\n",
        "        return context_layer, attention_probs\n",
        "\n",
        "    @staticmethod\n",
        "    def torch_gather_b2(params, indices):\n",
        "        # this operation is equivalent to tf.gather when batch_dims=2\n",
        "\n",
        "        if params.shape[:2] != indices.shape[:2]:\n",
        "            raise ValueError(\n",
        "                f\"Make sure that the first two dimensions of params and indices are identical, \\\n",
        "                but they are params: {params.shape[:2]} vs. indices: {params.shape[:2]}\"\n",
        "            )\n",
        "        num_indices_to_gather = indices.shape[-2] * indices.shape[-1]\n",
        "        num_indices_to_pick_from = params.shape[2]\n",
        "\n",
        "        indices_shift = (\n",
        "            torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)\n",
        "            // num_indices_to_gather\n",
        "            * num_indices_to_pick_from\n",
        "        )\n",
        "\n",
        "        flattened_indices = indices.view(-1) + indices_shift\n",
        "        flattened_params = params.reshape(-1, params.shape[-2], params.shape[-1])\n",
        "\n",
        "        out_flattened = flattened_params.index_select(0, flattened_indices)\n",
        "\n",
        "        out = out_flattened.reshape(params.shape[:2] + (num_indices_to_gather,) + params.shape[3:])\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_rand_mask_from_inputs(\n",
        "        from_blocked_mask,\n",
        "        to_blocked_mask,\n",
        "        rand_attn,\n",
        "        num_attention_heads,\n",
        "        num_rand_blocks,\n",
        "        batch_size,\n",
        "        from_seq_length,\n",
        "        from_block_size,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Create 3D attention mask from a 2D tensor mask.\n",
        "\n",
        "        Args:\n",
        "            from_blocked_mask: 2D Tensor of shape [batch_size,\n",
        "            from_seq_length//from_block_size, from_block_size].\n",
        "            to_blocked_mask: int32 Tensor of shape [batch_size,\n",
        "            to_seq_length//to_block_size, to_block_size].\n",
        "            rand_attn: [batch_size, num_attention_heads,\n",
        "            from_seq_length//from_block_size-2, num_rand_blocks]\n",
        "            num_attention_heads: int. Number of attention heads.\n",
        "            num_rand_blocks: int. Number of random chunks per row.\n",
        "            batch_size: int. Batch size for computation.\n",
        "            from_seq_length: int. length of from sequence.\n",
        "            from_block_size: int. size of block in from sequence.\n",
        "\n",
        "        Returns:\n",
        "            float Tensor of shape [batch_size, num_attention_heads, from_seq_length//from_block_size-2,\n",
        "            from_block_size, num_rand_blocks*to_block_size].\n",
        "        \"\"\"\n",
        "        num_windows = from_seq_length // from_block_size - 2\n",
        "        rand_mask = torch.stack([p1[i1.flatten()] for p1, i1 in zip(to_blocked_mask, rand_attn)])\n",
        "        rand_mask = rand_mask.view(batch_size, num_attention_heads, num_windows, num_rand_blocks * from_block_size)\n",
        "        rand_mask = torch.einsum(\"blq,bhlk->bhlqk\", from_blocked_mask[:, 1:-1], rand_mask)\n",
        "        return rand_mask\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_rand_attn_plan(from_seq_length, from_block_size, num_rand_blocks):\n",
        "        \"\"\"\n",
        "        Gives the plan of where to put random attention.\n",
        "\n",
        "        Args:\n",
        "            from_seq_length: int. length of from sequence.\n",
        "            from_block_size: int. size of block in from sequence.\n",
        "            num_rand_blocks: int. Number of random chunks per row.\n",
        "\n",
        "        Returns:\n",
        "            plan_from_length: ending location of from block plan_num_rand_blocks: number of random ending location for\n",
        "            each block\n",
        "        \"\"\"\n",
        "\n",
        "        plan_from_length = []\n",
        "        plan_num_rand_blocks = []\n",
        "        if (2 * num_rand_blocks + 5) < (from_seq_length // from_block_size):\n",
        "            plan_from_length.append(int((2 * num_rand_blocks + 5) * from_block_size))\n",
        "            plan_num_rand_blocks.append(num_rand_blocks)\n",
        "            plan_from_length.append(from_seq_length)\n",
        "            plan_num_rand_blocks.append(0)\n",
        "        elif (num_rand_blocks + 5) < (from_seq_length // from_block_size):\n",
        "            plan_from_length.append(int((num_rand_blocks + 5) * from_block_size))\n",
        "            plan_num_rand_blocks.append(num_rand_blocks // 2)\n",
        "            plan_from_length.append(from_seq_length)\n",
        "            plan_num_rand_blocks.append(num_rand_blocks - (num_rand_blocks // 2))\n",
        "        else:\n",
        "            plan_from_length.append(from_seq_length)\n",
        "            plan_num_rand_blocks.append(num_rand_blocks)\n",
        "\n",
        "        return plan_from_length, plan_num_rand_blocks\n",
        "\n",
        "    @staticmethod\n",
        "    def _bigbird_block_rand_mask(\n",
        "        from_seq_length, to_seq_length, from_block_size, to_block_size, num_rand_blocks, last_idx=-1\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Create adjacency list of random attention.\n",
        "\n",
        "        Args:\n",
        "            from_seq_length: int. length of from sequence.\n",
        "            to_seq_length: int. length of to sequence.\n",
        "            from_block_size: int. size of block in from sequence.\n",
        "            to_block_size: int. size of block in to sequence.\n",
        "            num_rand_blocks: int. Number of random chunks per row.\n",
        "            last_idx: if -1 then num_rand_blocks blocks chosen anywhere in to sequence,\n",
        "            if positive then num_rand_blocks blocks chosen only up to last_idx.\n",
        "\n",
        "        Returns:\n",
        "            adjacency list of size from_seq_length//from_block_size-2 by num_rand_blocks\n",
        "        \"\"\"\n",
        "        # using this method when from_seq_length in [1024, 3072, 4096]\n",
        "\n",
        "        assert (\n",
        "            from_seq_length // from_block_size == to_seq_length // to_block_size\n",
        "        ), \"Error the number of blocks needs to be same!\"\n",
        "\n",
        "        rand_attn = np.zeros((from_seq_length // from_block_size - 2, num_rand_blocks), dtype=np.int32)\n",
        "        middle_seq = np.arange(1, to_seq_length // to_block_size - 1, dtype=np.int32)\n",
        "        last = to_seq_length // to_block_size - 1\n",
        "        if last_idx > (2 * to_block_size):\n",
        "            last = (last_idx // to_block_size) - 1\n",
        "\n",
        "        r = num_rand_blocks  # shorthand\n",
        "        for i in range(1, from_seq_length // from_block_size - 1):\n",
        "            start = i - 2\n",
        "            end = i\n",
        "            if i == 1:\n",
        "                rand_attn[i - 1, :] = np.random.permutation(middle_seq[2:last])[:r]\n",
        "            elif i == 2:\n",
        "                rand_attn[i - 1, :] = np.random.permutation(middle_seq[3:last])[:r]\n",
        "            elif i == from_seq_length // from_block_size - 3:\n",
        "                rand_attn[i - 1, :] = np.random.permutation(middle_seq[:last])[:r]\n",
        "            # Missing -3: should have been sliced till last-3\n",
        "            elif i == from_seq_length // from_block_size - 2:\n",
        "                rand_attn[i - 1, :] = np.random.permutation(middle_seq[:last])[:r]\n",
        "            # Missing -4: should have been sliced till last-4\n",
        "            else:\n",
        "                if start > last:\n",
        "                    start = last\n",
        "                    rand_attn[i - 1, :] = np.random.permutation(middle_seq[:start])[:r]\n",
        "                elif (end + 1) == last:\n",
        "                    rand_attn[i - 1, :] = np.random.permutation(middle_seq[:start])[:r]\n",
        "                else:\n",
        "                    rand_attn[i - 1, :] = np.random.permutation(\n",
        "                        np.concatenate((middle_seq[:start], middle_seq[end + 1 : last]))\n",
        "                    )[:r]\n",
        "        return rand_attn\n",
        "\n",
        "    def _bigbird_block_rand_mask_with_head(\n",
        "        self,\n",
        "        from_seq_length,\n",
        "        to_seq_length,\n",
        "        from_block_size,\n",
        "        to_block_size,\n",
        "        num_heads,\n",
        "        plan_from_length,\n",
        "        plan_num_rand_blocks,\n",
        "        window_block_left=1,\n",
        "        window_block_right=1,\n",
        "        global_block_top=1,\n",
        "        global_block_bottom=1,\n",
        "        global_block_left=1,\n",
        "        global_block_right=1,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Create adjacency list of random attention.\n",
        "\n",
        "        Args:\n",
        "            from_seq_length: int. length of from sequence.\n",
        "            to_seq_length: int. length of to sequence.\n",
        "            from_block_size: int. size of block in from sequence.\n",
        "            to_block_size: int. size of block in to sequence.\n",
        "            num_heads: int. total number of heads.\n",
        "            plan_from_length: list. plan from length where num_random_blocks are choosen from.\n",
        "            plan_num_rand_blocks: list. number of rand blocks within the plan.\n",
        "            window_block_left: int. number of blocks of window to left of a block.\n",
        "            window_block_right: int. number of blocks of window to right of a block.\n",
        "            global_block_top: int. number of blocks at the top.\n",
        "            global_block_bottom: int. number of blocks at the bottom.\n",
        "            global_block_left: int. Number of blocks globally used to the left.\n",
        "            global_block_right: int. Number of blocks globally used to the right.\n",
        "\n",
        "        Returns:\n",
        "            adjacency list of size num_head where each element is of size from_seq_length//from_block_size-2 by\n",
        "            num_rand_blocks\n",
        "        \"\"\"\n",
        "        # using this method when from_seq_length not in [1024, 3072, 4096]\n",
        "\n",
        "        assert (\n",
        "            from_seq_length // from_block_size == to_seq_length // to_block_size\n",
        "        ), \"Error the number of blocks needs to be same!\"\n",
        "\n",
        "        assert from_seq_length in plan_from_length, \"Error from sequence length not in plan!\"\n",
        "\n",
        "        # Total number of blocks in the mmask\n",
        "        num_blocks = from_seq_length // from_block_size\n",
        "        # Number of blocks per plan\n",
        "        plan_block_length = np.array(plan_from_length) // from_block_size\n",
        "        # till when to follow plan\n",
        "        max_plan_idx = plan_from_length.index(from_seq_length)\n",
        "        # Random Attention adjacency list\n",
        "        rand_attn = [\n",
        "            np.zeros((num_blocks, np.sum(plan_num_rand_blocks[: max_plan_idx + 1])), dtype=np.int32)\n",
        "            for i in range(num_heads)\n",
        "        ]\n",
        "\n",
        "        # We will go iteratively over the plan blocks and pick random number of\n",
        "        # Attention blocks from the legally allowed blocks\n",
        "        for plan_idx in range(max_plan_idx + 1):\n",
        "            rnd_r_cnt = 0\n",
        "            if plan_idx > 0:\n",
        "                # set the row for all from_blocks starting from 0 to\n",
        "                # plan_block_length[plan_idx-1]\n",
        "                # column indx start fromm plan_block_length[plan_idx-1] and ends at\n",
        "                # plan_block_length[plan_idx]\n",
        "                if plan_num_rand_blocks[plan_idx] > 0:\n",
        "                    rnd_r_cnt = int(np.sum(plan_num_rand_blocks[:plan_idx]))\n",
        "                    curr_r_cnt = int(np.sum(plan_num_rand_blocks[: plan_idx + 1]))\n",
        "                    for blk_rw_idx in range(global_block_top, plan_block_length[plan_idx - 1]):\n",
        "                        for h in range(num_heads):\n",
        "                            rand_attn[h][blk_rw_idx, rnd_r_cnt:curr_r_cnt] = self._get_single_block_row_attention(\n",
        "                                block_id=blk_rw_idx,\n",
        "                                to_start_block_id=plan_block_length[plan_idx - 1],\n",
        "                                to_end_block_id=plan_block_length[plan_idx],\n",
        "                                num_rand_blocks=plan_num_rand_blocks[plan_idx],\n",
        "                                window_block_left=window_block_left,\n",
        "                                window_block_right=window_block_right,\n",
        "                                global_block_left=global_block_left,\n",
        "                                global_block_right=global_block_right,\n",
        "                            )\n",
        "\n",
        "                for pl_id in range(plan_idx):\n",
        "                    if plan_num_rand_blocks[pl_id] == 0:\n",
        "                        continue\n",
        "                    for blk_rw_idx in range(plan_block_length[plan_idx - 1], plan_block_length[plan_idx]):\n",
        "                        rnd_r_cnt = 0\n",
        "                        to_start_block_id = 0\n",
        "                        if pl_id > 0:\n",
        "                            rnd_r_cnt = int(np.sum(plan_num_rand_blocks[:pl_id]))\n",
        "                            to_start_block_id = plan_block_length[pl_id - 1]\n",
        "                        curr_r_cnt = int(np.sum(plan_num_rand_blocks[: pl_id + 1]))\n",
        "                        for h in range(num_heads):\n",
        "                            rand_attn[h][blk_rw_idx, rnd_r_cnt:curr_r_cnt] = self._get_single_block_row_attention(\n",
        "                                block_id=blk_rw_idx,\n",
        "                                to_start_block_id=to_start_block_id,\n",
        "                                to_end_block_id=plan_block_length[pl_id],\n",
        "                                num_rand_blocks=plan_num_rand_blocks[pl_id],\n",
        "                                window_block_left=window_block_left,\n",
        "                                window_block_right=window_block_right,\n",
        "                                global_block_left=global_block_left,\n",
        "                                global_block_right=global_block_right,\n",
        "                            )\n",
        "\n",
        "            if plan_num_rand_blocks[plan_idx] == 0:\n",
        "                continue\n",
        "            curr_r_cnt = int(np.sum(plan_num_rand_blocks[: plan_idx + 1]))\n",
        "            from_start_block_id = global_block_top\n",
        "            to_start_block_id = 0\n",
        "            if plan_idx > 0:\n",
        "                rnd_r_cnt = int(np.sum(plan_num_rand_blocks[:plan_idx]))\n",
        "                from_start_block_id = plan_block_length[plan_idx - 1]\n",
        "                to_start_block_id = plan_block_length[plan_idx - 1]\n",
        "\n",
        "            for blk_rw_idx in range(from_start_block_id, plan_block_length[plan_idx]):\n",
        "                for h in range(num_heads):\n",
        "                    rand_attn[h][blk_rw_idx, rnd_r_cnt:curr_r_cnt] = self._get_single_block_row_attention(\n",
        "                        block_id=blk_rw_idx,\n",
        "                        to_start_block_id=to_start_block_id,\n",
        "                        to_end_block_id=plan_block_length[plan_idx],\n",
        "                        num_rand_blocks=plan_num_rand_blocks[plan_idx],\n",
        "                        window_block_left=window_block_left,\n",
        "                        window_block_right=window_block_right,\n",
        "                        global_block_left=global_block_left,\n",
        "                        global_block_right=global_block_right,\n",
        "                    )\n",
        "\n",
        "        for nh in range(num_heads):\n",
        "            rand_attn[nh] = rand_attn[nh][global_block_top : num_blocks - global_block_bottom, :]\n",
        "\n",
        "        return rand_attn\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_single_block_row_attention(\n",
        "        block_id,\n",
        "        to_start_block_id,\n",
        "        to_end_block_id,\n",
        "        num_rand_blocks,\n",
        "        window_block_left=1,\n",
        "        window_block_right=1,\n",
        "        global_block_left=1,\n",
        "        global_block_right=1,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        For a single row block get random row attention.\n",
        "\n",
        "        Args:\n",
        "            block_id: int. block id of row.\n",
        "            to_start_block_id: int. random attention column start id.\n",
        "            to_end_block_id: int. random attention column end id.\n",
        "            num_rand_blocks: int. number of random blocks to be selected.\n",
        "            window_block_left: int. number of blocks of window to left of a block.\n",
        "            window_block_right: int. number of blocks of window to right of a block.\n",
        "            global_block_left: int. Number of blocks globally used to the left.\n",
        "            global_block_right: int. Number of blocks globally used to the right.\n",
        "\n",
        "        Returns:\n",
        "            row containing the random attention vector of size num_rand_blocks.\n",
        "        \"\"\"\n",
        "        # list of to_blocks from which to choose random attention\n",
        "        to_block_list = np.arange(to_start_block_id, to_end_block_id, dtype=np.int32)\n",
        "        # permute the blocks\n",
        "        perm_block = np.random.permutation(to_block_list)\n",
        "\n",
        "        # illegal blocks for the current block id, using window\n",
        "        illegal_blocks = list(range(block_id - window_block_left, block_id + window_block_right + 1))\n",
        "\n",
        "        # Add blocks at the start and at the end\n",
        "        illegal_blocks.extend(list(range(global_block_left)))\n",
        "        illegal_blocks.extend(list(range(to_end_block_id - global_block_right, to_end_block_id)))\n",
        "\n",
        "        # The second from_block cannot choose random attention on second last to_block\n",
        "        if block_id == 1:\n",
        "            illegal_blocks.append(to_end_block_id - 2)\n",
        "\n",
        "        # The second last from_block cannot choose random attention on second to_block\n",
        "        if block_id == to_end_block_id - 2:\n",
        "            illegal_blocks.append(1)\n",
        "\n",
        "        selected_random_blokcs = []\n",
        "\n",
        "        for i in range(to_end_block_id - to_start_block_id):\n",
        "            if perm_block[i] not in illegal_blocks:\n",
        "                selected_random_blokcs.append(perm_block[i])\n",
        "            if len(selected_random_blokcs) == num_rand_blocks:\n",
        "                break\n",
        "        return np.array(selected_random_blokcs, dtype=np.int32)\n",
        "\n",
        "\n",
        "# Copied from transformers.models.bert.modeling_bert.BertSelfOutput with Bert->BigBird\n",
        "class BigBirdSelfOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BigBirdAttention(nn.Module):\n",
        "    def __init__(self, config, seed=None):\n",
        "        super().__init__()\n",
        "        self.attention_type = config.attention_type\n",
        "        self.config = config\n",
        "        self.seed = seed\n",
        "\n",
        "        if self.config.attention_type == \"original_full\":\n",
        "            self.self = BigBirdSelfAttention(config)\n",
        "        elif self.config.attention_type == \"block_sparse\":\n",
        "            self.self = BigBirdBlockSparseAttention(config, seed)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"attention_type can either be original_full or block_sparse, but is {self.config.attention_type}\"\n",
        "            )\n",
        "\n",
        "        self.output = BigBirdSelfOutput(config)\n",
        "\n",
        "    def set_attention_type(self, value: str):\n",
        "        if value not in [\"original_full\", \"block_sparse\"]:\n",
        "            raise ValueError(\n",
        "                f\"attention_type can only be set to either 'original_full' or 'block_sparse', but is {value}\"\n",
        "            )\n",
        "        # attention type is already correctly set\n",
        "        if value == self.attention_type:\n",
        "            return\n",
        "\n",
        "        self.attention_type = value\n",
        "        if value == \"original_full\":\n",
        "            # copy all weights to new full attention class\n",
        "            attn_weights = BigBirdSelfAttention(self.config)\n",
        "        else:\n",
        "            # copy all weights to new sparse attention class\n",
        "            attn_weights = BigBirdBlockSparseAttention(self.config, self.seed)\n",
        "\n",
        "        attn_weights.query = self.self.query\n",
        "        attn_weights.value = self.self.value\n",
        "        attn_weights.key = self.self.key\n",
        "        self.self = attn_weights\n",
        "        self.attention_type = value\n",
        "\n",
        "        if not self.training:\n",
        "            self.self.eval()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_value=None,\n",
        "        output_attentions=False,\n",
        "        # block_sparse config\n",
        "        band_mask=None,\n",
        "        from_mask=None,\n",
        "        to_mask=None,\n",
        "        from_blocked_mask=None,\n",
        "        to_blocked_mask=None,\n",
        "    ):\n",
        "\n",
        "        if self.attention_type == \"original_full\":\n",
        "            self_outputs = self.self(\n",
        "                hidden_states,\n",
        "                attention_mask,\n",
        "                head_mask,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                past_key_value,\n",
        "                output_attentions,\n",
        "            )\n",
        "        else:\n",
        "            assert (\n",
        "                encoder_hidden_states is None\n",
        "            ), \"BigBird cannot be used as a decoder when config.attention_type != 'original_full'\"\n",
        "            self_outputs = self.self(\n",
        "                hidden_states, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, output_attentions\n",
        "            )\n",
        "\n",
        "        attention_output = self.output(self_outputs[0], hidden_states)\n",
        "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
        "        return outputs\n",
        "\n",
        "\n",
        "# Copied from transformers.models.bert.modeling_bert.BertIntermediate with Bert->BigBird\n",
        "class BigBirdIntermediate(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "# Copied from transformers.models.bert.modeling_bert.BertOutput with Bert->BigBird\n",
        "class BigBirdOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BigBirdLayer(nn.Module):\n",
        "    def __init__(self, config, seed=None):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.attention_type = config.attention_type\n",
        "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        self.seq_len_dim = 1\n",
        "        self.attention = BigBirdAttention(config, seed=seed)\n",
        "        self.is_decoder = config.is_decoder\n",
        "        self.add_cross_attention = config.add_cross_attention\n",
        "        if self.add_cross_attention:\n",
        "            assert self.is_decoder, f\"{self} should be used as a decoder model if cross attention is added\"\n",
        "            self.crossattention = BigBirdAttention(config)\n",
        "        self.intermediate = BigBirdIntermediate(config)\n",
        "        self.output = BigBirdOutput(config)\n",
        "\n",
        "    def set_attention_type(self, value: str):\n",
        "        if value not in [\"original_full\", \"block_sparse\"]:\n",
        "            raise ValueError(\n",
        "                f\"attention_type can only be set to either 'original_full' or 'block_sparse', but is {value}\"\n",
        "            )\n",
        "        # attention type is already correctly set\n",
        "        if value == self.attention_type:\n",
        "            return\n",
        "        self.attention_type = value\n",
        "        self.attention.set_attention_type(value)\n",
        "\n",
        "        if self.add_cross_attention:\n",
        "            self.crossattention.set_attention_type(value)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        band_mask=None,\n",
        "        from_mask=None,\n",
        "        to_mask=None,\n",
        "        blocked_encoder_mask=None,\n",
        "        past_key_value=None,\n",
        "        output_attentions=False,\n",
        "    ):\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "        self_attention_outputs = self.attention(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_attention_mask,\n",
        "            past_key_value=self_attn_past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "            band_mask=band_mask,\n",
        "            from_mask=from_mask,\n",
        "            to_mask=to_mask,\n",
        "            from_blocked_mask=blocked_encoder_mask,\n",
        "            to_blocked_mask=blocked_encoder_mask,\n",
        "        )\n",
        "        attention_output = self_attention_outputs[0]\n",
        "\n",
        "        # if decoder, the last output is tuple of self-attn cache\n",
        "        if self.is_decoder:\n",
        "            outputs = self_attention_outputs[1:-1]\n",
        "            present_key_value = self_attention_outputs[-1]\n",
        "        else:\n",
        "            outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
        "\n",
        "        cross_attn_present_key_value = None\n",
        "        if self.is_decoder and encoder_hidden_states is not None:\n",
        "            if not hasattr(self, \"crossattention\"):\n",
        "                raise ValueError(\n",
        "                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with \\\n",
        "                    cross-attention layers by setting `config.add_cross_attention=True`\"\n",
        "                )\n",
        "\n",
        "            # cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple\n",
        "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
        "            cross_attention_outputs = self.crossattention(\n",
        "                attention_output,\n",
        "                attention_mask,\n",
        "                head_mask,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                cross_attn_past_key_value,\n",
        "                output_attentions,\n",
        "            )\n",
        "            attention_output = cross_attention_outputs[0]\n",
        "            outputs = outputs + cross_attention_outputs[1:-1]  # add cross attentions if we output attention weights\n",
        "\n",
        "            # add cross-attn cache to positions 3,4 of present_key_value tuple\n",
        "            cross_attn_present_key_value = cross_attention_outputs[-1]\n",
        "            present_key_value = present_key_value + cross_attn_present_key_value\n",
        "\n",
        "        layer_output = apply_chunking_to_forward(\n",
        "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
        "        )\n",
        "\n",
        "        outputs = (layer_output,) + outputs\n",
        "\n",
        "        # if decoder, return the attn key/values as the last output\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (present_key_value,)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def feed_forward_chunk(self, attention_output):\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "        return layer_output\n",
        "\n",
        "\n",
        "class BigBirdEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.attention_type = config.attention_type\n",
        "\n",
        "        self.layer = nn.ModuleList(\n",
        "            [BigBirdLayer(config, seed=layer_idx) for layer_idx in range(config.num_hidden_layers)]\n",
        "        )\n",
        "\n",
        "    def set_attention_type(self, value: str):\n",
        "        if value not in [\"original_full\", \"block_sparse\"]:\n",
        "            raise ValueError(\n",
        "                f\"attention_type can only be set to either 'original_full' or 'block_sparse', but is {value}\"\n",
        "            )\n",
        "        # attention type is already correctly set\n",
        "        if value == self.attention_type:\n",
        "            return\n",
        "        self.attention_type = value\n",
        "        for layer in self.layer:\n",
        "            layer.set_attention_type(value)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_values=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=False,\n",
        "        output_hidden_states=False,\n",
        "        band_mask=None,\n",
        "        from_mask=None,\n",
        "        to_mask=None,\n",
        "        blocked_encoder_mask=None,\n",
        "        return_dict=True,\n",
        "    ):\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_self_attentions = () if output_attentions else None\n",
        "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
        "\n",
        "        next_decoder_cache = () if use_cache else None\n",
        "\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
        "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
        "\n",
        "            if getattr(self.config, \"gradient_checkpointing\", False) and self.training:\n",
        "\n",
        "                if use_cache:\n",
        "                    logger.warning(\n",
        "                        \"`use_cache=True` is incompatible with `config.gradient_checkpointing=True`. Setting \"\n",
        "                        \"`use_cache=False`...\"\n",
        "                    )\n",
        "                    use_cache = False\n",
        "\n",
        "                def create_custom_forward(module):\n",
        "                    def custom_forward(*inputs):\n",
        "                        return module(*inputs, past_key_value, output_attentions)\n",
        "\n",
        "                    return custom_forward\n",
        "\n",
        "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
        "                    create_custom_forward(layer_module),\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    layer_head_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                    band_mask,\n",
        "                    from_mask,\n",
        "                    to_mask,\n",
        "                    blocked_encoder_mask,\n",
        "                )\n",
        "            else:\n",
        "\n",
        "                layer_outputs = layer_module(\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    layer_head_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                    band_mask,\n",
        "                    from_mask,\n",
        "                    to_mask,\n",
        "                    blocked_encoder_mask,\n",
        "                    past_key_value,\n",
        "                    output_attentions,\n",
        "                )\n",
        "\n",
        "            hidden_states = layer_outputs[0]\n",
        "            if use_cache:\n",
        "                next_decoder_cache += (layer_outputs[-1],)\n",
        "            if output_attentions:\n",
        "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
        "                if self.config.add_cross_attention:\n",
        "                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                v\n",
        "                for v in [\n",
        "                    hidden_states,\n",
        "                    next_decoder_cache,\n",
        "                    all_hidden_states,\n",
        "                    all_self_attentions,\n",
        "                    all_cross_attentions,\n",
        "                ]\n",
        "                if v is not None\n",
        "            )\n",
        "        return BaseModelOutputWithPastAndCrossAttentions(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=next_decoder_cache,\n",
        "            hidden_states=all_hidden_states,\n",
        "            attentions=all_self_attentions,\n",
        "            cross_attentions=all_cross_attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "# Copied from transformers.models.bert.modeling_bert.BertPredictionHeadTransform with Bert->BigBird\n",
        "class BigBirdPredictionHeadTransform(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.transform_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.transform_act_fn = config.hidden_act\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.transform_act_fn(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "# Copied from transformers.models.bert.modeling_bert.BertLMPredictionHead with Bert->BigBird\n",
        "class BigBirdLMPredictionHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.transform = BigBirdPredictionHeadTransform(config)\n",
        "\n",
        "        # The output weights are the same as the input embeddings, but there is\n",
        "        # an output-only bias for each token.\n",
        "        self.decoder = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
        "\n",
        "        self.bias = nn.Parameter(torch.zeros(config.vocab_size))\n",
        "\n",
        "        # Need a link between the two variables so that the bias is correctly resized with `resize_token_embeddings`\n",
        "        self.decoder.bias = self.bias\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.transform(hidden_states)\n",
        "        hidden_states = self.decoder(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "# Copied from transformers.models.bert.modeling_bert.BertOnlyMLMHead with Bert->BigBird\n",
        "class BigBirdOnlyMLMHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.predictions = BigBirdLMPredictionHead(config)\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        prediction_scores = self.predictions(sequence_output)\n",
        "        return prediction_scores\n",
        "\n",
        "\n",
        "# Copied from transformers.models.bert.modeling_bert.BertOnlyNSPHead with Bert->BigBird\n",
        "class BigBirdOnlyNSPHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, pooled_output):\n",
        "        seq_relationship_score = self.seq_relationship(pooled_output)\n",
        "        return seq_relationship_score\n",
        "\n",
        "\n",
        "# Copied from transformers.models.bert.modeling_bert.BertPreTrainingHeads with Bert->BigBird\n",
        "class BigBirdPreTrainingHeads(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.predictions = BigBirdLMPredictionHead(config)\n",
        "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, sequence_output, pooled_output):\n",
        "        prediction_scores = self.predictions(sequence_output)\n",
        "        seq_relationship_score = self.seq_relationship(pooled_output)\n",
        "        return prediction_scores, seq_relationship_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "QiCM9rB4LerF",
        "outputId": "0f1d1e62-6446-426d-b4ab-791f6cb7c7cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-21e4d027-0b63-46b0-ae53-66e867dd0762\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.004983</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.008945</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.009451</td>\n",
              "      <td>0.001921</td>\n",
              "      <td>0.001354</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.005840</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004610</td>\n",
              "      <td>0.008102</td>\n",
              "      <td>0.001962</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.736972</td>\n",
              "      <td>0.004714</td>\n",
              "      <td>0.002476</td>\n",
              "      <td>0.003086</td>\n",
              "      <td>0.006548</td>\n",
              "      <td>47.485476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.002543</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>0.000837</td>\n",
              "      <td>0.003957</td>\n",
              "      <td>0.008997</td>\n",
              "      <td>0.008148</td>\n",
              "      <td>0.004351</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.006267</td>\n",
              "      <td>0.002008</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000964</td>\n",
              "      <td>0.001262</td>\n",
              "      <td>0.001590</td>\n",
              "      <td>0.007377</td>\n",
              "      <td>0.743387</td>\n",
              "      <td>0.001479</td>\n",
              "      <td>0.006701</td>\n",
              "      <td>0.003134</td>\n",
              "      <td>0.009406</td>\n",
              "      <td>47.485476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.008613</td>\n",
              "      <td>0.005722</td>\n",
              "      <td>0.005788</td>\n",
              "      <td>0.001877</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.006194</td>\n",
              "      <td>0.008359</td>\n",
              "      <td>0.004732</td>\n",
              "      <td>0.006726</td>\n",
              "      <td>0.000741</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.009443</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.005258</td>\n",
              "      <td>0.741795</td>\n",
              "      <td>0.004211</td>\n",
              "      <td>0.007478</td>\n",
              "      <td>0.002682</td>\n",
              "      <td>0.002490</td>\n",
              "      <td>47.485476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003853</td>\n",
              "      <td>0.008152</td>\n",
              "      <td>0.004747</td>\n",
              "      <td>0.004947</td>\n",
              "      <td>0.002003</td>\n",
              "      <td>0.004539</td>\n",
              "      <td>0.009524</td>\n",
              "      <td>0.002514</td>\n",
              "      <td>0.007553</td>\n",
              "      <td>0.004519</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002109</td>\n",
              "      <td>0.009667</td>\n",
              "      <td>0.001788</td>\n",
              "      <td>0.002898</td>\n",
              "      <td>0.742650</td>\n",
              "      <td>0.005261</td>\n",
              "      <td>0.007522</td>\n",
              "      <td>0.000468</td>\n",
              "      <td>0.004992</td>\n",
              "      <td>47.485476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.004892</td>\n",
              "      <td>0.008918</td>\n",
              "      <td>0.007099</td>\n",
              "      <td>0.007647</td>\n",
              "      <td>0.008757</td>\n",
              "      <td>0.004360</td>\n",
              "      <td>0.006958</td>\n",
              "      <td>0.001609</td>\n",
              "      <td>0.005866</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006228</td>\n",
              "      <td>0.004907</td>\n",
              "      <td>0.001430</td>\n",
              "      <td>0.008935</td>\n",
              "      <td>0.736942</td>\n",
              "      <td>0.003995</td>\n",
              "      <td>0.001199</td>\n",
              "      <td>0.003697</td>\n",
              "      <td>0.009813</td>\n",
              "      <td>47.485476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.007133</td>\n",
              "      <td>0.001346</td>\n",
              "      <td>0.003455</td>\n",
              "      <td>0.001165</td>\n",
              "      <td>0.007156</td>\n",
              "      <td>0.001426</td>\n",
              "      <td>0.007293</td>\n",
              "      <td>0.006472</td>\n",
              "      <td>0.003502</td>\n",
              "      <td>0.004174</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005282</td>\n",
              "      <td>0.003754</td>\n",
              "      <td>0.004017</td>\n",
              "      <td>0.004994</td>\n",
              "      <td>0.743629</td>\n",
              "      <td>0.008933</td>\n",
              "      <td>0.006378</td>\n",
              "      <td>0.004348</td>\n",
              "      <td>0.008932</td>\n",
              "      <td>47.485476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.007142</td>\n",
              "      <td>0.002919</td>\n",
              "      <td>0.001570</td>\n",
              "      <td>0.006602</td>\n",
              "      <td>0.004666</td>\n",
              "      <td>0.008854</td>\n",
              "      <td>0.005708</td>\n",
              "      <td>0.006622</td>\n",
              "      <td>0.003046</td>\n",
              "      <td>0.005028</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007132</td>\n",
              "      <td>0.003535</td>\n",
              "      <td>0.009001</td>\n",
              "      <td>0.008312</td>\n",
              "      <td>0.739608</td>\n",
              "      <td>0.009807</td>\n",
              "      <td>0.002342</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.006083</td>\n",
              "      <td>47.485476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.001819</td>\n",
              "      <td>0.007247</td>\n",
              "      <td>0.003984</td>\n",
              "      <td>0.004188</td>\n",
              "      <td>0.002156</td>\n",
              "      <td>0.004890</td>\n",
              "      <td>0.001188</td>\n",
              "      <td>0.000822</td>\n",
              "      <td>0.005861</td>\n",
              "      <td>0.006609</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006952</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000491</td>\n",
              "      <td>0.001292</td>\n",
              "      <td>0.736253</td>\n",
              "      <td>0.007337</td>\n",
              "      <td>0.000560</td>\n",
              "      <td>0.005609</td>\n",
              "      <td>0.001151</td>\n",
              "      <td>47.485476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.001205</td>\n",
              "      <td>0.009044</td>\n",
              "      <td>0.009305</td>\n",
              "      <td>0.003271</td>\n",
              "      <td>0.007974</td>\n",
              "      <td>0.007183</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>0.003393</td>\n",
              "      <td>0.002009</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007042</td>\n",
              "      <td>0.009443</td>\n",
              "      <td>0.007935</td>\n",
              "      <td>0.009709</td>\n",
              "      <td>0.738220</td>\n",
              "      <td>0.003710</td>\n",
              "      <td>0.005426</td>\n",
              "      <td>0.007349</td>\n",
              "      <td>0.007049</td>\n",
              "      <td>47.485476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.002491</td>\n",
              "      <td>0.005109</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.009686</td>\n",
              "      <td>0.003539</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.005681</td>\n",
              "      <td>0.002222</td>\n",
              "      <td>0.009647</td>\n",
              "      <td>0.006950</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005524</td>\n",
              "      <td>0.002169</td>\n",
              "      <td>0.004735</td>\n",
              "      <td>0.004943</td>\n",
              "      <td>0.743020</td>\n",
              "      <td>0.008936</td>\n",
              "      <td>0.001742</td>\n",
              "      <td>0.006288</td>\n",
              "      <td>0.002786</td>\n",
              "      <td>47.485476</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21e4d027-0b63-46b0-ae53-66e867dd0762')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21e4d027-0b63-46b0-ae53-66e867dd0762 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21e4d027-0b63-46b0-ae53-66e867dd0762');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         0         1         2         3         4         5         6    \\\n",
              "0   0.004983  0.001248  0.008945  0.000294  0.009451  0.001921  0.001354   \n",
              "1   0.002543  0.000458  0.000837  0.003957  0.008997  0.008148  0.004351   \n",
              "2   0.008613  0.005722  0.005788  0.001877  0.002395  0.006194  0.008359   \n",
              "3   0.003853  0.008152  0.004747  0.004947  0.002003  0.004539  0.009524   \n",
              "4   0.004892  0.008918  0.007099  0.007647  0.008757  0.004360  0.006958   \n",
              "..       ...       ...       ...       ...       ...       ...       ...   \n",
              "95  0.007133  0.001346  0.003455  0.001165  0.007156  0.001426  0.007293   \n",
              "96  0.007142  0.002919  0.001570  0.006602  0.004666  0.008854  0.005708   \n",
              "97  0.001819  0.007247  0.003984  0.004188  0.002156  0.004890  0.001188   \n",
              "98  0.001961  0.001205  0.009044  0.009305  0.003271  0.007974  0.007183   \n",
              "99  0.002491  0.005109  0.000585  0.009686  0.003539  0.000380  0.005681   \n",
              "\n",
              "         7         8         9    ...       91        92        93        94   \\\n",
              "0   0.000231  0.005840  0.004167  ...  0.004610  0.008102  0.001962  0.000142   \n",
              "1   0.000205  0.006267  0.002008  ...  0.000964  0.001262  0.001590  0.007377   \n",
              "2   0.004732  0.006726  0.000741  ...  0.000642  0.009443  0.000094  0.005258   \n",
              "3   0.002514  0.007553  0.004519  ...  0.002109  0.009667  0.001788  0.002898   \n",
              "4   0.001609  0.005866  0.000596  ...  0.006228  0.004907  0.001430  0.008935   \n",
              "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
              "95  0.006472  0.003502  0.004174  ...  0.005282  0.003754  0.004017  0.004994   \n",
              "96  0.006622  0.003046  0.005028  ...  0.007132  0.003535  0.009001  0.008312   \n",
              "97  0.000822  0.005861  0.006609  ...  0.006952  0.000015  0.000491  0.001292   \n",
              "98  0.002864  0.003393  0.002009  ...  0.007042  0.009443  0.007935  0.009709   \n",
              "99  0.002222  0.009647  0.006950  ...  0.005524  0.002169  0.004735  0.004943   \n",
              "\n",
              "         95        96        97        98        99         100  \n",
              "0   0.736972  0.004714  0.002476  0.003086  0.006548  47.485476  \n",
              "1   0.743387  0.001479  0.006701  0.003134  0.009406  47.485476  \n",
              "2   0.741795  0.004211  0.007478  0.002682  0.002490  47.485476  \n",
              "3   0.742650  0.005261  0.007522  0.000468  0.004992  47.485476  \n",
              "4   0.736942  0.003995  0.001199  0.003697  0.009813  47.485476  \n",
              "..       ...       ...       ...       ...       ...        ...  \n",
              "95  0.743629  0.008933  0.006378  0.004348  0.008932  47.485476  \n",
              "96  0.739608  0.009807  0.002342  0.003143  0.006083  47.485476  \n",
              "97  0.736253  0.007337  0.000560  0.005609  0.001151  47.485476  \n",
              "98  0.738220  0.003710  0.005426  0.007349  0.007049  47.485476  \n",
              "99  0.743020  0.008936  0.001742  0.006288  0.002786  47.485476  \n",
              "\n",
              "[100 rows x 101 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Transformer_BigBird.parameters(TestsetF[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQmavrAOXyHX"
      },
      "source": [
        "#API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6bShK7E9XwSR"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'your_module'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32md:\\Work\\Cyrus\\API_FTransformer_ECT2023_04_07[12295].ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflask\u001b[39;00m \u001b[39mimport\u001b[39;00m Flask, jsonify\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39myour_module\u001b[39;00m \u001b[39mimport\u001b[39;00m Transformer_BigBird\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m app \u001b[39m=\u001b[39m Flask(\u001b[39m__name__\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m@app\u001b[39m\u001b[39m.\u001b[39mroute(\u001b[39m'\u001b[39m\u001b[39m/parameters\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Cyrus/API_FTransformer_ECT2023_04_07%5B12295%5D.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_parameters\u001b[39m():\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'your_module'"
          ]
        }
      ],
      "source": [
        "from flask import Flask, jsonify\n",
        "from your_module import Transformer_BigBird\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/parameters')\n",
        "def get_parameters():\n",
        "    model = Transformer_BigBird()\n",
        "    params = model.parameters()\n",
        "    return jsonify(list(params))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LdTXjqh249Vv",
        "ns83q7e70TAo",
        "2U7pAnVm-ozZ"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
